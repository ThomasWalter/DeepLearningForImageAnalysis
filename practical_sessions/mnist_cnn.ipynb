{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying digits using a convolutional neural network\n",
    "\n",
    "In this practical exercice a convolutional neural network  is built using keras. It is then trained to classify image digits from the MNIST database.\n",
    "\n",
    "Some baseline results:\n",
    "\n",
    "| Method                                                                      | Test error (%) |\n",
    "|-----------------------------------------------------------------------------|---------------:|\n",
    "| Linear classifier (LeCun et al. 1998)                                       |           12.0 |\n",
    "| K-nearest-neighbors, Euclidean (L2) (LeCun et al. 1998)                     |            5.0 |\n",
    "| 3-layer NN, 500-300, softmax, cross entropy, weight decay (Hinton, 2005)    |            1.5 |\n",
    "| Convolutional net LeNet-4 (LeCun et al. 1998)                               |            1.1 |\n",
    "| Virtual SVM deg-9 poly [data augmentation] (LeCun et al. 1998)              |            0.8 |\n",
    "| 6-layer NN with [data augmentation] (Ciresan et al. 2010)                   |           0.35 |\n",
    "| Deep conv. net, 7 layers [data augmentation] (Ciresan et al. IJCAI 2011)    |           0.35 |\n",
    "\n",
    "More results are available from: http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "Try to improve on some of these results, at least on those that do not use data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist as db\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Magic used by the notebook to show figures inline\n",
    "%matplotlib inline\n",
    "# matplotlib default values\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# auto-reloading packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and have a look at the data\n",
    "(x, y), (x_test, y_test) = db.load_data()\n",
    "\n",
    "# Visualize a single digit, with its class\n",
    "index = 2\n",
    "plt.imshow(x[index])\n",
    "print(\"Class: \", y[index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data management\n",
    "from keras import backend as K\n",
    "print(K.image_data_format())\n",
    "\n",
    "nb_samples = x.shape[0]\n",
    "val_nb = 5000  # number of validation samples\n",
    "if val_nb > nb_samples:\n",
    "    raise ValueError(\"You need some samples to train your network!\")\n",
    "\n",
    "img_rows, img_cols = x.shape[1:3]  # input image dimensions\n",
    "\n",
    "x = x.reshape(nb_samples, img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "x = x.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x /= 255\n",
    "x_test /= 255\n",
    "\n",
    "x_val = x[:val_nb, ]\n",
    "x_train = x[val_nb:, ]\n",
    "y_val = y[:val_nb]\n",
    "y_train = y[val_nb:]\n",
    "\n",
    "print(x_train.shape, 'x train samples')\n",
    "print(x_val.shape, 'x val samples')\n",
    "print(x_test.shape, 'x test samples')\n",
    "print(y_train.shape, 'y train samples')\n",
    "print(y_val.shape, 'y val samples')\n",
    "print(y_test.shape, 'y test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "num_classes = max(y) + 1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition\n",
    "\n",
    "The following model uses keras to build a convolutional network. It has to respect some constraints:\n",
    "\n",
    "- The input shape has to match the size of each input sample. \n",
    "- The ouptput should be of size 10 (num_classes)\n",
    "\n",
    "Other than that, feel free to modify the architecture and its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters0 = 32\n",
    "nb_dense = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters0, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "model.add(Conv2D(filters0 * 2, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(nb_dense, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "learning_rate = 0.1\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "output = model.fit(x_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=(x_val, y_val),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the results\n",
    "\n",
    "Visualizing what is going on is extremely important. For that:\n",
    "\n",
    "- inspecting traning and validation performance is essential;\n",
    "\n",
    "- looking at the errors might also be interesting.\n",
    "\n",
    "Is there overfitting? How can it be reduced?\n",
    "Is the network 'confident' when making errors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the performance of our network\n",
    "plt.plot(output.epoch, output.history['loss'], label='train')\n",
    "plt.plot(output.epoch, output.history['val_loss'], label='val')\n",
    "plt.title('Training and validation performance')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "# plt.ylim(0.2, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting activations of the neurons\n",
    "\n",
    "Given a certain input is possible to show the activations of the neurons of the convolutional layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a random sample from the training data\n",
    "index = np.random.randint(0, len(x_train))\n",
    "sample = x_train[index]\n",
    "\n",
    "plt.imshow(sample[:,:,0])\n",
    "print(\"Class: \", np.arange(num_classes)[y_train[index].astype('bool')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
    "activations = activation_model.predict(sample.reshape(1,28,28,1))\n",
    " \n",
    "def display_activation(activations, col_size, row_size, act_index): \n",
    "    activation = activations[act_index]\n",
    "    activation_index=0\n",
    "    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5,col_size*1.5))\n",
    "    for row in range(0,row_size):\n",
    "        for col in range(0,col_size):\n",
    "            ax[row][col].imshow(activation[0, :, :, activation_index], cmap=plt.cm.bwr)\n",
    "            ax[row][col].axis('off')\n",
    "            activation_index += 1\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display activation layer of the first filter\n",
    "print('Activations values in the first convolutional layer')\n",
    "display_activation(activations, 8, 4, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display activation filter of the second filter\n",
    "print('Activations values in the second convolutional layer')\n",
    "display_activation(activations, 8, 8, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "Testing is the last stage of the learning process. Good practice recommends to do it only once, when you have completely finished with the optimization of the network parameters and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, keras.utils.to_categorical(y_test, num_classes), verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_proba = model.predict(x_test)\n",
    "\n",
    "y_predict = np.argmax(y_predict_proba, 1)\n",
    "\n",
    "diff = y_test != y_predict\n",
    "x_test_errors = x_test[diff]\n",
    "y_test_errors = y_test[diff]\n",
    "y_predict_errors = y_predict[diff]\n",
    "y_predict_proba_errors = y_predict_proba[diff]\n",
    "\n",
    "index = 0\n",
    "\n",
    "print(\"Correct label is: \", y_test_errors[index])\n",
    "print(\"Predicted label is: \", y_predict_errors[index])\n",
    "print(\"Probabilities: \", y_predict_proba_errors[index])\n",
    "plt.imshow(np.squeeze(x_test_errors[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with a more complex database\n",
    "\n",
    "In the second cell, you can replace:\n",
    "\n",
    "<code>from keras.datasets import mnist as db</code>\n",
    "\n",
    "with:\n",
    "\n",
    "<code>from keras.datasets import fashion_mnist as db</code>\n",
    "\n",
    "in order to experiment with a more complex database. The best test accuracy reported on this database is 0.967 (see https://github.com/zalandoresearch/fashion-mnist).\n",
    "\n",
    "You can use the following dictionary to transform number labels into meaningfull labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_dict = {\n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\"\n",
    "    }\n",
    "\n",
    "print(fashion_dict[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
