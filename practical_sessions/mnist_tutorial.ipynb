{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist as db\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x, y), (x_test_ori, y_test_ori) = db.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a single digit, with its class\n",
    "plt_r,plt_c = 4,4\n",
    "f, ax = plt.subplots(plt_r,plt_c, figsize=(16,16))\n",
    "for i in range(plt_r):\n",
    "    for j in range(plt_c):\n",
    "        index = np.random.randint(x.shape[0])\n",
    "        ax[i][j].imshow(x[index])\n",
    "        ax[i][j].axis('off')\n",
    "        ax[i][j].set_title(\"Example: {}, Class: {}\".format(index, y[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data management\n",
    "val_nb = 5000  # number of validation samples\n",
    "nb_samples = x.shape[0]\n",
    "\n",
    "if val_nb > nb_samples:\n",
    "    raise ValueError(\"You need some samples to train your network!\")\n",
    "\n",
    "x = x.reshape(nb_samples, 784)\n",
    "x_test = x_test_ori.reshape(x_test_ori.shape[0], 784)\n",
    "x = x.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x /= 255\n",
    "x_test /= 255\n",
    "\n",
    "x_val = x[:val_nb, ]\n",
    "x_train = x[val_nb:, ]\n",
    "y_val = y[:val_nb]\n",
    "y_train = y[val_nb:]\n",
    "\n",
    "print(x_train.shape, 'x train samples')\n",
    "print(x_val.shape, 'x val samples')\n",
    "print(x_test.shape, 'x test samples')\n",
    "print(y_train.shape, 'y train samples')\n",
    "print(y_val.shape, 'y val samples')\n",
    "print(y_test_ori.shape, 'y test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "num_classes = max(y) + 1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test_ori, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition\n",
    "\n",
    "The following model uses keras to build a fully convolutional network. It has to respect some constraints:\n",
    "\n",
    "- The input shape has to match the size of each input sample. \n",
    "- The ouptput should be of size 10 (num_classes)\n",
    "\n",
    "Other than that, you change the number of layers as well as the size of each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple model without hidden variables\n",
    "model = Sequential()\n",
    "model.add(Dense(num_classes, activation='softmax', input_shape=(x_train.shape[1],)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "The following section takes care of training.\n",
    "\n",
    "Firstly, the model has to be 'compiled'. This operations lets the user choose the loss, the optimizer and the metrics, then configures the model for training.\n",
    "\n",
    "Secondly, the 'fit' method runs the optmization. Training and validation data are specified here, as well as batch size and the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "learning_rate = 0.1\n",
    "# muli\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "output = model.fit(x_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(output.epoch, output.history['loss'], label='train')\n",
    "plt.plot(output.epoch, output.history['val_loss'], label='val')\n",
    "plt.title('Training and validation performance')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "# plt.ylim(0.2, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the weights in the \n",
    "W, b = model.layers[0].get_weights()\n",
    "print(W.shape)\n",
    "print(b.shape)\n",
    "f, ax = plt.subplots(2, 5, figsize=(16,6))\n",
    "for plt_row in range(2):\n",
    "    for plt_col in range(5):\n",
    "        ax[plt_row][plt_col].imshow(W[:,plt_row*5 + plt_col].reshape(28,28))\n",
    "        ax[plt_row][plt_col].axis('off')\n",
    "        ax[plt_row][plt_col].set_title(\"Weights for the class {}\".format(plt_row*5 + plt_col))\n",
    "        print(W[392, plt_row*5 + plt_col])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
