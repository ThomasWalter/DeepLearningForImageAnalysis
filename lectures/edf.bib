
@article{alais_fast_2020,
	title = {Fast macula detection and application to retinal image quality assessment},
	volume = {55},
	issn = {1746-8094},
	url = {https://www.sciencedirect.com/science/article/pii/S1746809419301417},
	doi = {10.1016/j.bspc.2019.101567},
	abstract = {In this article, we present a segmentation algorithm for assessing retinal image quality with respect to the visibility of the macular region. An image is considered of acceptable quality if the macular region is clearly visible and entirely in the field of view. Additionally, for acceptable images, the method is able to locate the fovea with a maximal error of 0.34 mm. The algorithm is based on a lightweight fully-convolutional network, several thousand times smaller than state-of-the-art networks investigated so far in preliminary studies. We obtain near-human performance for assessing macula visibility and fovea localization. The presented method can easily be embedded in tabletop or handheld retinographs, decreasing the number of ungradable images, saving both patient and physician time. It is an important step towards automatic screening of retinal pathologies, including diabetic retinopathy, which is a major global healthcare issue.},
	language = {en},
	urldate = {2021-10-19},
	journal = {Biomedical Signal Processing and Control},
	author = {Alais, Robin and Dokládal, Petr and Erginay, Ali and Figliuzzi, Bruno and Decencière, Etienne},
	month = jan,
	year = {2020},
	keywords = {Convolutional neural networks, Image quality assessment, Macula detection, Retinal imaging},
	pages = {101567},
}

@inproceedings{duque-arias_power_2021,
	address = {Vienne (on line), Austria},
	title = {On power {Jaccard} losses for semantic segmentation},
	url = {https://hal.archives-ouvertes.fr/hal-03139997},
	abstract = {In this work, a new generalized loss function is proposed called power Jaccard to perform semantic segmentation tasks. It is compared with classical loss functions in different scenarios, including gray level and color image segmentation, as well as 3D point cloud segmentation. The results show improved performance, stability and convergence. We made available the code with our proposal with a demonstrative example.},
	urldate = {2021-10-19},
	booktitle = {{VISAPP} 2021 : 16th {International} {Conference} on {Computer} {Vision} {Theory} and {Applications}},
	author = {Duque-Arias, David and Velasco-Forero, Santiago and Deschaud, Jean-Emmanuel and Goulette, Francois and Serna, Andrés and Decencière, Etienne and Marcotegui, Beatriz},
	month = feb,
	year = {2021},
	keywords = {deep learning, Image segmentation, Jaccard loss, Loss functions, U-net architecture},
}

@article{xiao_fashion-mnist_2017,
	title = {Fashion-{MNIST}: a {Novel} {Image} {Dataset} for {Benchmarking} {Machine} {Learning} {Algorithms}},
	shorttitle = {Fashion-{MNIST}},
	url = {http://arxiv.org/abs/1708.07747},
	abstract = {We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at https://github.com/zalandoresearch/fashion-mnist},
	urldate = {2021-10-01},
	journal = {arXiv:1708.07747 [cs, stat]},
	author = {Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
	month = sep,
	year = {2017},
	note = {arXiv: 1708.07747},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{bergmann_mvtec_2021,
	title = {The {MVTec} {Anomaly} {Detection} {Dataset}: {A} {Comprehensive} {Real}-{World} {Dataset} for {Unsupervised} {Anomaly} {Detection}},
	volume = {129},
	issn = {1573-1405},
	shorttitle = {The {MVTec} {Anomaly} {Detection} {Dataset}},
	url = {https://doi.org/10.1007/s11263-020-01400-4},
	doi = {10.1007/s11263-020-01400-4},
	abstract = {The detection of anomalous structures in natural image data is of utmost importance for numerous tasks in the field of computer vision. The development of methods for unsupervised anomaly detection requires data on which to train and evaluate new approaches and ideas. We introduce the MVTec anomaly detection dataset containing 5354 high-resolution color images of different object and texture categories. It contains normal, i.e., defect-free images intended for training and images with anomalies intended for testing. The anomalies manifest themselves in the form of over 70 different types of defects such as scratches, dents, contaminations, and various structural changes. In addition, we provide pixel-precise ground truth annotations for all anomalies. We conduct a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pretrained convolutional neural networks, as well as classical computer vision methods. We highlight the advantages and disadvantages of multiple performance metrics as well as threshold estimation techniques. This benchmark indicates that methods that leverage descriptors of pretrained networks outperform all other approaches and deep-learning-based generative models show considerable room for improvement.},
	language = {en},
	number = {4},
	urldate = {2021-10-01},
	journal = {International Journal of Computer Vision},
	author = {Bergmann, Paul and Batzner, Kilian and Fauser, Michael and Sattlegger, David and Steger, Carsten},
	month = apr,
	year = {2021},
	pages = {1038--1059},
}

@inproceedings{dinh_density_2017,
	title = {Density estimation using {Real} {NVP}},
	url = {http://arxiv.org/abs/1605.08803},
	abstract = {Unsupervised learning of probabilistic models is a central yet challenging problem in machine learning. Specifically, designing models with tractable learning, sampling, inference and evaluation is crucial in solving this task. We extend the space of such models using real-valued non-volume preserving (real NVP) transformations, a set of powerful invertible and learnable transformations, resulting in an unsupervised learning algorithm with exact log-likelihood computation, exact sampling, exact inference of latent variables, and an interpretable latent space. We demonstrate its ability to model natural images on four datasets through sampling, log-likelihood evaluation and latent variable manipulations.},
	urldate = {2021-09-29},
	booktitle = {{ICLR}},
	author = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
	month = feb,
	year = {2017},
	note = {arXiv: 1605.08803},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
}

@incollection{ciresan_deep_2012,
	title = {Deep {Neural} {Networks} {Segment} {Neuronal} {Membranes} in {Electron} {Microscopy} {Images}},
	url = {http://papers.nips.cc/paper/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images.pdf},
	urldate = {2018-10-17},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	publisher = {Curran Associates, Inc.},
	author = {Cireşan, Dan and Giusti, Alessandro and Gambardella, Luca M. and Schmidhuber, Jürgen},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
	pages = {2843--2851},
}

@inproceedings{zhang_application_2011,
	title = {Application of the {Morphological} {Ultimate} {Opening} to the {Detection} of {Microaneurysms} on {Eye} {Fundus} {Images} from {Clinical} {Databases}},
	booktitle = {{ICS}'13},
	author = {Zhang, Xiwei and Thibault, Guillaume and Decencière, Etienne},
	year = {2011},
}

@inproceedings{decenciere_dealing_2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Dealing with {Topological} {Information} {Within} a {Fully} {Convolutional} {Neural} {Network}},
	isbn = {978-3-030-01449-0},
	doi = {10.1007/978-3-030-01449-0_39},
	abstract = {A fully convolutional neural network has a receptive field of limited size and therefore cannot exploit global information, such as topological information. A solution is proposed in this paper to solve this problem, based on pre-processing with a geodesic operator. It is applied to the segmentation of histological images of pigmented reconstructed epidermis acquired via Whole Slide Imaging.},
	language = {en},
	booktitle = {Advanced {Concepts} for {Intelligent} {Vision} {Systems}},
	publisher = {Springer International Publishing},
	author = {Decencière, Etienne and Velasco-Forero, Santiago and Min, Fu and Chen, Juanjuan and Burdin, Hélène and Gauthier, Gervais and Laÿ, Bruno and Bornschloegl, Thomas and Baldeweck, Thérèse},
	editor = {Blanc-Talon, Jacques and Helbert, David and Philips, Wilfried and Popescu, Dan and Scheunders, Paul},
	year = {2018},
	keywords = {Convolutional neural network, Geodesic operators, Histological image segmentation, Mathematical morphology},
	pages = {462--471},
}

@incollection{ronneberger_u-net:_2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	copyright = {©2015 Springer International Publishing Switzerland},
	shorttitle = {U-{Net}},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	language = {en},
	number = {9351},
	urldate = {2016-09-12},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2015},
	publisher = {Springer International Publishing},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	editor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
	month = oct,
	year = {2015},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Graphics, Health Informatics, Image Processing and Computer Vision, Imaging / Radiology, Pattern recognition},
	pages = {234--241},
	file = {Snapshot:/home/edecenciere/Zotero/storage/BBUWJFJV/978-3-319-24574-4_28.html:text/html},
}

@inproceedings{roussel_recurrent_2019,
	title = {A {Recurrent} {Neural} {Network} for the {Prediction} of {Vital} {Sign} {Evolution} and {Sepsis} in {ICU}},
	booktitle = {2019 {Computing} in {Cardiology} ({CinC})},
	publisher = {IEEE},
	author = {Roussel, Benjamin and Behar, Joachim and Oster, Julien},
	year = {2019},
	pages = {Page--1},
}

@article{pelt_improving_2018,
	title = {Improving {Tomographic} {Reconstruction} from {Limited} {Data} {Using} {Mixed}-{Scale} {Dense} {Convolutional} {Neural} {Networks}},
	volume = {4},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2313-433X/4/11/128},
	doi = {10.3390/jimaging4110128},
	abstract = {In many applications of tomography, the acquired data are limited in one or more ways due to unavoidable experimental constraints. In such cases, popular direct reconstruction algorithms tend to produce inaccurate images, and more accurate iterative algorithms often have prohibitively high computational costs. Using machine learning to improve the image quality of direct algorithms is a recently proposed alternative, for which promising results have been shown. However, previous attempts have focused on using encoder\&ndash;decoder networks, which have several disadvantages when applied to large tomographic images, preventing wide application in practice. Here, we propose the use of the Mixed-Scale Dense convolutional neural network architecture, which was specifically designed to avoid these disadvantages, to improve tomographic reconstruction from limited data. Results are shown for various types of data limitations and object types, for both simulated data and large-scale real-world experimental data. The results are compared with popular tomographic reconstruction algorithms and machine learning algorithms, showing that Mixed-Scale Dense networks are able to significantly improve reconstruction quality even with severely limited data, and produce more accurate results than existing algorithms.},
	language = {en},
	number = {11},
	urldate = {2021-06-25},
	journal = {Journal of Imaging},
	author = {Pelt, Daniël M. and Batenburg, Kees Joost and Sethian, James A.},
	month = nov,
	year = {2018},
	note = {Number: 11
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {deep learning, image reconstruction, machine learning, tomography},
	pages = {128},
}

@article{baum_capabilities_1988,
	title = {On the capabilities of multilayer perceptrons},
	volume = {4},
	issn = {0885-064X},
	url = {https://www.sciencedirect.com/science/article/pii/0885064X88900209},
	doi = {10.1016/0885-064X(88)90020-9},
	abstract = {What is the smallest multilayer perceptron able to compute arbitrary and random functions? Previous results show that a net with one hidden layer containing N − 1 threshold units is capable of implementing an arbitrary dichotomy of N points. A construction is presented here for implementing an arbitrary dichotomy with one hidden layer containing [Nd] units, for any set of N points in general position in d dimensions. This is in fact the smallest such net as dichotomies which cannot be implemented by any net with fewer units are described. Several constructions are presented of one-hidden-layer nets implementing arbitrary functions into the e-dimensional hypercube. One of these has only [4Nd][e[log2(Nd)]] units in its hidden layer. Arguments based on a function counting theorem of Cover establish that any net implementing arbitrary functions must have at least Nelog2(N) weights, so that no net with one hidden layer containing less than Ne/(d log2(N)) units will suffice. Simple counts also show that if the weights are only allowed to assume one of ng possible values, no net with fewer than Nelog2(ng) weights will suffice. Thus the gain coming from using real valued synapses appears to be only logarithmic. The circuit implementing functions into the e hypercube realizes such logarithmic gains. Since the counting arguments limit below only the number of weights, the possibility is suggested that, if suitable restrictions are imposed on the input vector set to avoid topological obstructions, two-hidden-layer nets with O(N) weights but only O(√N) threshold units might suffice for arbitrary dichotomies. Interesting and potentially sufficient restrictions include (a) if the vectors are binary, i.e., lie on the d hypercube or (b) if they are randomly and uniformly selected from a bounded region.},
	language = {en},
	number = {3},
	urldate = {2021-06-10},
	journal = {Journal of Complexity},
	author = {Baum, Eric B},
	month = sep,
	year = {1988},
	pages = {193--215},
}

@article{tolstikhin_mlp-mixer_2021,
	title = {{MLP}-{Mixer}: {An} all-{MLP} {Architecture} for {Vision}},
	shorttitle = {{MLP}-{Mixer}},
	url = {http://arxiv.org/abs/2105.01601},
	abstract = {Convolutional Neural Networks (CNNs) are the go-to model for computer vision. Recently, attention-based networks, such as the Vision Transformer, have also become popular. In this paper we show that while convolutions and attention are both sufficient for good performance, neither of them are necessary. We present MLP-Mixer, an architecture based exclusively on multi-layer perceptrons (MLPs). MLP-Mixer contains two types of layers: one with MLPs applied independently to image patches (i.e. "mixing" the per-location features), and one with MLPs applied across patches (i.e. "mixing" spatial information). When trained on large datasets, or with modern regularization schemes, MLP-Mixer attains competitive scores on image classification benchmarks, with pre-training and inference cost comparable to state-of-the-art models. We hope that these results spark further research beyond the realms of well established CNNs and Transformers.},
	urldate = {2021-06-07},
	journal = {arXiv:2105.01601 [cs]},
	author = {Tolstikhin, Ilya and Houlsby, Neil and Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Unterthiner, Thomas and Yung, Jessica and Steiner, Andreas and Keysers, Daniel and Uszkoreit, Jakob and Lucic, Mario and Dosovitskiy, Alexey},
	month = may,
	year = {2021},
	note = {arXiv: 2105.01601},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{glorot_deep_2011,
	title = {Deep {Sparse} {Rectifier} {Neural} {Networks}},
	url = {http://proceedings.mlr.press/v15/glorot11a.html},
	abstract = {While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neu...},
	language = {en},
	urldate = {2021-05-06},
	booktitle = {Proceedings of the {Fourteenth} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {JMLR Workshop and Conference Proceedings},
	author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
	month = jun,
	year = {2011},
	note = {ISSN: 1938-7228},
	pages = {315--323},
}

@article{decenciere_teleophta_2013,
	series = {Special issue : {ANR} {TECSAN} : {Technologies} for {Health} and {Autonomy}},
	title = {{TeleOphta}: {Machine} learning and image processing methods for teleophthalmology},
	volume = {34},
	issn = {1959-0318},
	shorttitle = {{TeleOphta}},
	url = {https://www.sciencedirect.com/science/article/pii/S1959031813000237},
	doi = {10.1016/j.irbm.2013.01.010},
	abstract = {A complete prototype for the automatic detection of normal examinations on a teleophthalmology network for diabetic retinopathy screening is presented. The system combines pathological pattern mining methods, with specific lesion detection methods, to extract information from the images. This information, plus patient and other contextual data, is used by a classifier to compute an abnormality risk. Such a system should reduce the burden on readers on teleophthalmology networks.},
	language = {en},
	number = {2},
	urldate = {2021-05-05},
	journal = {IRBM},
	author = {Decencière, E. and Cazuguel, G. and Zhang, X. and Thibault, G. and Klein, J. -C. and Meyer, F. and Marcotegui, B. and Quellec, G. and Lamard, M. and Danno, R. and Elie, D. and Massin, P. and Viktor, Z. and Erginay, A. and Laÿ, B. and Chabouis, A.},
	month = apr,
	year = {2013},
	pages = {196--203},
}

@article{shen_deep_2019,
	title = {Deep image reconstruction from human brain activity},
	volume = {15},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006633},
	doi = {10.1371/journal.pcbi.1006633},
	abstract = {The mental contents of perception and imagery are thought to be encoded in hierarchical representations in the brain, but previous attempts to visualize perceptual contents have failed to capitalize on multiple levels of the hierarchy, leaving it challenging to reconstruct internal imagery. Recent work showed that visual cortical activity measured by functional magnetic resonance imaging (fMRI) can be decoded (translated) into the hierarchical features of a pre-trained deep neural network (DNN) for the same input image, providing a way to make use of the information from hierarchical visual features. Here, we present a novel image reconstruction method, in which the pixel values of an image are optimized to make its DNN features similar to those decoded from human brain activity at multiple layers. We found that our method was able to reliably produce reconstructions that resembled the viewed natural images. A natural image prior introduced by a deep generator neural network effectively rendered semantically meaningful details to the reconstructions. Human judgment of the reconstructions supported the effectiveness of combining multiple DNN layers to enhance the visual quality of generated images. While our model was solely trained with natural images, it successfully generalized to artificial shapes, indicating that our model was not simply matching to exemplars. The same analysis applied to mental imagery demonstrated rudimentary reconstructions of the subjective content. Our results suggest that our method can effectively combine hierarchical neural representations to reconstruct perceptual and subjective images, providing a new window into the internal contents of the brain.},
	language = {en},
	number = {1},
	urldate = {2021-05-05},
	journal = {PLOS Computational Biology},
	author = {Shen, Guohua and Horikawa, Tomoyasu and Majima, Kei and Kamitani, Yukiyasu},
	month = jan,
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Algorithms, Functional magnetic resonance imaging, Imaging techniques, Luminance, Neural networks, Optimization, Sensory perception, Vision},
	pages = {e1006633},
}

@article{touvron_training_2021,
	title = {Training data-efficient image transformers \& distillation through attention},
	url = {http://arxiv.org/abs/2012.12877},
	abstract = {Recently, neural networks purely based on attention were shown to address image understanding tasks such as image classification. However, these visual transformers are pre-trained with hundreds of millions of images using an expensive infrastructure, thereby limiting their adoption. In this work, we produce a competitive convolution-free transformer by training on Imagenet only. We train them on a single computer in less than 3 days. Our reference vision transformer (86M parameters) achieves top-1 accuracy of 83.1\% (single-crop evaluation) on ImageNet with no external data. More importantly, we introduce a teacher-student strategy specific to transformers. It relies on a distillation token ensuring that the student learns from the teacher through attention. We show the interest of this token-based distillation, especially when using a convnet as a teacher. This leads us to report results competitive with convnets for both Imagenet (where we obtain up to 85.2\% accuracy) and when transferring to other tasks. We share our code and models.},
	urldate = {2021-03-29},
	journal = {arXiv:2012.12877 [cs]},
	author = {Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and Jégou, Hervé},
	month = jan,
	year = {2021},
	note = {arXiv: 2012.12877},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{cherti_out--class_2017,
	title = {Out-of-{Class} {Novelty} {Generation} : {An} {Experimental} {Foundation}},
	shorttitle = {Out-of-{Class} {Novelty} {Generation}},
	doi = {10.1109/ICTAI.2017.00197},
	abstract = {Recent advances in machine learning have brought the field closer to computational creativity research. From a creativity research point of view, this offers the potential to study creativity in relationship with knowledge acquisition. From a machine learning perspective, however, several aspects of creativity need to be better defined to allow the machine learning community to develop and test hypotheses in a systematic way. We propose an actionable definition of creativity as the generation of out-of-distribution novelty. We assess several metrics designed for evaluating the quality of generative models on this new task. We also propose a new experimental setup. Inspired by the usual held-out validation, we hold out entire classes for evaluating the generative potential of models. The goal of the novelty generator is then to use training classes to build a model that can generate objects from future (hold-out) classes, unknown at training time - and thus, are novel with respect to the knowledge the model incorporates. Through extensive experiments on various types of generative models, we are able to find architectures and hyperparameter combinations which lead to out-of-distribution novelty.},
	booktitle = {2017 {IEEE} 29th {International} {Conference} on {Tools} with {Artificial} {Intelligence} ({ICTAI})},
	author = {Cherti, M. and Kégl, B. and Kazakçı, A.},
	month = nov,
	year = {2017},
	note = {ISSN: 2375-0197},
	keywords = {actionable definition, computational creativity research, Creativity, deep neural nets, entire classes, evaluation of generative models, experimental setup, Gallium nitride, generative model, Generators, knowledge acquisition, knowledge driven creativity, learning (artificial intelligence), Machine learning, machine learning perspective, Measurement, novelty generator, out-of-class novelty generation, out-of-distribution novelty, Pipelines, Training, training classes, value of novelty},
	pages = {1312--1319},
}

@inproceedings{kolesnikov_big_2020,
	title = {Big {Transfer} ({BiT}): {General} {Visual} {Representation} {Learning}},
	shorttitle = {Big {Transfer} ({BiT})},
	booktitle = {European {Conference} on {Computer} {Vision}},
	author = {Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Puigcerver, Joan and Yung, Jessica and Gelly, Sylvain and Houlsby, Neil},
	year = {2020},
}

@inproceedings{dosovitskiy_image_2021,
	title = {An {Image} is {Worth} 16x16 {Words}: {Transformers} for {Image} {Recognition} at {Scale}},
	shorttitle = {An {Image} is {Worth} 16x16 {Words}},
	url = {http://arxiv.org/abs/2010.11929},
	urldate = {2021-02-15},
	booktitle = {{arXiv}:2010.11929 [cs]},
	author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
	year = {2021},
	note = {arXiv: 2010.11929},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{carion_end--end_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {End-to-{End} {Object} {Detection} with {Transformers}},
	isbn = {978-3-030-58452-8},
	doi = {10.1007/978-3-030-58452-8_13},
	abstract = {We present a new method that views object detection as a direct set prediction problem. Our approach streamlines the detection pipeline, effectively removing the need for many hand-designed components like a non-maximum suppression procedure or anchor generation that explicitly encode our prior knowledge about the task. The main ingredients of the new framework, called DEtection TRansformer or DETR, are a set-based global loss that forces unique predictions via bipartite matching, and a transformer encoder-decoder architecture. Given a fixed small set of learned object queries, DETR reasons about the relations of the objects and the global image context to directly output the final set of predictions in parallel. The new model is conceptually simple and does not require a specialized library, unlike many other modern detectors. DETR demonstrates accuracy and run-time performance on par with the well-established and highly-optimized Faster R-CNN baseline on the challenging COCO object detection dataset. Moreover, DETR can be easily generalized to produce panoptic segmentation in a unified manner. We show that it significantly outperforms competitive baselines. Training code and pretrained models are available at https://github.com/facebookresearch/detr.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2020},
	publisher = {Springer International Publishing},
	author = {Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
	editor = {Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael},
	year = {2020},
	pages = {213--229},
}

@article{vaswani_attention_2017,
	title = {Attention is {All} you {Need}},
	volume = {30},
	url = {https://papers.nips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
	language = {en},
	urldate = {2021-02-12},
	journal = {Advances in Neural Information Processing Systems},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	year = {2017},
}

@article{itti_computational_2001,
	title = {Computational modelling of visual attention},
	volume = {2},
	copyright = {2001 Nature Publishing Group},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/35058500},
	doi = {10.1038/35058500},
	abstract = {We review recent work on computational models of focal visual attention, with emphasis on the bottom-up, saliency- or image-based control of attentional deployment. We highlight five important trends that have emerged from the computational literature: First, the perceptual saliency of stimuli critically depends on surrounding context; that is, the same object may or may not appear salient depending on the nature and arrangement of other objects in the scene. Computationally, this means that contextual influences, such as non-classical surround interactions, must be included in models. Second, a unique 'saliency map' topographically encoding for stimulus conspicuity over the visual scene has proved to be an efficient and plausible bottom-up control strategy. Many successful models are based on such architecture, and electrophysiological as well as psychophysical studies have recently supported the idea that saliency is explicitly encoded in the brain. Third, inhibition-of-return (IOR), the process by which the currently attended location is transiently inhibited, is a critical element of attentional deployment. Without IOR, attention would endlessly be attracted towards the most salient stimulus. IOR thus implements a memory of recently visited locations, and allows attention to thoroughly scan our visual environment. Fourth, attention and eye movements tightly interplay, posing computational challenges with respect to the coordinate system used to control attention. Understanding the interaction between overt and covert attention is particularly important for models concerned with visual search. Last, scene understanding and object recognition strongly constrain the selection of attended locations. Although several models have approached, in an information-theoretical sense, the problem of optimally deploying attention to analyse a scene, biologically plausible implementations of such a computational strategy remain to be developed.},
	language = {en},
	number = {3},
	urldate = {2021-02-12},
	journal = {Nature Reviews Neuroscience},
	author = {Itti, Laurent and Koch, Christof},
	month = mar,
	year = {2001},
	note = {Number: 3
Publisher: Nature Publishing Group},
	pages = {194--203},
}

@inproceedings{vaswani_attention_2017-1,
	title = {Attention is {All} you {Need}},
	url = {https://openreview.net/forum?id=H1ZGYPb_ZS},
	abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the...},
	language = {en},
	urldate = {2021-02-12},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = jan,
	year = {2017},
}

@article{jaderberg_spatial_2016,
	title = {Spatial {Transformer} {Networks}},
	url = {http://arxiv.org/abs/1506.02025},
	abstract = {Convolutional Neural Networks define an exceptionally powerful class of models, but are still limited by the lack of ability to be spatially invariant to the input data in a computationally and parameter efficient manner. In this work we introduce a new learnable module, the Spatial Transformer, which explicitly allows the spatial manipulation of data within the network. This differentiable module can be inserted into existing convolutional architectures, giving neural networks the ability to actively spatially transform feature maps, conditional on the feature map itself, without any extra training supervision or modification to the optimisation process. We show that the use of spatial transformers results in models which learn invariance to translation, scale, rotation and more generic warping, resulting in state-of-the-art performance on several benchmarks, and for a number of classes of transformations.},
	urldate = {2021-02-10},
	journal = {arXiv:1506.02025 [cs]},
	author = {Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and Kavukcuoglu, Koray},
	month = feb,
	year = {2016},
	note = {arXiv: 1506.02025},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{ren_faster_2015,
	title = {Faster {R}-{CNN}: {Towards} {Real}-{Time} {Object} {Detection} with {Region} {Proposal} {Networks}},
	volume = {28},
	shorttitle = {Faster {R}-{CNN}},
	url = {https://proceedings.neurips.cc/paper/2015/hash/14bfa6bb14875e45bba028a21ed38046-Abstract.html},
	language = {en},
	urldate = {2021-02-10},
	journal = {Advances in Neural Information Processing Systems},
	author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
	year = {2015},
	pages = {91--99},
}

@article{bergstra_random_2012,
	title = {Random search for hyper-parameter optimization.},
	volume = {13},
	number = {2},
	journal = {Journal of machine learning research},
	author = {Bergstra, James and Bengio, Yoshua},
	year = {2012},
}

@article{denil_learning_2012,
	title = {Learning {Where} to {Attend} with {Deep} {Architectures} for {Image} {Tracking}},
	volume = {24},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/NECO_a_00312},
	doi = {10.1162/NECO_a_00312},
	abstract = {We discuss an attentional model for simultaneous object tracking and recognition that is driven by gaze data. Motivated by theories of perception, the model consists of two interacting pathways, identity and control, intended to mirror the what and where pathways in neuroscience models. The identity pathway models object appearance and performs classification using deep (factored)-restricted Boltzmann machines. At each point in time, the observations consist of foveated images, with decaying resolution toward the periphery of the gaze. The control pathway models the location, orientation, scale, and speed of the attended object. The posterior distribution of these states is estimated with particle filtering. Deeper in the control pathway, we encounter an attentional mechanism that learns to select gazes so as to minimize tracking uncertainty. Unlike in our previous work, we introduce gaze selection strategies that operate in the presence of partial information and on a continuous action space. We show that a straightforward extension of the existing approach to the partial information setting results in poor performance, and we propose an alternative method based on modeling the reward surface as a gaussian process. This approach gives good performance in the presence of partial information and allows us to expand the action space from a small, discrete set of fixation points to a continuous domain.},
	number = {8},
	urldate = {2021-02-09},
	journal = {Neural Computation},
	author = {Denil, Misha and Bazzani, Loris and Larochelle, Hugo and de Freitas, Nando},
	month = apr,
	year = {2012},
	note = {Publisher: MIT Press},
	pages = {2151--2184},
}

@article{viola_robust_2004,
	title = {Robust {Real}-{Time} {Face} {Detection}},
	volume = {57},
	issn = {1573-1405},
	url = {https://doi.org/10.1023/B:VISI.0000013087.49260.fb},
	doi = {10.1023/B:VISI.0000013087.49260.fb},
	abstract = {This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the “Integral Image” which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a “cascade” which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second.},
	language = {en},
	number = {2},
	urldate = {2021-02-09},
	journal = {International Journal of Computer Vision},
	author = {Viola, Paul and Jones, Michael J.},
	month = may,
	year = {2004},
	pages = {137--154},
}

@inproceedings{viola_rapid_2001,
	title = {Rapid object detection using a boosted cascade of simple features},
	volume = {1},
	doi = {10.1109/CVPR.2001.990517},
	abstract = {This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the "integral image" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a "cascade" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.},
	booktitle = {Proceedings of the 2001 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}. {CVPR} 2001},
	author = {Viola, P. and Jones, M.},
	month = dec,
	year = {2001},
	note = {ISSN: 1063-6919},
	keywords = {machine learning, learning (artificial intelligence), Machine learning, AdaBoost, background regions, boosted simple feature cascade, classifiers, Detectors, face detection, Face detection, feature extraction, Filters, Focusing, image classification, image processing, image representation, Image representation, integral image, object detection, Object detection, object specific focus-of-attention mechanism, Pixel, rapid object detection, real-time applications, Robustness, Skin, statistical guarantees, visual object detection},
	pages = {I--I},
}

@article{itti_model_1998,
	title = {A model of saliency-based visual attention for rapid scene analysis},
	volume = {20},
	issn = {1939-3539},
	doi = {10.1109/34.730558},
	abstract = {A visual attention system, inspired by the behavior and the neuronal architecture of the early primate visual system, is presented. Multiscale image features are combined into a single topographical saliency map. A dynamical neural network then selects attended locations in order of decreasing saliency. The system breaks down the complex problem of scene understanding by rapidly selecting, in a computationally efficient manner, conspicuous locations to be analyzed in detail.},
	number = {11},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Itti, L. and Koch, C. and Niebur, E.},
	month = nov,
	year = {1998},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Neural networks, feature extraction, Object detection, Biological system modeling, Brain modeling, Computer architecture, computer vision, dynamical neural network, Feature extraction, Hardware, Image analysis, image recognition, Layout, neural nets, rapid scene analysis, saliency, scene understanding, target detection, target tracking, topographical saliency map, visual attention, visual search, Visual system},
	pages = {1254--1259},
}

@incollection{yarbus_eye_1967,
	address = {Boston, MA},
	title = {Eye {Movements} {During} {Perception} of {Complex} {Objects}},
	isbn = {978-1-4899-5379-7},
	url = {https://doi.org/10.1007/978-1-4899-5379-7_8},
	language = {en},
	urldate = {2021-02-09},
	booktitle = {Eye {Movements} and {Vision}},
	publisher = {Springer US},
	author = {Yarbus, Alfred L.},
	editor = {Yarbus, Alfred L.},
	year = {1967},
	doi = {10.1007/978-1-4899-5379-7_8},
	keywords = {Complex Object, Optical Illusion, Retinal Image, Retinal Movement, Stationary Object},
	pages = {171--211},
}

@article{tatler_yarbus_2010,
	title = {Yarbus, {Eye} {Movements}, and {Vision}},
	volume = {1},
	issn = {2041-6695},
	url = {https://doi.org/10.1068/i0382},
	doi = {10.1068/i0382},
	abstract = {The impact of Yarbus's research on eye movements was enormous following the translation of his book Eye Movements and Vision into English in 1967. In stark contrast, the published material in English concerning his life is scant. We provide a brief biography of Yarbus and assess his impact on contemporary approaches to research on eye movements. While early interest in his work focused on his study of stabilised retinal images, more recently this has been replaced with interest in his work on the cognitive influences on scanning patterns. We extended his experiment on the effect of instructions on viewing a picture using a portrait of Yarbus rather than a painting. The results obtained broadly supported those found by Yarbus.},
	language = {en},
	number = {1},
	urldate = {2021-02-09},
	journal = {i-Perception},
	author = {Tatler, Benjamin W and Wade, Nicholas J and Kwan, Hoi and Findlay, John M and Velichkovsky, Boris M},
	month = apr,
	year = {2010},
	note = {Publisher: SAGE Publications},
	keywords = {eye guidance, eye movement, face perception, history, saccade, scene perception, stabilised retinal image, Yarbus},
	pages = {7--27},
}

@inproceedings{hinton_transforming_2011,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Transforming {Auto}-{Encoders}},
	isbn = {978-3-642-21735-7},
	doi = {10.1007/978-3-642-21735-7_6},
	abstract = {The artificial neural networks that are used to recognize shapes typically use one or more layers of learned feature detectors that produce scalar outputs. By contrast, the computer vision community uses complicated, hand-engineered features, like SIFT [6], that produce a whole vector of outputs including an explicit representation of the pose of the feature. We show how neural networks can be used to learn features that output a whole vector of instantiation parameters and we argue that this is a much more promising way of dealing with variations in position, orientation, scale and lighting than the methods currently employed in the neural networks community. It is also more promising than the hand-engineered features currently used in computer vision because it provides an efficient way of adapting the features to the domain.},
	language = {en},
	booktitle = {Artificial {Neural} {Networks} and {Machine} {Learning} – {ICANN} 2011},
	publisher = {Springer},
	author = {Hinton, Geoffrey E. and Krizhevsky, Alex and Wang, Sida D.},
	editor = {Honkela, Timo and Duch, Włodzisław and Girolami, Mark and Kaski, Samuel},
	year = {2011},
	keywords = {auto-encoder, Invariance, shape representation},
	pages = {44--51},
}

@inproceedings{hinton_parallel_1981,
	address = {San Francisco, CA, USA},
	series = {{IJCAI}'81},
	title = {A parallel computation that assigns canonical object-based frames of reference},
	abstract = {A viewpoint-independent description of the shape of an object can be generated by imposing a canonical frame of reference on the object and describing the spatial dispositions of the parts relative to this object-based frame. When a familiar object is in an unusual orientation, the deciding factor in the choice of the canonical object-based frame may be the fact that relative to this frame the object has a familiar shape description. This may suggest that we first hypothesise an object-based frame and then test the resultant shape description for familiarity. However, it is possible to organise the interactions between units in a parallel network so that the pattern of activity in the network simultaneously converges on a representation of the shape and a representation of the object-based frame of reference. The connections in the network are determined by the constraints inherent in the image formation process.},
	urldate = {2021-02-08},
	booktitle = {Proceedings of the 7th international joint conference on {Artificial} intelligence - {Volume} 2},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Hinton, Geoffrey F.},
	month = aug,
	year = {1981},
	pages = {683--685},
}

@article{devlin_bert_2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2021-02-08},
	journal = {arXiv:1810.04805 [cs]},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	note = {arXiv: 1810.04805},
	keywords = {Computer Science - Computation and Language},
}

@article{brown_language_2020,
	title = {Language {Models} are {Few}-{Shot} {Learners}},
	url = {http://arxiv.org/abs/2005.14165},
	abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.},
	urldate = {2021-02-08},
	journal = {arXiv:2005.14165 [cs]},
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	month = jul,
	year = {2020},
	note = {arXiv: 2005.14165},
	keywords = {Computer Science - Computation and Language},
}

@article{wermeskerken_what_2018,
	title = {What {Am} {I} {Looking} at? {Interpreting} {Dynamic} and {Static} {Gaze} {Displays}},
	volume = {42},
	copyright = {Copyright © 2017 The Authors. Cognitive Science published by Wiley Periodicals, Inc. on behalf of Cognitive Science Society.},
	issn = {1551-6709},
	shorttitle = {What {Am} {I} {Looking} at?},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12484},
	doi = {https://doi.org/10.1111/cogs.12484},
	abstract = {Displays of eye movements may convey information about cognitive processes but require interpretation. We investigated whether participants were able to interpret displays of their own or others' eye movements. In Experiments 1 and 2, participants observed an image under three different viewing instructions. Then they were shown static or dynamic gaze displays and had to judge whether it was their own or someone else's eye movements and what instruction was reflected. Participants were capable of recognizing the instruction reflected in their own and someone else's gaze display. Instruction recognition was better for dynamic displays, and only this condition yielded above chance performance in recognizing the display as one's own or another person's (Experiments 1 and 2). Experiment 3 revealed that order information in the gaze displays facilitated instruction recognition when transitions between fixated regions distinguish one viewing instruction from another. Implications of these findings are discussed.},
	language = {en},
	number = {1},
	urldate = {2021-02-05},
	journal = {Cognitive Science},
	author = {Wermeskerken, Margot van and Litchfield, Damien and Gog, Tamara van},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12484},
	keywords = {Eye movements, Eye tracking, Gaze display, Gaze interpretation, Gaze recognition},
	pages = {220--252},
}

@misc{noauthor_yarbus_nodate,
	title = {Yarbus: {Eye} movements and vision - {Google} {Scholar}},
	url = {https://scholar.google.com/scholar_lookup?title=Eye%20movements%20and%20vision&publication_year=1967&author=A.%20Yarbus},
	urldate = {2021-02-05},
}

@inproceedings{ma_contrast-based_2003,
	address = {New York, NY, USA},
	series = {{MULTIMEDIA} '03},
	title = {Contrast-based image attention analysis by using fuzzy growing},
	isbn = {978-1-58113-722-4},
	url = {https://doi.org/10.1145/957013.957094},
	doi = {10.1145/957013.957094},
	abstract = {Visual attention analysis provides an alternative methodology to semantic image understanding in many applications such as adaptive content delivery and region-based image retrieval. In this paper, we propose a feasible and fast approach to attention area detection in images based on contrast analysis. The main contributions are threefold: 1) a new saliency map generation method based on local contrast analysis is proposed; 2) by simulating human perception, a fuzzy growing method is used to extract attended areas or objects from the saliency map; and 3) a practicable framework for image attention analysis is presented, which provides three-level attention analysis, i.e., attended view, attended areas and attended points. This framework facilitates visual analysis tools or vision systems to automatically extract attentions from images in a manner like human perception. User study results indicate that the proposed approach is effective and practicable.},
	urldate = {2021-02-04},
	booktitle = {Proceedings of the eleventh {ACM} international conference on {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Ma, Yu-Fei and Zhang, Hong-Jiang},
	month = nov,
	year = {2003},
	keywords = {attention detection, contrast analysis, fuzzy growing, image analysis, visual attention model},
	pages = {374--381},
}

@article{rippel_modeling_2020,
	title = {Modeling the {Distribution} of {Normal} {Data} in {Pre}-{Trained} {Deep} {Features} for {Anomaly} {Detection}},
	url = {http://arxiv.org/abs/2005.14140},
	abstract = {Anomaly Detection (AD) in images is a fundamental computer vision problem and refers to identifying images and image substructures that deviate significantly from the norm. Popular AD algorithms commonly try to learn a model of normality from scratch using task specific datasets, but are limited to semi-supervised approaches employing mostly normal data due to the inaccessibility of anomalies on a large scale combined with the ambiguous nature of anomaly appearance. We follow an alternative approach and demonstrate that deep feature representations learned by discriminative models on large natural image datasets are well suited to describe normality and detect even subtle anomalies in a transfer learning setting. Our model of normality is established by fitting a multivariate Gaussian (MVG) to deep feature representations of classification networks trained on ImageNet using normal data only. By subsequently applying the Mahalanobis distance as the anomaly score we outperform the current state of the art on the public MVTec AD dataset, achieving an AUROC value of \$95.8 {\textbackslash}pm 1.2\$ (mean \${\textbackslash}pm\$ SEM) over all 15 classes. We further investigate why the learned representations are discriminative to the AD task using Principal Component Analysis. We find that the principal components containing little variance in normal data are the ones crucial for discriminating between normal and anomalous instances. This gives a possible explanation to the often sub-par performance of AD approaches trained from scratch using normal data only. By selectively fitting a MVG to these most relevant components only, we are able to further reduce model complexity while retaining AD performance. We also investigate setting the working point by selecting acceptable False Positive Rate thresholds based on the MVG assumption. Code available at https://github.com/ORippler/gaussian-ad-mvtec},
	urldate = {2021-01-25},
	journal = {arXiv:2005.14140 [cs]},
	author = {Rippel, Oliver and Mertens, Patrick and Merhof, Dorit},
	month = oct,
	year = {2020},
	note = {arXiv: 2005.14140},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{haselmann_anomaly_2018,
	title = {Anomaly {Detection} {Using} {Deep} {Learning} {Based} {Image} {Completion}},
	doi = {10.1109/ICMLA.2018.00201},
	abstract = {Automated surface inspection is an important task in many manufacturing industries and often requires machine learning driven solutions. Supervised approaches, however, can be challenging, since it is often difficult to obtain large amounts of labeled training data. In this work, we instead perform one-class unsupervised learning on fault-free samples by training a deep convolutional neural network to complete images whose center regions are cut out. Since the network is trained exclusively on fault-free data, it completes the image patches with a fault-free version of the missing image region. The pixel-wise reconstruction error within the cut out region is an anomaly image which can be used for anomaly detection. Results on surface images of decorated plastic parts demonstrate that this approach is suitable for detection of visible anomalies and moreover surpasses all other tested methods.},
	booktitle = {2018 17th {IEEE} {International} {Conference} on {Machine} {Learning} and {Applications} ({ICMLA})},
	author = {Haselmann, M. and Gruber, D. P. and Tabatabai, P.},
	month = dec,
	year = {2018},
	keywords = {Convolutional neural networks, deep learning, image reconstruction, Training, anomaly detection, Anomaly detection, Anomaly Detection, anomaly image, automated surface inspection, automatic optical inspection, convolutional neural nets, Convolutional Neural Networks, deep convolutional neural network, Defect detection, fault-free data, image completion, Image Completion, image patches, Image reconstruction, Inpainting, Inspection, manufacturing industries, missing image region, One-class, one-class unsupervised learning, pixel-wise reconstruction error, production engineering computing, surface images, Surface Inspection, Surface reconstruction, Task analysis, Unsupervised, unsupervised learning},
	pages = {1237--1242},
}

@article{luo_understanding_2017,
	title = {Understanding the {Effective} {Receptive} {Field} in {Deep} {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1701.04128},
	abstract = {We study characteristics of receptive fields of units in deep convolutional networks. The receptive field size is a crucial issue in many visual tasks, as the output must respond to large enough areas in the image to capture information about large objects. We introduce the notion of an effective receptive field, and show that it both has a Gaussian distribution and only occupies a fraction of the full theoretical receptive field. We analyze the effective receptive field in several architecture designs, and the effect of nonlinear activations, dropout, sub-sampling and skip connections on it. This leads to suggestions for ways to address its tendency to be too small.},
	urldate = {2021-01-22},
	journal = {arXiv:1701.04128 [cs]},
	author = {Luo, Wenjie and Li, Yujia and Urtasun, Raquel and Zemel, Richard},
	month = jan,
	year = {2017},
	note = {arXiv: 1701.04128},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{glorot_understanding_2010,
	title = {Understanding the difficulty of training deep feedforward neural networks},
	booktitle = {Proceedings of the thirteenth international conference on artificial intelligence and statistics},
	author = {Glorot, Xavier and Bengio, Yoshua},
	year = {2010},
	pages = {249--256},
}

@inproceedings{jain_supervised_2007,
	title = {Supervised {Learning} of {Image} {Restoration} with {Convolutional} {Networks}},
	doi = {10.1109/ICCV.2007.4408909},
	abstract = {Convolutional networks have achieved a great deal of success in high-level vision problems such as object recognition. Here we show that they can also be used as a general method for low-level image processing. As an example of our approach, convolutional networks are trained using gradient learning to solve the problem of restoring noisy or degraded images. For our training data, we have used electron microscopic images of neural circuitry with ground truth restorations provided by human experts. On this dataset, Markov random field (MRF), conditional random field (CRF), and anisotropic diffusion algorithms perform about the same as simple thresholding, but superior performance is obtained with a convolutional network containing over 34,000 adjustable parameters. When restored by this convolutional network, the images are clean enough to be used for segmentation, whereas the other approaches fail in this respect. We do not believe that convolutional networks are fundamentally superior to MRFs as a representation for image processing algorithms. On the contrary, the two approaches are closely related. But in practice, it is possible to train complex convolutional networks, while even simple MRF models are hindered by problems with Bayesian learning and inference procedures. Our results suggest that high model complexity is the single most important factor for good performance, and this is possible with convolutional networks.},
	booktitle = {2007 {IEEE} 11th {International} {Conference} on {Computer} {Vision}},
	author = {Jain, V. and Murray, J. F. and Roth, F. and Turaga, S. and Zhigulin, V. and Briggman, K. L. and Helmstaedter, M. N. and Denk, W. and Seung, H. S.},
	month = oct,
	year = {2007},
	note = {ISSN: 2380-7504},
	keywords = {learning (artificial intelligence), computer vision, anisotropic diffusion algorithms, Bayesian learning, Circuit noise, conditional random field, convolutional networks, Degradation, degraded images, electron microscopic images, Electron microscopy, gradient learning, high-level vision problems, Humans, Image processing, image restoration, Image restoration, inference mechanisms, inference procedures, low-level image processing, Markov processes, Markov random field, Markov random fields, neural circuitry, object recognition, Object recognition, supervised learning, Supervised learning, Training data},
	pages = {1--8},
}

@article{feng_ning_toward_2005,
	title = {Toward automatic phenotyping of developing embryos from videos},
	volume = {14},
	issn = {1941-0042},
	doi = {10.1109/TIP.2005.852470},
	abstract = {We describe a trainable system for analyzing videos of developing C. elegans embryos. The system automatically detects, segments, and locates cells and nuclei in microscopic images. The system was designed as the central component of a fully automated phenotyping system. The system contains three modules 1) a convolutional network trained to classify each pixel into five categories: cell wall, cytoplasm, nucleus membrane, nucleus, outside medium; 2) an energy-based model, which cleans up the output of the convolutional network by learning local consistency constraints that must be satisfied by label images; 3) a set of elastic models of the embryo at various stages of development that are matched to the label images.},
	number = {9},
	journal = {IEEE Transactions on Image Processing},
	author = {{Feng Ning} and Delhomme, D. and LeCun, Y. and Piano, F. and Bottou, L. and Barbano, P. E.},
	month = sep,
	year = {2005},
	note = {Conference Name: IEEE Transactions on Image Processing},
	keywords = {Image segmentation, Algorithms, Biological system modeling, Animals, Artificial Intelligence, automatic phenotyping, Bioinformatics, biological techniques, Caenorhabditis elegans, cellular biophysics, convolutional network, Convolutional network, cytoplasm, Embryo, Embryo, Nonmammalian, embryos, energy-based model, Fetal Development, genetics, Genomics, Image Enhancement, Image Interpretation, Computer-Assisted, image segmentation, microscopic images, Microscopy, Microscopy, Phase-Contrast, Microscopy, Video, Motion pictures, nonlinear filter, nucleus membrane, optical microscopy, Pattern Recognition, Automated, Performance analysis, Phenotype, Reproducibility of Results, Sensitivity and Specificity, Videos},
	pages = {1360--1371},
}

@inproceedings{holschneider_real-time_1990,
	address = {Berlin, Heidelberg},
	series = {inverse problems and theoretical imaging},
	title = {A {Real}-{Time} {Algorithm} for {Signal} {Analysis} with the {Help} of the {Wavelet} {Transform}},
	isbn = {978-3-642-75988-8},
	doi = {10.1007/978-3-642-75988-8_28},
	abstract = {The purpose of this paper is to present a real-time algorithm for the analysis of time-varying signals with the help of the wavelet transform. We shall briefly describe this transformation in the following. For more details, we refer to the literature [1].},
	language = {en},
	booktitle = {Wavelets},
	publisher = {Springer},
	author = {Holschneider, M. and Kronland-Martinet, R. and Morlet, J. and Tchamitchian, Ph.},
	editor = {Combes, Jean-Michel and Grossmann, Alexander and Tchamitchian, Philippe},
	year = {1990},
	keywords = {Dilation Parameter, Discrete Wavelet, Graph Algebra, Interpolation Filter, Wavelet Transform},
	pages = {286--297},
}

@inproceedings{glasner_super-resolution_2009,
	title = {Super-resolution from a single image},
	doi = {10.1109/ICCV.2009.5459271},
	abstract = {Methods for super-resolution can be broadly classified into two families of methods: (i) The classical multi-image super-resolution (combining images obtained at subpixel misalignments), and (ii) Example-Based super-resolution (learning correspondence between low and high resolution image patches from a database). In this paper we propose a unified framework for combining these two families of methods. We further show how this combined approach can be applied to obtain super resolution from as little as a single image (with no database or prior examples). Our approach is based on the observation that patches in a natural image tend to redundantly recur many times inside the image, both within the same scale, as well as across different scales. Recurrence of patches within the same image scale (at subpixel misalignments) gives rise to the classical super-resolution, whereas recurrence of patches across different scales of the same image gives rise to example-based super-resolution. Our approach attempts to recover at each pixel its best possible resolution increase based on its patch redundancy within and across scales.},
	booktitle = {2009 {IEEE} 12th {International} {Conference} on {Computer} {Vision}},
	author = {Glasner, D. and Bagon, S. and Irani, M.},
	month = sep,
	year = {2009},
	note = {ISSN: 2380-7504},
	keywords = {Layout, Image reconstruction, Computer science, Computer vision, Equations, example-based super-resolution, Frequency, high resolution image patch, Image databases, image resolution, Image resolution, image scale, low resolution image patch, Mathematics, multiimage super-resolution, natural image, single image, Strontium, subpixel misalignment},
	pages = {349--356},
}

@inproceedings{shocher_zero-shot_2018,
	title = {“{Zero}-{Shot}” {Super}-{Resolution} {Using} {Deep} {Internal} {Learning}},
	url = {https://openaccess.thecvf.com/content_cvpr_2018/html/Shocher_Zero-Shot_Super-Resolution_Using_CVPR_2018_paper.html},
	urldate = {2021-01-12},
	author = {Shocher, Assaf and Cohen, Nadav and Irani, Michal},
	year = {2018},
	pages = {3118--3126},
}

@inproceedings{kovalevsky_digital_1993,
	title = {Digital geometry based on the topology of abstract cell complexes},
	booktitle = {Discrete geometry for computer imagery},
	author = {Kovalevsky, Vladimir A.},
	year = {1993},
	pages = {p259--284},
}

@article{zhang_fast_1984,
	title = {A fast parallel algorithm for thinning digital patterns},
	volume = {27},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/357994.358023},
	doi = {10.1145/357994.358023},
	number = {3},
	urldate = {2020-11-25},
	journal = {Communications of the ACM},
	author = {Zhang, T. Y. and Suen, C. Y.},
	month = mar,
	year = {1984},
	keywords = {parallel algorithm, skeletonization, thinning of digital patterns},
	pages = {236--239},
}

@article{saeed_k3m_2010,
	title = {{K3M}: {A} universal algorithm for image skeletonization and a review of thinning techniques},
	volume = {20},
	shorttitle = {{K3M}},
	url = {https://content.sciendo.com/view/journals/amcs/20/2/article-p317.xml},
	doi = {10.2478/v10006-010-0024-4},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d5e2"{\textgreater}K3M: A universal algorithm for image skeletonization and a review of thinning techniques{\textless}/h2{\textgreater}{\textless}p{\textgreater}This paper aims at three aspects closely related to each other: first, it presents the state of the art in the area of thinning methodologies, by giving descriptions of general ideas of the most significant algorithms with a comparison between them. Secondly, it proposes a new thinning algorithm that presents interesting properties in terms of processing quality and algorithm clarity, enriched with examples. Thirdly, the work considers parallelization issues for intrinsically sequential algorithms of thinning. The main advantage of the suggested algorithm is its universality, which makes it useful and versatile for a variety of applications.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {en},
	number = {2},
	urldate = {2020-11-25},
	journal = {International Journal of Applied Mathematics and Computer Science},
	author = {Saeed, Khalid and Tabędzki, Marek and Rybnik, Mariusz and Adamski, Marcin},
	month = jun,
	year = {2010},
	note = {Publisher: Sciendo
Section: International Journal of Applied Mathematics and Computer Science},
	pages = {317--335},
}

@article{pan_survey_2010,
	title = {A {Survey} on {Transfer} {Learning}},
	volume = {22},
	issn = {1558-2191},
	doi = {10.1109/TKDE.2009.191},
	abstract = {A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research.},
	number = {10},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Pan, Sinno Jialin and Yang, Qiang},
	month = oct,
	year = {2010},
	note = {Conference Name: IEEE Transactions on Knowledge and Data Engineering},
	keywords = {machine learning, Machine learning, unsupervised learning, Training data, data mining, Data mining, data mining., inductive transfer learning, knowledge engineering, Knowledge engineering, knowledge transfer, Knowledge transfer, Labeling, learning by example, Learning systems, Machine learning algorithms, optimisation, Space technology, survey, Testing, transductive transfer learning, Transfer learning, unsupervised transfer learning},
	pages = {1345--1359},
}

@article{grogin_candels_2011,
	title = {{CANDELS}: {THE} {COSMIC} {ASSEMBLY} {NEAR}-{INFRARED} {DEEP} {EXTRAGALACTIC} {LEGACY} {SURVEY}},
	volume = {197},
	issn = {0067-0049},
	shorttitle = {{CANDELS}},
	url = {https://doi.org/10.1088%2F0067-0049%2F197%2F2%2F35},
	doi = {10.1088/0067-0049/197/2/35},
	abstract = {The Cosmic Assembly Near-infrared Deep Extragalactic Legacy Survey (CANDELS) is designed to document the first third of galactic evolution, over the approximate redshift (z) range 8-1.5. It will image {\textgreater}250,000 distant galaxies using three separate cameras on the Hubble Space Telescope, from the mid-ultraviolet to the near-infrared, and will find and measure Type Ia supernovae at z {\textgreater} 1.5 to test their accuracy as standardizable candles for cosmology. Five premier multi-wavelength sky regions are selected, each with extensive ancillary data. The use of five widely separated fields mitigates cosmic variance and yields statistically robust and complete samples of galaxies down to a stellar mass of 109 M ☉ to z ≈ 2, reaching the knee of the ultraviolet luminosity function of galaxies to z ≈ 8. The survey covers approximately 800 arcmin2 and is divided into two parts. The CANDELS/Deep survey (5σ point-source limit H = 27.7 mag) covers ∼125 arcmin2 within Great Observatories Origins Deep Survey (GOODS)-N and GOODS-S. The CANDELS/Wide survey includes GOODS and three additional fields (Extended Groth Strip, COSMOS, and Ultra-deep Survey) and covers the full area to a 5σ point-source limit of H ≳ 27.0 mag. Together with the Hubble Ultra Deep Fields, the strategy creates a three-tiered “wedding-cake” approach that has proven efficient for extragalactic surveys. Data from the survey are nonproprietary and are useful for a wide variety of science investigations. In this paper, we describe the basic motivations for the survey, the CANDELS team science goals and the resulting observational requirements, the field selection and geometry, and the observing design. The Hubble data processing and products are described in a companion paper.},
	language = {en},
	number = {2},
	urldate = {2020-10-15},
	journal = {The Astrophysical Journal Supplement Series},
	author = {Grogin, Norman A. and Kocevski, Dale D. and Faber, S. M. and Ferguson, Henry C. and Koekemoer, Anton M. and Riess, Adam G. and Acquaviva, Viviana and Alexander, David M. and Almaini, Omar and Ashby, Matthew L. N. and Barden, Marco and Bell, Eric F. and Bournaud, Frédéric and Brown, Thomas M. and Caputi, Karina I. and Casertano, Stefano and Cassata, Paolo and Castellano, Marco and Challis, Peter and Chary, Ranga-Ram and Cheung, Edmond and Cirasuolo, Michele and Conselice, Christopher J. and Cooray, Asantha Roshan and Croton, Darren J. and Daddi, Emanuele and Dahlen, Tomas and Davé, Romeel and Mello, Duília F. de and Dekel, Avishai and Dickinson, Mark and Dolch, Timothy and Donley, Jennifer L. and Dunlop, James S. and Dutton, Aaron A. and Elbaz, David and Fazio, Giovanni G. and Filippenko, Alexei V. and Finkelstein, Steven L. and Fontana, Adriano and Gardner, Jonathan P. and Garnavich, Peter M. and Gawiser, Eric and Giavalisco, Mauro and Grazian, Andrea and Guo, Yicheng and Hathi, Nimish P. and Häussler, Boris and Hopkins, Philip F. and Huang, Jia-Sheng and Huang, Kuang-Han and Jha, Saurabh W. and Kartaltepe, Jeyhan S. and Kirshner, Robert P. and Koo, David C. and Lai, Kamson and Lee, Kyoung-Soo and Li, Weidong and Lotz, Jennifer M. and Lucas, Ray A. and Madau, Piero and McCarthy, Patrick J. and McGrath, Elizabeth J. and McIntosh, Daniel H. and McLure, Ross J. and Mobasher, Bahram and Moustakas, Leonidas A. and Mozena, Mark and Nandra, Kirpal and Newman, Jeffrey A. and Niemi, Sami-Matias and Noeske, Kai G. and Papovich, Casey J. and Pentericci, Laura and Pope, Alexandra and Primack, Joel R. and Rajan, Abhijith and Ravindranath, Swara and Reddy, Naveen A. and Renzini, Alvio and Rix, Hans-Walter and Robaina, Aday R. and Rodney, Steven A. and Rosario, David J. and Rosati, Piero and Salimbeni, Sara and Scarlata, Claudia and Siana, Brian and Simard, Luc and Smidt, Joseph and Somerville, Rachel S. and Spinrad, Hyron and Straughn, Amber N. and Strolger, Louis-Gregory and Telford, Olivia and Teplitz, Harry I. and Trump, Jonathan R. and Wel, Arjen van der and Villforth, Carolin and Wechsler, Risa H. and Weiner, Benjamin J. and Wiklind, Tommy and Wild, Vivienne and Wilson, Grant and Wuyts, Stijn and Yan, Hao-Jing and Yun, Min S.},
	month = dec,
	year = {2011},
	note = {Publisher: IOP Publishing},
	pages = {35},
}

@article{tuccillo_deep_2018,
	title = {Deep learning for galaxy surface brightness profile fitting},
	volume = {475},
	issn = {0035-8711},
	url = {https://academic.oup.com/mnras/article/475/1/894/4725057},
	doi = {10.1093/mnras/stx3186},
	abstract = {Abstract.  Numerous ongoing and future large area surveys (e.g. Dark Energy Survey, EUCLID, Large Synoptic Survey Telescope, Wide Field Infrared Survey Telescop},
	language = {en},
	number = {1},
	urldate = {2020-10-15},
	journal = {Monthly Notices of the Royal Astronomical Society},
	author = {Tuccillo, D. and Huertas-Company, M. and Decencière, E. and Velasco-Forero, S. and Domínguez Sánchez, H. and Dimauro, P.},
	month = mar,
	year = {2018},
	note = {Publisher: Oxford Academic},
	pages = {894--909},
}

@inproceedings{heller_imperfect_2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Imperfect {Segmentation} {Labels}: {How} {Much} {Do} {They} {Matter}?},
	isbn = {978-3-030-01364-6},
	shorttitle = {Imperfect {Segmentation} {Labels}},
	doi = {10.1007/978-3-030-01364-6_13},
	abstract = {Labeled datasets for semantic segmentation are imperfect, especially in medical imaging where borders are often subtle or ill-defined. Little work has been done to analyze the effect that label errors have on the performance of segmentation methodologies. Here we present a large-scale study of model performance in the presence of varying types and degrees of error in training data. We trained U-Net, SegNet, and FCN32 several times for liver segmentation with 10 different modes of ground-truth perturbation. Our results show that for each architecture, performance steadily declines with boundary-localized errors, however, U-Net was significantly more robust to jagged boundary errors than the other architectures. We also found that each architecture was very robust to non-boundary-localized errors, suggesting that boundary-localized errors are fundamentally different and more challenging problem than random label errors in a classification setting.},
	language = {en},
	booktitle = {Intravascular {Imaging} and {Computer} {Assisted} {Stenting} and {Large}-{Scale} {Annotation} of {Biomedical} {Data} and {Expert} {Label} {Synthesis}},
	publisher = {Springer International Publishing},
	author = {Heller, Nicholas and Dean, Joshua and Papanikolopoulos, Nikolaos},
	editor = {Stoyanov, Danail and Taylor, Zeike and Balocco, Simone and Sznitman, Raphael and Martel, Anne and Maier-Hein, Lena and Duong, Luc and Zahnd, Guillaume and Demirci, Stefanie and Albarqouni, Shadi and Lee, Su-Lin and Moriconi, Stefano and Cheplygina, Veronika and Mateus, Diana and Trucco, Emanuele and Granger, Eric and Jannin, Pierre},
	year = {2018},
	keywords = {Boundary-localized Errors, Jagged Boundaries, Liver Segmentation, SegNet, Semantic Segmentation Techniques},
	pages = {112--120},
}

@article{oktay_attention_2018,
	title = {Attention {U}-{Net}: {Learning} {Where} to {Look} for the {Pancreas}},
	shorttitle = {Attention {U}-{Net}},
	url = {http://arxiv.org/abs/1804.03999},
	abstract = {We propose a novel attention gate (AG) model for medical imaging that automatically learns to focus on target structures of varying shapes and sizes. Models trained with AGs implicitly learn to suppress irrelevant regions in an input image while highlighting salient features useful for a specific task. This enables us to eliminate the necessity of using explicit external tissue/organ localisation modules of cascaded convolutional neural networks (CNNs). AGs can be easily integrated into standard CNN architectures such as the U-Net model with minimal computational overhead while increasing the model sensitivity and prediction accuracy. The proposed Attention U-Net architecture is evaluated on two large CT abdominal datasets for multi-class image segmentation. Experimental results show that AGs consistently improve the prediction performance of U-Net across different datasets and training sizes while preserving computational efficiency. The code for the proposed architecture is publicly available.},
	urldate = {2020-10-13},
	journal = {arXiv:1804.03999 [cs]},
	author = {Oktay, Ozan and Schlemper, Jo and Folgoc, Loic Le and Lee, Matthew and Heinrich, Mattias and Misawa, Kazunari and Mori, Kensaku and McDonagh, Steven and Hammerla, Nils Y. and Kainz, Bernhard and Glocker, Ben and Rueckert, Daniel},
	month = may,
	year = {2018},
	note = {arXiv: 1804.03999},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{yosinski_how_2014,
	address = {Cambridge, MA, USA},
	series = {{NIPS}'14},
	title = {How transferable are features in deep neural networks?},
	abstract = {Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset.},
	urldate = {2020-10-09},
	booktitle = {Proceedings of the 27th {International} {Conference} on {Neural} {Information} {Processing} {Systems} - {Volume} 2},
	publisher = {MIT Press},
	author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
	month = dec,
	year = {2014},
	pages = {3320--3328},
}

@article{ounkomol_label-free_2018,
	title = {Label-free prediction of three-dimensional fluorescence images from transmitted light microscopy},
	volume = {15},
	issn = {1548-7091},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6212323/},
	doi = {10.1038/s41592-018-0111-2},
	abstract = {Understanding cells as integrated systems is a challenge central to modern biology. The different microscopy approaches used to probe biological organization each present limitations, ultimately restricting insight into unified cellular processes. Fluorescence microscopy can resolve subcellular structure in living cells, but is expensive, slow, and toxic. Here, we present a label-free method for predicting 3D fluorescence directly from transmitted light images and demonstrate its use to generate multi-structure, integrated images.},
	number = {11},
	urldate = {2020-10-05},
	journal = {Nature methods},
	author = {Ounkomol, Chawin and Seshamani, Sharmishtaa and Maleckar, Mary M. and Collman, Forrest and Johnson, Gregory R.},
	month = nov,
	year = {2018},
	pmid = {30224672},
	pmcid = {PMC6212323},
	pages = {917--920},
}

@incollection{lee_simple_2018,
	title = {A {Simple} {Unified} {Framework} for {Detecting} {Out}-of-{Distribution} {Samples} and {Adversarial} {Attacks}},
	url = {http://papers.nips.cc/paper/7947-a-simple-unified-framework-for-detecting-out-of-distribution-samples-and-adversarial-attacks.pdf},
	urldate = {2020-10-01},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 31},
	publisher = {Curran Associates, Inc.},
	author = {Lee, Kimin and Lee, Kibok and Lee, Honglak and Shin, Jinwoo},
	editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
	year = {2018},
	pages = {7167--7177},
}

@inproceedings{bergmann_mvtec_2019,
	title = {{MVTec} {AD} -- {A} {Comprehensive} {Real}-{World} {Dataset} for {Unsupervised} {Anomaly} {Detection}},
	url = {https://openaccess.thecvf.com/content_CVPR_2019/html/Bergmann_MVTec_AD_--_A_Comprehensive_Real-World_Dataset_for_Unsupervised_Anomaly_CVPR_2019_paper.html},
	urldate = {2020-10-01},
	author = {Bergmann, Paul and Fauser, Michael and Sattlegger, David and Steger, Carsten},
	year = {2019},
	pages = {9592--9600},
}

@article{donahue_adversarial_2017,
	title = {Adversarial {Feature} {Learning}},
	url = {http://arxiv.org/abs/1605.09782},
	abstract = {The ability of the Generative Adversarial Networks (GANs) framework to learn generative models mapping from simple latent distributions to arbitrarily complex data distributions has been demonstrated empirically, with compelling results showing that the latent space of such generators captures semantic variation in the data distribution. Intuitively, models trained to predict these semantic latent representations given data may serve as useful feature representations for auxiliary problems where semantics are relevant. However, in their existing form, GANs have no means of learning the inverse mapping -- projecting data back into the latent space. We propose Bidirectional Generative Adversarial Networks (BiGANs) as a means of learning this inverse mapping, and demonstrate that the resulting learned feature representation is useful for auxiliary supervised discrimination tasks, competitive with contemporary approaches to unsupervised and self-supervised feature learning.},
	urldate = {2020-09-30},
	journal = {arXiv:1605.09782 [cs, stat]},
	author = {Donahue, Jeff and Krähenbühl, Philipp and Darrell, Trevor},
	month = apr,
	year = {2017},
	note = {arXiv: 1605.09782},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
}

@article{huang_densely_2018,
	title = {Densely {Connected} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1608.06993},
	abstract = {Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet .},
	urldate = {2020-09-27},
	journal = {arXiv:1608.06993 [cs]},
	author = {Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q.},
	month = jan,
	year = {2018},
	note = {arXiv: 1608.06993},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{chollet_xception_2017,
	title = {Xception: {Deep} {Learning} with {Depthwise} {Separable} {Convolutions}},
	shorttitle = {Xception},
	url = {http://arxiv.org/abs/1610.02357},
	abstract = {We present an interpretation of Inception modules in convolutional neural networks as being an intermediate step in-between regular convolution and the depthwise separable convolution operation (a depthwise convolution followed by a pointwise convolution). In this light, a depthwise separable convolution can be understood as an Inception module with a maximally large number of towers. This observation leads us to propose a novel deep convolutional neural network architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions. We show that this architecture, dubbed Xception, slightly outperforms Inception V3 on the ImageNet dataset (which Inception V3 was designed for), and significantly outperforms Inception V3 on a larger image classification dataset comprising 350 million images and 17,000 classes. Since the Xception architecture has the same number of parameters as Inception V3, the performance gains are not due to increased capacity but rather to a more efficient use of model parameters.},
	urldate = {2020-09-25},
	journal = {arXiv:1610.02357 [cs]},
	author = {Chollet, François},
	month = apr,
	year = {2017},
	note = {arXiv: 1610.02357},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{stallkamp_german_2011,
	title = {The {German} {Traffic} {Sign} {Recognition} {Benchmark}: {A} multi-class classification competition},
	shorttitle = {The {German} {Traffic} {Sign} {Recognition} {Benchmark}},
	doi = {10.1109/IJCNN.2011.6033395},
	abstract = {The “German Traffic Sign Recognition Benchmark” is a multi-category classification competition held at IJCNN 2011. Automatic recognition of traffic signs is required in advanced driver assistance systems and constitutes a challenging real-world computer vision and pattern recognition problem. A comprehensive, lifelike dataset of more than 50,000 traffic sign images has been collected. It reflects the strong variations in visual appearance of signs due to distance, illumination, weather conditions, partial occlusions, and rotations. The images are complemented by several precomputed feature sets to allow for applying machine learning algorithms without background knowledge in image processing. The dataset comprises 43 classes with unbalanced class frequencies. Participants have to classify two test sets of more than 12,500 images each. Here, the results on the first of these sets, which was used in the first evaluation stage of the two-fold challenge, are reported. The methods employed by the participants who achieved the best results are briefly described and compared to human traffic sign recognition performance and baseline results.},
	booktitle = {The 2011 {International} {Joint} {Conference} on {Neural} {Networks}},
	author = {Stallkamp, Johannes and Schlipsing, Marc and Salmen, Jan and Igel, Christian},
	month = jul,
	year = {2011},
	note = {ISSN: 2161-4407},
	keywords = {learning (artificial intelligence), Training, image classification, image processing, computer vision, Humans, Image resolution, Benchmark testing, driver assistance system, driver information systems, German Traffic Sign Recognition Benchmark, Histograms, Image color analysis, Lead, machine learning algorithm, multiclass classification competition, pattern recognition problem, traffic engineering computing},
	pages = {1453--1460},
}

@article{russakovsky_imagenet_2015,
	title = {{ImageNet} {Large} {Scale} {Visual} {Recognition} {Challenge}},
	volume = {115},
	issn = {1573-1405},
	url = {https://doi.org/10.1007/s11263-015-0816-y},
	doi = {10.1007/s11263-015-0816-y},
	abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5 years of the challenge, and propose future directions and improvements.},
	language = {en},
	number = {3},
	urldate = {2020-09-23},
	journal = {International Journal of Computer Vision},
	author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
	month = dec,
	year = {2015},
	pages = {211--252},
}

@inproceedings{werbos_applications_1982,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Control} and {Information} {Sciences}},
	title = {Applications of advances in nonlinear sensitivity analysis},
	isbn = {978-3-540-39459-4},
	doi = {10.1007/BFb0006203},
	abstract = {The following paper summarizes the major properties and applications of a collection of algorithms involving differentiation and optimization at minimum cost. The areas of application include the sensitivity analysis of models, new work in statistical or econometric estimation, optimization, artificial intelligence and neuron modelling. The details, references and derivations can be obtained by requesting „Sensitivity Analysis Methods for Nonlinear Systems“ from Forecast Analysis and Evaluation Team, Quality Assurance, OSS/EIA, Room 7413, Department of Energy, Washington, DC 20461.},
	language = {en},
	booktitle = {System {Modeling} and {Optimization}},
	publisher = {Springer},
	author = {Werbos, Paul J.},
	editor = {Drenick, R. F. and Kozin, F.},
	year = {1982},
	keywords = {Deterministic Optimization, Energy Information Administration, Evaluation Team, Sensitivity Analysis Method, Stochastic Optimization},
	pages = {762--770},
}

@book{hawkins_identification_1980,
	title = {Identification of outliers},
	volume = {11},
	publisher = {Springer},
	author = {Hawkins, Douglas M.},
	year = {1980},
}

@article{huang_epithelium-stroma_2017,
	title = {Epithelium-{Stroma} {Classification} via {Convolutional} {Neural} {Networks} and {Unsupervised} {Domain} {Adaptation} in {Histopathological} {Images}},
	volume = {21},
	issn = {2168-2208},
	doi = {10.1109/JBHI.2017.2691738},
	abstract = {Epithelium-stroma classification is a necessary preprocessing step in histopathological image analysis. Current deep learning based recognition methods for histology data require collection of large volumes of labeled data in order to train a new neural network when there are changes to the image acquisition procedure. However, it is extremely expensive for pathologists to manually label sufficient volumes of data for each pathology study in a professional manner, which results in limitations in real-world applications. A very simple but effective deep learning method, that introduces the concept of unsupervised domain adaptation to a simple convolutional neural network (CNN), has been proposed in this paper. Inspired by transfer learning, our paper assumes that the training data and testing data follow different distributions, and there is an adaptation operation to more accurately estimate the kernels in CNN in feature extraction, in order to enhance performance by transferring knowledge from labeled data in source domain to unlabeled data in target domain. The model has been evaluated using three independent public epithelium-stroma datasets by cross-dataset validations. The experimental results demonstrate that for epithelium-stroma classification, the proposed framework outperforms the state-of-the-art deep neural network model, and it also achieves better performance than other existing deep domain adaptation methods. The proposed model can be considered to be a better option for real-world applications in histopathological image analysis, since there is no longer a requirement for large-scale labeled data in each specified domain.},
	number = {6},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Huang, Yue and Zheng, Han and Liu, Chi and Ding, Xinghao and Rohde, Gustavo K.},
	month = nov,
	year = {2017},
	keywords = {Convolutional neural networks, Algorithms, Neural networks, Machine learning, Training, feature extraction, image classification, Feature extraction, Image analysis, neural nets, unsupervised learning, Humans, Adaptation models, biomedical optical imaging, Breast Neoplasms, cancer, Connective Tissue, convolutional neural networks, deep learning method, domain adaptation, Epithelium, epithelium-stroma classification, epithelium-stroma dataset, Female, Histocytochemistry, histology data, histopathological image analysis, image acquisition procedure, Image Processing, Computer-Assisted, Kernel, Machine Learning, medical image processing, Neural Networks (Computer), recognition method, transfer learning, unsupervised domain adaptation},
	pages = {1625--1632},
}

@inproceedings{ren_adversarial_2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Adversarial {Domain} {Adaptation} for {Classification} of {Prostate} {Histopathology} {Whole}-{Slide} {Images}},
	isbn = {978-3-030-00934-2},
	doi = {10.1007/978-3-030-00934-2_23},
	abstract = {Automatic and accurate Gleason grading of histopathology tissue slides is crucial for prostate cancer diagnosis, treatment, and prognosis. Usually, histopathology tissue slides from different institutions show heterogeneous appearances because of different tissue preparation and staining procedures, thus the predictable model learned from one domain may not be applicable to a new domain directly. Here we propose to adopt unsupervised domain adaptation to transfer the discriminative knowledge obtained from the source domain to the target domain without requiring labeling of images at the target domain. The adaptation is achieved through adversarial training to find an invariant feature space along with the proposed Siamese architecture on the target domain to add a regularization that is appropriate for the whole-slide images. We validate the method on two prostate cancer datasets and obtain significant classification improvement of Gleason scores as compared with the baseline models.},
	language = {en},
	booktitle = {Medical {Image} {Computing} and {Computer} {Assisted} {Intervention} – {MICCAI} 2018},
	publisher = {Springer International Publishing},
	author = {Ren, Jian and Hacihaliloglu, Ilker and Singer, Eric A. and Foran, David J. and Qi, Xin},
	editor = {Frangi, Alejandro F. and Schnabel, Julia A. and Davatzikos, Christos and Alberola-López, Carlos and Fichtinger, Gabor},
	year = {2018},
	pages = {201--209},
}

@inproceedings{xiao_new_2019,
	title = {A {New} {Color} {Augmentation} {Method} for {Deep} {Learning} {Segmentation} of {Histological} {Images}},
	doi = {10.1109/ISBI.2019.8759591},
	abstract = {This paper addresses the problem of labeled data insufficiency in neural network training for semantic segmentation of color-stained histological images acquired via Whole Slide Imaging. It proposes an efficient image augmentation method to alleviate the demand for a large amount of labeled data and improve the network's generalization capacity. Typical image augmentation in bioimaging involves geometric transformation. Here, we propose a new image augmentation technique by combining the structure of one image with the color appearance of another image to construct augmented images on-the-fly for each training iteration. We show that it improves performance in the segmentation of histological images of human skin, and also offers better results when combined with geometric transformation.},
	booktitle = {2019 {IEEE} 16th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI} 2019)},
	author = {Xiao, Yang and Decencière, Etienne and Velasco-Forero, Santiago and Burdin, Hélène and Bornschlögl, Thomas and Bernerd, Françoise and Warrick, Emilie and Baldeweck, Thérèse},
	month = apr,
	year = {2019},
	note = {ISSN: 1945-7928},
	keywords = {deep learning, Image segmentation, learning (artificial intelligence), Training, Skin, neural nets, image segmentation, Image color analysis, medical image processing, Agriculture, biological tissues, color appearance, color augmentation, color transfer, color-stained histological images, color-stained slide, Databases, Deep learning, deep learning segmentation, Fontana Masson, geometric transformation, geometry, histopathology, human skin, image augmentation, image colour analysis, neural network training, segmentation, semantic segmentation, skin, transforms, whole slide imaging},
	pages = {886--890},
}

@inproceedings{magee_colour_2009,
	title = {Colour normalisation in digital histopathology images},
	volume = {100},
	booktitle = {Proc {Optical} {Tissue} {Image} analysis in {Microscopy}, {Histopathology} and {Endoscopy} ({MICCAI} {Workshop})},
	publisher = {Citeseer},
	author = {Magee, Derek and Treanor, Darren and Crellin, Doreen and Shires, Mike and Smith, Katherine and Mohee, Kevin and Quirke, Philip},
	year = {2009},
	pages = {100--111},
}

@article{ruifrok_quantification_2001,
	title = {Quantification of histochemical staining by color deconvolution},
	volume = {23},
	number = {4},
	journal = {Analytical and quantitative cytology and histology},
	author = {Ruifrok, Arnout C. and Johnston, Dennis A.},
	year = {2001},
	pages = {291--299},
}

@article{azevedo_tosta_computational_2019,
	title = {Computational normalization of {H}\&{E}-stained histological images: {Progress}, challenges and future potential},
	volume = {95},
	issn = {0933-3657},
	shorttitle = {Computational normalization of {H}\&{E}-stained histological images},
	url = {http://www.sciencedirect.com/science/article/pii/S093336571830424X},
	doi = {10.1016/j.artmed.2018.10.004},
	abstract = {Different types of cancer can be diagnosed with the analysis of histological samples stained with hematoxylin–eosin (H\&E). Through this stain, it is possible to identify the architecture of tissue components and analyze cellular morphological aspects that are essential for cancer diagnosis. However, preparation and digitization of histological samples can lead to color variations that influence the performance of segmentation and classification algorithms in histological image analysis systems. Among the determinant factors of these color variations are different staining time, concentration and pH of the solutions, and the use of different digitization systems. This has motivated the development of normalization algorithms of histological images for their color adjustments. These methods are designed to guarantee that biological samples are not altered and artifacts are not introduced in the images, thus compromising the lesions diagnosis. In this context, normalization techniques are proposed to minimize color variations in histological images, and they are topics covered by important studies in the literature. In this proposal, it is presented a detailed study of the state of art of computational normalization of H\&E-stained histological images, highlighting the main contributions and limitations of correlated works. Besides, the evaluation of normalization methods published in the literature are depicted and possible directions for new methods are described.},
	language = {en},
	urldate = {2020-01-27},
	journal = {Artificial Intelligence in Medicine},
	author = {Azevedo Tosta, Thaína A. and de Faria, Paulo Rogério and Neves, Leandro Alves and do Nascimento, Marcelo Zanchetta},
	month = apr,
	year = {2019},
	keywords = {Color corrections, Hematoxylin–eosin, Histological image analysis, Normalization},
	pages = {118--132},
}

@article{reinhard_color_2001,
	title = {Color transfer between images},
	volume = {21},
	issn = {02721716},
	url = {http://ieeexplore.ieee.org/document/946629/},
	doi = {10.1109/38.946629},
	number = {4},
	urldate = {2020-01-27},
	journal = {IEEE Computer Graphics and Applications},
	author = {Reinhard, E. and Adhikhmin, M. and Gooch, B. and Shirley, P.},
	month = aug,
	year = {2001},
	pages = {34--41},
}

@inproceedings{akcay_ganomaly:_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{GANomaly}: {Semi}-supervised {Anomaly} {Detection} via {Adversarial} {Training}},
	isbn = {978-3-030-20893-6},
	shorttitle = {{GANomaly}},
	doi = {10.1007/978-3-030-20893-6_39},
	abstract = {Anomaly detection is a classical problem in computer vision, namely the determination of the normal from the abnormal when datasets are highly biased towards one class (normal) due to the insufficient sample size of the other class (abnormal). While this can be addressed as a supervised learning problem, a significantly more challenging problem is that of detecting the unknown/unseen anomaly case that takes us instead into the space of a one-class, semi-supervised learning paradigm. We introduce such a novel anomaly detection model, by using a conditional generative adversarial network that jointly learns the generation of high-dimensional image space and the inference of latent space. Employing encoder-decoder-encoder sub-networks in the generator network enables the model to map the input image to a lower dimension vector, which is then used to reconstruct the generated output image. The use of the additional encoder network maps this generated image to its latent representation. Minimizing the distance between these images and the latent vectors during training aids in learning the data distribution for the normal samples. As a result, a larger distance metric from this learned data distribution at inference time is indicative of an outlier from that distribution—an anomaly. Experimentation over several benchmark datasets, from varying domains, shows the model efficacy and superiority over previous state-of-the-art approaches.},
	language = {en},
	booktitle = {Computer {Vision} – {ACCV} 2018},
	publisher = {Springer International Publishing},
	author = {Akcay, Samet and Atapour-Abarghouei, Amir and Breckon, Toby P.},
	editor = {Jawahar, C. V. and Li, Hongdong and Mori, Greg and Schindler, Konrad},
	year = {2019},
	keywords = {Anomaly detection, Generative Adversarial Networks, Semi-supervised learning, X-ray security imagery},
	pages = {622--637},
}

@article{zenati_efficient_2018,
	title = {Efficient {GAN}-{Based} {Anomaly} {Detection}},
	volume = {abs/1802.06222},
	url = {http://arxiv.org/abs/1802.06222},
	urldate = {2019-12-04},
	journal = {CoRR},
	author = {Zenati, Houssam and Foo, Chuan Sheng and Lecouat, Bruno and Manek, Gaurav and Chandrasekhar, Vijay Ramaseshan},
	year = {2018},
}

@inproceedings{basharat_learning_2008,
	title = {Learning object motion patterns for anomaly detection and improved object detection},
	doi = {10.1109/CVPR.2008.4587510},
	abstract = {We present a novel framework for learning patterns of motion and sizes of objects in static camera surveillance. The proposed method provides a new higher-level layer to the traditional surveillance pipeline for anomalous event detection and scene model feedback. Pixel level probability density functions (pdfs) of appearance have been used for background modelling in the past, but modelling pixel level pdfs of object speed and size from the tracks is novel. Each pdf is modelled as a multivariate Gaussian mixture model (GMM) of the motion (destination location \& transition time) and the size (width \& height) parameters of the objects at that location. Output of the tracking module is used to perform unsupervised EM-based learning of every GMM. We have successfully used the proposed scene model to detect local as well as global anomalies in object tracks. We also show the use of this scene model to improve object detection through pixel-level parameter feedback of the minimum object size and background learning rate. Most object path modelling approaches first cluster the tracks into major paths in the scene, which can be a source of error. We avoid this by building local pdfs that capture a variety of tracks which are passing through them. Qualitative and quantitative analysis of actual surveillance videos proved the effectiveness of the proposed approach.},
	booktitle = {2008 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Basharat, Arslan and Gritai, Alexei and Shah, Mubarak},
	month = jun,
	year = {2008},
	note = {ISSN: 1063-6919},
	keywords = {Pipelines, object detection, Object detection, Layout, anomaly detection, Videos, image resolution, actual surveillance videos, background modelling, Cameras, Event detection, Feedback, Gaussian processes, image motion analysis, Motion detection, multivariate Gaussian mixture model, object motion patterns, object path modelling, pixel level probability density functions, pixel-level parameter feedback, Probability density function, scene model feedback, static camera surveillance, Surveillance, video signal processing, video surveillance},
	pages = {1--8},
}

@article{chandola_anomaly_2009,
	title = {Anomaly {Detection}: {A} {Survey}},
	volume = {41},
	issn = {0360-0300},
	shorttitle = {Anomaly {Detection}},
	url = {http://doi.acm.org/10.1145/1541880.1541882},
	doi = {10.1145/1541880.1541882},
	abstract = {Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with.},
	number = {3},
	urldate = {2019-11-26},
	journal = {ACM Comput. Surv.},
	author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
	month = jul,
	year = {2009},
	keywords = {Anomaly detection, outlier detection},
	pages = {15:1--15:58},
}

@misc{noauthor_imperfect_nodate,
	title = {Imperfect {Segmentation} {Labels}: {How} {Much} {Do} {They} {Matter}? {\textbar} {SpringerLink}},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-01364-6_13},
	urldate = {2019-10-24},
}

@inproceedings{ganaye_towards_2018,
	title = {Towards integrating spatial localization in convolutional neural networks for brain image segmentation},
	booktitle = {2018 {IEEE} 15th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI} 2018)},
	publisher = {IEEE},
	author = {Ganaye, Pierre-Antoine and Sdika, Michaël and Benoit-Cattin, Hugues},
	year = {2018},
	pages = {621--625},
}

@inproceedings{ganaye_semi-supervised_2018,
	title = {Semi-supervised learning for segmentation under semantic constraint},
	booktitle = {International {Conference} on {Medical} {Image} {Computing} and {Computer}-{Assisted} {Intervention}},
	publisher = {Springer},
	author = {Ganaye, Pierre-Antoine and Sdika, Michaël and Benoit-Cattin, Hugues},
	year = {2018},
	pages = {595--602},
}

@inproceedings{lee_roomnet:_2017,
	title = {{RoomNet}: {End}-{To}-{End} {Room} {Layout} {Estimation}},
	shorttitle = {{RoomNet}},
	url = {http://openaccess.thecvf.com/content_iccv_2017/html/Lee_RoomNet_End-To-End_Room_ICCV_2017_paper.html},
	urldate = {2019-06-13},
	author = {Lee, Chen-Yu and Badrinarayanan, Vijay and Malisiewicz, Tomasz and Rabinovich, Andrew},
	year = {2017},
	pages = {4865--4874},
}

@inproceedings{liu_intriguing_2018,
	title = {An intriguing failing of convolutional neural networks and the coordconv solution},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Liu, Rosanne and Lehman, Joel and Molino, Piero and Such, Felipe Petroski and Frank, Eric and Sergeev, Alex and Yosinski, Jason},
	year = {2018},
	pages = {9605--9616},
}

@inproceedings{mondal_morphological_2019,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Morphological {Networks} for {Image} {De}-raining},
	isbn = {978-3-030-14085-4},
	abstract = {Mathematical morphological methods have successfully been applied to filter out (emphasize or remove) different structures of an image. However, it is argued that these methods could be suitable for the task only if the type and order of the filter(s) as well as the shape and size of operator kernel are designed properly. Thus the existing filtering operators are problem (instance) specific and are designed by the domain experts. In this work we propose a morphological network that emulates classical morphological filtering consisting of a series of erosion and dilation operators with trainable structuring elements. We evaluate the proposed network for image de-raining task where the SSIM and mean absolute error (MAE) loss corresponding to predicted and ground-truth clean image is back-propagated through the network to train the structuring elements. We observe that a single morphological network can de-rain an image with any arbitrary shaped rain-droplets and achieves similar performance with the contemporary CNNs for this task with a fraction of trainable parameters (network size). The proposed morphological network (MorphoN) is not designed specifically for de-raining and can readily be applied to similar filtering/noise cleaning tasks. The source code can be found here https://github.com/ranjanZ/2D-Morphological-Network.},
	language = {en},
	booktitle = {Discrete {Geometry} for {Computer} {Imagery}},
	publisher = {Springer International Publishing},
	author = {Mondal, Ranjan and Purkait, Pulak and Santra, Sanchayan and Chanda, Bhabatosh},
	editor = {Couprie, Michel and Cousty, Jean and Kenmochi, Yukiko and Mustafa, Nabil},
	year = {2019},
	keywords = {Mathematical morphology, Optimization, Image filtering, Morphological network},
	pages = {262--275},
}

@article{chandola_anomaly_2009-1,
	title = {Anomaly {Detection}: {A} {Survey}},
	volume = {41},
	issn = {0360-0300},
	shorttitle = {Anomaly {Detection}},
	url = {http://doi.acm.org/10.1145/1541880.1541882},
	doi = {10.1145/1541880.1541882},
	abstract = {Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with.},
	number = {3},
	urldate = {2019-05-17},
	journal = {ACM Comput. Surv.},
	author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
	month = jul,
	year = {2009},
	keywords = {Anomaly detection, outlier detection},
	pages = {15:1--15:58},
}

@article{markou_novelty_2003,
	title = {Novelty detection: a review—part 2:: neural network based approaches},
	volume = {83},
	issn = {0165-1684},
	shorttitle = {Novelty detection},
	url = {http://www.sciencedirect.com/science/article/pii/S0165168403002032},
	doi = {10.1016/j.sigpro.2003.07.019},
	abstract = {Novelty detection is the identification of new or unknown data or signal that a machine learning system is not aware of during training. In this paper we focus on neural network-based approaches for novelty detection. Statistical approaches are covered in Part 1 paper.},
	number = {12},
	urldate = {2019-05-17},
	journal = {Signal Processing},
	author = {Markou, Markos and Singh, Sameer},
	month = dec,
	year = {2003},
	keywords = {Neural networks, ART, MLP, Network-based approaches, Novelty detection, RBF},
	pages = {2499--2521},
}

@article{markou_novelty_2003-1,
	title = {Novelty detection: a review—part 1: statistical approaches},
	volume = {83},
	issn = {0165-1684},
	shorttitle = {Novelty detection},
	url = {http://www.sciencedirect.com/science/article/pii/S0165168403002020},
	doi = {10.1016/j.sigpro.2003.07.018},
	abstract = {Novelty detection is the identification of new or unknown data or signal that a machine learning system is not aware of during training. Novelty detection is one of the fundamental requirements of a good classification or identification system since sometimes the test data contains information about objects that were not known at the time of training the model. In this paper we provide state-of-the-art review in the area of novelty detection based on statistical approaches. The second part paper details novelty detection using neural networks. As discussed, there are a multitude of applications where novelty detection is extremely important including signal processing, computer vision, pattern recognition, data mining, and robotics.},
	number = {12},
	urldate = {2019-05-17},
	journal = {Signal Processing},
	author = {Markou, Markos and Singh, Sameer},
	month = dec,
	year = {2003},
	keywords = {Clustering, Gaussian mixture models, Hidden Markov models, KNN, Novelty detection review, Parzen density estimation, Statistical approaches, String matching},
	pages = {2481--2497},
}

@article{pimentel_review_2014,
	title = {A review of novelty detection},
	volume = {99},
	issn = {0165-1684},
	url = {http://www.sciencedirect.com/science/article/pii/S016516841300515X},
	doi = {10.1016/j.sigpro.2013.12.026},
	abstract = {Novelty detection is the task of classifying test data that differ in some respect from the data that are available during training. This may be seen as “one-class classification”, in which a model is constructed to describe “normal” training data. The novelty detection approach is typically used when the quantity of available “abnormal” data is insufficient to construct explicit models for non-normal classes. Application includes inference in datasets from critical systems, where the quantity of available normal data is very large, such that “normality” may be accurately modelled. In this review we aim to provide an updated and structured investigation of novelty detection research papers that have appeared in the machine learning literature during the last decade.},
	urldate = {2019-05-17},
	journal = {Signal Processing},
	author = {Pimentel, Marco A. F. and Clifton, David A. and Clifton, Lei and Tarassenko, Lionel},
	month = jun,
	year = {2014},
	keywords = {Machine learning, Novelty detection, One-class classification},
	pages = {215--249},
}

@inproceedings{carrera_detecting_2015,
	title = {Detecting anomalous structures by convolutional sparse models},
	doi = {10.1109/IJCNN.2015.7280790},
	abstract = {We address the problem of detecting anomalies in images, specifically that of detecting regions characterized by structures that do not conform those of normal images. In the proposed approach we exploit convolutional sparse models to learn a dictionary of filters from a training set of normal images. These filters capture the structure of normal images and are leveraged to quantitatively assess whether regions of a test image are normal or anomalous. Each test image is at first encoded with respect to the learned dictionary, yielding sparse coefficient maps, and then analyzed by computing indicator vectors that assess the conformance of local image regions with the learned filters. Anomalies are then detected by identifying outliers in these indicators. Our experiments demonstrate that a convolutional sparse model provides better anomaly-detection performance than an equivalent method based on standard patch-based sparsity. Most importantly, our results highlight that monitoring the local group sparsity, namely the spread of nonzero coefficients across different maps, is essential for detecting anomalous regions.},
	booktitle = {2015 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Carrera, D. and Boracchi, G. and Foi, A. and Wohlberg, B.},
	month = jul,
	year = {2015},
	keywords = {image processing, anomaly detection, Anomaly Detection, anomalous structure, anomaly-detection performance, computing indicator vector, convolution, convolutional sparse model, Convolutional Sparse Models, Deconvolutional Networks, filtering theory, learned dictionary, learned filter, local image region, nonzero coefficient, normal image, sparse coefficient map, standard patch-based sparsity},
	pages = {1--8},
}

@article{ronse_algebraic_1991,
	title = {The algebraic basis of mathematical morphology: {II}. {Openings} and closings},
	volume = {54},
	issn = {1049-9660},
	shorttitle = {The algebraic basis of mathematical morphology},
	url = {http://www.sciencedirect.com/science/article/pii/1049966091900762},
	doi = {10.1016/1049-9660(91)90076-2},
	abstract = {This paper is the sequel to a previous paper (Part I) where we introduced and investigated an abstract algebraic framework for mathematical morphology. The main assumption is that the object space is a complete lattice. Of interest are all (increasing) operators which are invariant under a given abelian group of automorphisms on the lattice. In Part I we were mainly concerned with the basic operations dilation and erosion. In this paper we concentrate on openings and closings, which are very special classes of idempotent operators. Much attention is given to specific methods for building openings and closings in an economical way; in particular we study annular openings and inf-overfilters. We also consider the possibility of generating new openings by iteration of anti-extensive operators. Some examples illustrate the abstract theory.},
	number = {1},
	urldate = {2019-04-25},
	journal = {CVGIP: Image Understanding},
	author = {Ronse, C. and Heijmans, H. J. A. M.},
	month = jul,
	year = {1991},
	pages = {74--97},
}

@article{heijmans_algebraic_1990,
	title = {The algebraic basis of mathematical morphology {I}. {Dilations} and erosions},
	volume = {50},
	issn = {0734-189X},
	url = {http://www.sciencedirect.com/science/article/pii/0734189X9090148O},
	doi = {10.1016/0734-189X(90)90148-O},
	abstract = {Mathematical morphology is a theory of image transformations and functionals deriving its tools from set theory and integral geometry. This paper deals with a general algebraic approach which both reveals the mathematical structure of morphological operations and unifies several examples into one framework. The main assumption is that the object space is a complete lattice and that the transformations of interest are invariant under a given abelian group of automorphisms on that lattice. It turns out that the basic operations called dilation and erosion are adjoints of each other in a very specific lattice sense and can be completely characterized if the automorphism group is assumed to be transitive on a sup-generating subset of the complete lattice. The abstract theory is illustrated by a large variety of examples and applications.},
	number = {3},
	urldate = {2019-04-25},
	journal = {Computer Vision, Graphics, and Image Processing},
	author = {Heijmans, H. J. A. M and Ronse, C},
	month = jun,
	year = {1990},
	pages = {245--295},
}

@article{diaz-pinto_cnns_2019,
	title = {{CNNs} for automatic glaucoma assessment using fundus images: an extensive validation},
	volume = {18},
	issn = {1475-925X},
	shorttitle = {{CNNs} for automatic glaucoma assessment using fundus images},
	url = {https://doi.org/10.1186/s12938-019-0649-y},
	doi = {10.1186/s12938-019-0649-y},
	abstract = {BackgroundMost current algorithms for automatic glaucoma assessment using fundus images rely on handcrafted features based on segmentation, which are affected by the performance of the chosen segmentation method and the extracted features. Among other characteristics, convolutional neural networks (CNNs) are known because of their ability to learn highly discriminative features from raw pixel intensities.MethodsIn this paper, we employed five different ImageNet-trained models (VGG16, VGG19, InceptionV3, ResNet50 and Xception) for automatic glaucoma assessment using fundus images. Results from an extensive validation using cross-validation and cross-testing strategies were compared with previous works in the literature.ResultsUsing five public databases (1707 images), an average AUC of 0.9605 with a 95\% confidence interval of 95.92–97.07\%, an average specificity of 0.8580 and an average sensitivity of 0.9346 were obtained after using the Xception architecture, significantly improving the performance of other state-of-the-art works. Moreover, a new clinical database, ACRIMA, has been made publicly available, containing 705 labelled images. It is composed of 396 glaucomatous images and 309 normal images, which means, the largest public database for glaucoma diagnosis. The high specificity and sensitivity obtained from the proposed approach are supported by an extensive validation using not only the cross-validation strategy but also the cross-testing validation on, to the best of the authors’ knowledge, all publicly available glaucoma-labelled databases.ConclusionsThese results suggest that using ImageNet-trained models is a robust alternative for automatic glaucoma screening system. All images, CNN weights and software used to fine-tune and test the five CNNs are publicly available, which could be used as a testbed for further comparisons.},
	language = {en},
	number = {1},
	urldate = {2019-03-25},
	journal = {BioMedical Engineering OnLine},
	author = {Diaz-Pinto, Andres and Morales, Sandra and Naranjo, Valery and Köhler, Thomas and Mossi, Jose M. and Navea, Amparo},
	month = mar,
	year = {2019},
	keywords = {ACRIMA database, CNN, Fine-tuning, Fundus images, Glaucoma},
	pages = {29},
}

@article{milletari_v-net:_2016,
	title = {V-{Net}: {Fully} {Convolutional} {Neural} {Networks} for {Volumetric} {Medical} {Image} {Segmentation}},
	shorttitle = {V-{Net}},
	url = {http://arxiv.org/abs/1606.04797},
	abstract = {Convolutional Neural Networks (CNNs) have been recently employed to solve problems from both the computer vision and medical image analysis fields. Despite their popularity, most approaches are only able to process 2D images while most medical data used in clinical practice consists of 3D volumes. In this work we propose an approach to 3D image segmentation based on a volumetric, fully convolutional, neural network. Our CNN is trained end-to-end on MRI volumes depicting prostate, and learns to predict segmentation for the whole volume at once. We introduce a novel objective function, that we optimise during training, based on Dice coefficient. In this way we can deal with situations where there is a strong imbalance between the number of foreground and background voxels. To cope with the limited number of annotated volumes available for training, we augment the data applying random non-linear transformations and histogram matching. We show in our experimental evaluation that our approach achieves good performances on challenging test data while requiring only a fraction of the processing time needed by other previous methods.},
	urldate = {2019-03-22},
	journal = {arXiv:1606.04797 [cs]},
	author = {Milletari, Fausto and Navab, Nassir and Ahmadi, Seyed-Ahmad},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.04797},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{long_fully_2014,
	title = {Fully {Convolutional} {Networks} for {Semantic} {Segmentation}},
	url = {http://arxiv.org/abs/1411.4038},
	abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build "fully convolutional" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a novel architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20\% relative improvement to 62.2\% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes one third of a second for a typical image.},
	urldate = {2019-03-22},
	journal = {arXiv:1411.4038 [cs]},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	month = nov,
	year = {2014},
	note = {arXiv: 1411.4038},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{jegou_one_2016,
	title = {The {One} {Hundred} {Layers} {Tiramisu}: {Fully} {Convolutional} {DenseNets} for {Semantic} {Segmentation}},
	shorttitle = {The {One} {Hundred} {Layers} {Tiramisu}},
	url = {http://arxiv.org/abs/1611.09326},
	abstract = {State-of-the-art approaches for semantic image segmentation are built on Convolutional Neural Networks (CNNs). The typical segmentation architecture is composed of (a) a downsampling path responsible for extracting coarse semantic features, followed by (b) an upsampling path trained to recover the input image resolution at the output of the model and, optionally, (c) a post-processing module (e.g. Conditional Random Fields) to refine the model predictions. Recently, a new CNN architecture, Densely Connected Convolutional Networks (DenseNets), has shown excellent results on image classification tasks. The idea of DenseNets is based on the observation that if each layer is directly connected to every other layer in a feed-forward fashion then the network will be more accurate and easier to train. In this paper, we extend DenseNets to deal with the problem of semantic segmentation. We achieve state-of-the-art results on urban scene benchmark datasets such as CamVid and Gatech, without any further post-processing module nor pretraining. Moreover, due to smart construction of the model, our approach has much less parameters than currently published best entries for these datasets. Code to reproduce the experiments is available here : https://github.com/SimJeg/FC-DenseNet/blob/master/train.py},
	urldate = {2019-03-22},
	journal = {arXiv:1611.09326 [cs]},
	author = {Jégou, Simon and Drozdzal, Michal and Vazquez, David and Romero, Adriana and Bengio, Yoshua},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.09326},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{drozdzal_importance_2016,
	title = {The {Importance} of {Skip} {Connections} in {Biomedical} {Image} {Segmentation}},
	url = {http://arxiv.org/abs/1608.04117},
	abstract = {In this paper, we study the influence of both long and short skip connections on Fully Convolutional Networks (FCN) for biomedical image segmentation. In standard FCNs, only long skip connections are used to skip features from the contracting path to the expanding path in order to recover spatial information lost during downsampling. We extend FCNs by adding short skip connections, that are similar to the ones introduced in residual networks, in order to build very deep FCNs (of hundreds of layers). A review of the gradient flow confirms that for a very deep FCN it is beneficial to have both long and short skip connections. Finally, we show that a very deep FCN can achieve near-to-state-of-the-art results on the EM dataset without any further post-processing.},
	urldate = {2019-03-22},
	journal = {arXiv:1608.04117 [cs]},
	author = {Drozdzal, Michal and Vorontsov, Eugene and Chartrand, Gabriel and Kadoury, Samuel and Pal, Chris},
	month = aug,
	year = {2016},
	note = {arXiv: 1608.04117},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{javaid_semantic_2019,
	title = {Semantic segmentation of computed tomography for radiotherapy with deep learning: compensating insufficient annotation quality using contour augmentation},
	volume = {10949},
	shorttitle = {Semantic segmentation of computed tomography for radiotherapy with deep learning},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10949/109492P/Semantic-segmentation-of-computed-tomography-for-radiotherapy-with-deep-learning/10.1117/12.2512461.short},
	doi = {10.1117/12.2512461},
	abstract = {In radiotherapy treatment planning, manual annotation of organs-at-risk and target volumes is a difficult and time-consuming task, prone to intra and inter-observer variabilities. Deep learning networks (DLNs) are gaining worldwide attention to automate such annotative tasks because of their ability to capture data hierarchy. However, for better performance DLNs require large number of data samples whereas annotated medical data is scarce. To remedy this, data augmentation is used to increase the training data for DLNs that enables robust learning by incorporating spatial/translational invariance into the training phase. Importantly, performance of DLNs is highly dependent on the ground truth (GT) quality: if manual annotation is not accurate enough, the network cannot learn better than the annotated example. This highlights the need to compensate for possibly insufficient GT quality using augmentation, i.e., by providing more GTs per image, in order to improve performance of DLNs. In this work, small random alterations were applied to GT and each altered GT was considered as an additional annotation. Contour augmentation was used to train a dilated U-Net in multiple GTs per image setting, which was tested on a pelvic CT dataset acquired from 67 patients to segment bladder and rectum in a multi-class segmentation setting. By using contour augmentation (coupled with data augmentation), the network learnt better than with data augmentation only, as it was able to correct slightly offset contours in GT. The segmentation results produced were quantified using spatial overlap, distance-based and probabilistic measures. The Dice score for bladder and rectum are reported as 0.88\&plusmn;0.19 and 0.89\&plusmn;0.04, whereas the average symmetric surface distance are 0.22 \&plusmn; 0.09 mm and 0.09 \&plusmn; 0.05 mm, respectively.},
	urldate = {2019-03-18},
	booktitle = {Medical {Imaging} 2019: {Image} {Processing}},
	publisher = {International Society for Optics and Photonics},
	author = {Javaid, Umair and Dasnoy, Damien and Lee, John A.},
	month = mar,
	year = {2019},
	pages = {109492P},
}

@article{januszewski_flood-filling_2016,
	title = {Flood-{Filling} {Networks}},
	url = {http://arxiv.org/abs/1611.00421},
	abstract = {State-of-the-art image segmentation algorithms generally consist of at least two successive and distinct computations: a boundary detection process that uses local image information to classify image locations as boundaries between objects, followed by a pixel grouping step such as watershed or connected components that clusters pixels into segments. Prior work has varied the complexity and approach employed in these two steps, including the incorporation of multi-layer neural networks to perform boundary prediction, and the use of global optimizations during pixel clustering. We propose a unified and end-to-end trainable machine learning approach, flood-filling networks, in which a recurrent 3d convolutional network directly produces individual segments from a raw image. The proposed approach robustly segments images with an unknown and variable number of objects as well as highly variable object sizes. We demonstrate the approach on a challenging 3d image segmentation task, connectomic reconstruction from volume electron microscopy data, on which flood-filling neural networks substantially improve accuracy over other state-of-the-art methods. The proposed approach can replace complex multi-step segmentation pipelines with a single neural network that is learned end-to-end.},
	urldate = {2019-03-05},
	journal = {arXiv:1611.00421 [cs]},
	author = {Januszewski, Michał and Maitin-Shepard, Jeremy and Li, Peter and Kornfeld, Jörgen and Denk, Winfried and Jain, Viren},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.00421},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{hou_unsupervised_2017,
	title = {Unsupervised {Histopathology} {Image} {Synthesis}},
	url = {http://arxiv.org/abs/1712.05021},
	abstract = {Hematoxylin and Eosin stained histopathology image analysis is essential for the diagnosis and study of complicated diseases such as cancer. Existing state-of-the-art approaches demand extensive amount of supervised training data from trained pathologists. In this work we synthesize in an unsupervised manner, large histopathology image datasets, suitable for supervised training tasks. We propose a unified pipeline that: a) generates a set of initial synthetic histopathology images with paired information about the nuclei such as segmentation masks; b) refines the initial synthetic images through a Generative Adversarial Network (GAN) to reference styles; c) trains a task-specific CNN and boosts the performance of the task-specific CNN with on-the-fly generated adversarial examples. Our main contribution is that the synthetic images are not only realistic, but also representative (in reference styles) and relatively challenging for training task-specific CNNs. We test our method for nucleus segmentation using images from four cancer types. When no supervised data exists for a cancer type, our method without supervision cost significantly outperforms supervised methods which perform across-cancer generalization. Even when supervised data exists for all cancer types, our approach without supervision cost performs better than supervised methods.},
	urldate = {2019-01-11},
	journal = {arXiv:1712.05021 [cs]},
	author = {Hou, Le and Agarwal, Ayush and Samaras, Dimitris and Kurc, Tahsin M. and Gupta, Rajarsi R. and Saltz, Joel H.},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.05021},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{carmona_identification_2008,
	title = {Identification of the optic nerve head with genetic algorithms},
	volume = {43},
	issn = {0933-3657},
	url = {http://www.aiimjournal.com/article/S0933-3657(08)00054-7/abstract},
	doi = {10.1016/j.artmed.2008.04.005},
	abstract = {Objective
This work proposes creating an automatic system to locate and segment the optic nerve head (ONH) in eye fundus photographic images using genetic algorithms.
Methods and material
Domain knowledge is used to create a set of heuristics that guide the various steps involved in the process. Initially, using an eye fundus colour image as input, a set of hypothesis points was obtained that exhibited geometric properties and intensity levels similar to the ONH contour pixels. Next, a genetic algorithm was used to find an ellipse containing the maximum number of hypothesis points in an offset of its perimeter, considering some constraints. The ellipse thus obtained is the approximation to the ONH. The segmentation method is tested in a sample of 110 eye fundus images, belonging to 55 patients with glaucoma (23.1\%) and eye hypertension (76.9\%) and random selected from an eye fundus image base belonging to the Ophthalmology Service at Miguel Servet Hospital, Saragossa (Spain).
Results and conclusions
The results obtained are competitive with those in the literature. The method's generalization capability is reinforced when it is applied to a different image base from the one used in our study and a discrepancy curve is obtained very similar to the one obtained in our image base. In addition, the robustness of the method proposed can be seen in the high percentage of images obtained with a discrepancy δ{\textless}5 (96\% and 99\% in our and a different image base, respectively). The results also confirm the hypothesis that the ONH contour can be properly approached with a non-deformable ellipse. Another important aspect of the method is that it directly provides the parameters characterising the shape of the papilla: lengths of its major and minor axes, its centre of location and its orientation with regard to the horizontal position.},
	number = {3},
	urldate = {2014-02-25},
	journal = {Artificial Intelligence in Medicine},
	author = {Carmona, Enrique J. and Rincón, Mariano and García-Feijoó, Julián and Martínez-de-la-Casa, José M.},
	month = jul,
	year = {2008},
	keywords = {Glaucoma, Constraint handling, Ellipse fitting, Genetic algorithm, Optic nerve head segmentation},
	pages = {243--259},
	file = {Snapshot:/home/edecenciere/Zotero/storage/AWHQ52H7/abstract.html:text/html},
}

@article{staal_ridge-based_2004,
	title = {Ridge-based vessel segmentation in color images of the retina},
	volume = {23},
	issn = {0278-0062},
	doi = {10.1109/TMI.2004.825627},
	abstract = {A method is presented for automated segmentation of vessels in two-dimensional color images of the retina. This method can be used in computer analyses of retinal images, e.g., in automated screening for diabetic retinopathy. The system is based on extraction of image ridges, which coincide approximately with vessel centerlines. The ridges are used to compose primitives in the form of line elements. With the line elements an image is partitioned into patches by assigning each image pixel to the closest line element. Every line element constitutes a local coordinate frame for its corresponding patch. For every pixel, feature vectors are computed that make use of properties of the patches and the line elements. The feature vectors are classified using a kNN-classifier and sequential forward feature selection. The algorithm was tested on a database consisting of 40 manually labeled images. The method achieves an area under the receiver operating characteristic curve of 0.952. The method is compared with two recently published rule-based methods of Hoover et al. and Jiang et al. . The results show that our method is significantly better than the two rule-based methods (p{\textless}0.01). The accuracy of our method is 0.944 versus 0.947 for a second observer.},
	number = {4},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Staal, J. and Abramoff, M.D. and Niemeijer, M. and Viergever, M.A. and van Ginneken, B.},
	month = apr,
	year = {2004},
	keywords = {Image segmentation, Algorithms, Pixel, Feature extraction, Image analysis, Humans, Image Interpretation, Computer-Assisted, Pattern Recognition, Automated, Reproducibility of Results, Sensitivity and Specificity, Image databases, Testing, medical image processing, automated segmentation, classifier, Cluster Analysis, Color, Databases, Factual, Diabetes, Diabetic Retinopathy, Expert Systems, eye, Fluorescein Angiography, image ridge extraction, Ophthalmoscopy, Retina, Retinal Vessels, Retinopathy, ridge-based vessel segmentation, sequential forward feature selection, Spatial databases, two-dimensional color images},
	pages = {501--509},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/56NH7B7K/login.html:text/html},
}

@article{hoover_locating_2000,
	title = {Locating blood vessels in retinal images by piecewise threshold probing of a matched filter response},
	volume = {19},
	issn = {0278-0062},
	doi = {10.1109/42.845178},
	abstract = {Describes an automated method to locate and outline blood vessels in images of the ocular fundus. Such a tool should prove useful to eye care specialists for purposes of patient screening, treatment evaluation, and clinical study. The authors' method differs from previously known methods in that it uses local and global vessel features cooperatively to segment the vessel network. The authors evaluate their method using hand-labeled ground truth segmentations of 20 images. A plot of the operating characteristic shows that the authors' method reduces false positives by as much as 15 times over basic thresholding of a matched filter response (MFR), at up to a 75\% true positive rate. For a baseline, they also compared the ground truth against a second hand-labeling, yielding a 90\% true positive and a 4\% false positive detection rate, on average. These numbers suggest there is still room for a 15\% true positive rate improvement, with the same false positive rate, over the authors' method. They are making all their images and hand labelings publicly available for interested researchers to use in evaluating related methods.},
	number = {3},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Hoover, A. and Kouznetsova, V. and Goldbaum, M.},
	month = mar,
	year = {2000},
	keywords = {Image segmentation, Algorithms, Humans, Reproducibility of Results, Labeling, Image Processing, Computer-Assisted, medical image processing, Diabetes, eye, Retina, Retinal Vessels, Arteriosclerosis, Biomedical imaging, blood vessels, blood vessels location, clinical study, eye care specialists, false positive detection rate, global vessel features, Hypertension, local vessel features, Magnetic Resonance Imaging, matched filter response, matched filters, Medical treatment, operating characteristic, optical images, patient screening, piecewise threshold probing, Retinal Diseases, retinal images, treatment evaluation, true positive rate, vessel network segmentation},
	pages = {203--210},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/UBGMAPTH/login.html:text/html},
}

@inproceedings{kauppi_diaretdb1_2007,
	title = {The {DIARETDB1} {Diabetic} {Retinopathy} {Database} and {Evaluation} {Protocol}.},
	booktitle = {British {Machine} {Vision} {Conference}},
	author = {Kauppi, Tomi and Kalesnykiene, Valentina and Kamarainen, Joni-Kristian and Lensu, Lasse and Sorri, Iiris and Raninen, Asta and Voutilainen, Raija and Uusitalo, Hannu and Kälviäinen, Heikki and Pietilä, Juhani},
	year = {2007},
	pages = {1--10},
}

@article{decenciere_teleophta:_2013,
	title = {{TeleOphta}: {Machine} learning and image processing methods for teleophthalmology},
	volume = {34},
	issn = {1959-0318},
	shorttitle = {{TeleOphta}},
	url = {http://www.sciencedirect.com/science/article/pii/S1959031813000237},
	doi = {10.1016/j.irbm.2013.01.010},
	abstract = {A complete prototype for the automatic detection of normal examinations on a teleophthalmology network for diabetic retinopathy screening is presented. The system combines pathological pattern mining methods, with specific lesion detection methods, to extract information from the images. This information, plus patient and other contextual data, is used by a classifier to compute an abnormality risk. Such a system should reduce the burden on readers on teleophthalmology networks.},
	number = {2},
	urldate = {2014-02-20},
	journal = {IRBM},
	author = {Decencière, E. and Cazuguel, G. and Zhang, X. and Thibault, G. and Klein, J. -C. and Meyer, F. and Marcotegui, B. and Quellec, G. and Lamard, M. and Danno, R. and Elie, D. and Massin, P. and Viktor, Z. and Erginay, A. and Laÿ, B. and Chabouis, A.},
	month = apr,
	year = {2013},
	pages = {196--203},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/9325FDH7/S1959031813000237.html:text/html},
}

@article{pisinger_upper_2006,
	title = {Upper bounds and exact algorithms for -dispersion problems},
	volume = {33},
	issn = {0305-0548},
	url = {http://www.sciencedirect.com/science/article/pii/S0305054804002552},
	doi = {10.1016/j.cor.2004.09.033},
	abstract = {The p-dispersion-sum problem is the problem of locating p facilities at some of n predefined locations, such that the distance sum between the p facilities is maximized. The problem has applications in telecommunication (where it is desirable to disperse the transceivers in order to minimize interference problems), and in location of shops and service-stations (where the mutual competition should be minimized).
A number of fast upper bounds are presented based on Lagrangian relaxation, semidefinite programming and reformulation techniques. A branch-and-bound algorithm is then derived, which at each branching node is able to compute the reformulation-based upper bound in O(n)O(n) time. Computational experiments show that the algorithm may solve geometric problems of size up to n=90n=90, and weighted geometric problems of size n=250n=250.
The related p-dispersion problem is the problem of locating p facilities such that the minimum distance between two facilities is as large as possible. New formulations and fast upper bounds are presented, and it is discussed whether a similar framework as for the p-dispersion sum problem can be used to tighten the upper bounds. A solution algorithm based on transformation of the p-dispersion problem to the p-dispersion-sum problem is finally presented, and its performance is evaluated through several computational experiments.},
	number = {5},
	urldate = {2014-02-17},
	journal = {Computers \& Operations Research},
	author = {Pisinger, David},
	month = may,
	year = {2006},
	keywords = {branch-and-bound, locational analysis, upper bounds},
	pages = {1380--1398},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/UPZ6ET5N/S0305054804002552.html:text/html},
}

@article{erkut_discrete_1990,
	title = {The discrete p-dispersion problem},
	volume = {46},
	issn = {0377-2217},
	url = {http://www.sciencedirect.com/science/article/pii/037722179090297O},
	doi = {10.1016/0377-2217(90)90297-O},
	abstract = {Considered is the problem of selecting p out of n given points in some space, such that the minimum distance between pairs of selected points is maximized. This objective may be appropriate if the selected points correspond to facility sites and the objective is to have as ‘dispersed’ a set as possible. This problem is NP-complete. Related graph theoretical problems are discussed, integer programming models are proposed, and an outline is given on a line search procedure to solve this problem optimally. Using a branch-and-bound procedure, problems with n = 40 and p = 16 can be solved on a microcomputer. The heuristic, developed to get an initial lower bound, finds an optimal solution for most of our random test problems. Also described is an extension to the basic problem that allows for preselected points, which may correspond to existing facility locations. This more general version can be solved by slight modifications of the algorithms.},
	number = {1},
	urldate = {2014-02-17},
	journal = {European Journal of Operational Research},
	author = {Erkut, Erhan},
	month = may,
	year = {1990},
	keywords = {dispersion, heuristics, Location, undesirable facilities},
	pages = {48--60},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/36CH63FS/037722179090297O.html:text/html},
}

@article{pisinger_upper_2006-1,
	title = {Upper {Bounds} and {Exact} {Algorithms} for {P}-dispersion {Problems}},
	volume = {33},
	issn = {0305-0548},
	url = {http://dx.doi.org/10.1016/j.cor.2004.09.033},
	doi = {10.1016/j.cor.2004.09.033},
	abstract = {The p-dispersion-sum problem is the problem of locating p facilities at some of n predefined locations, such that the distance sum between the p facilities is maximized. The problem has applications in telecommunication (where it is desirable to disperse the transceivers in order to minimize interference problems), and in location of shops and service-stations (where the mutual competition should be minimized).A number of fast upper bounds are presented based on Lagrangian relaxation, semidefinite programming and reformulation techniques. A branch-and-bound algorithm is then derived, which at each branching node is able to compute the reformulation-based upper bound in O(n) time. Computational experiments show that the algorithm may solve geometric problems of size up to n = 90, and weighted geometric problems of size n = 250.The related p-dispersion problem is the problem of locating p facilities such that the minimum distance between two facilities is as large as possible. New formulations and fast upper bounds are presented, and it is discussed whether a similar framework as for the p-dispersion sum problem can be used to tighten the upper bounds. A solution algorithm based on transformation of the p-dispersion problem to the p-dispersion-sum problem is finally presented, and its performance is evaluated through several computational experiments.},
	number = {5},
	urldate = {2014-02-17},
	journal = {Comput. Oper. Res.},
	author = {Pisinger, David},
	month = may,
	year = {2006},
	keywords = {branch-and-bound, locational analysis, upper bounds},
	pages = {1380--1398},
}

@misc{ravi_heuristic_1994,
	type = {research-article},
	title = {Heuristic and {Special} {Case} {Algorithms} for {Dispersion} {Problems}},
	url = {http://pubsonline.informs.org/doi/abs/10.1287/opre.42.2.299},
	abstract = {The dispersion problem arises in selecting facilities to maximize some function of the distances between the facilities. The problem also arises in selecting nondominated solutions for multiobjective decision making. It is known to be NP-hard under two objectives: maximizing the minimum distance (MAX-MIN) between any pair of facilities and maximizing the average distance (MAX-AVG). We consider the question of obtaining near-optimal solutions. for MAX-MIN, we show that if the distances do not satisfy the triangle inequality, there is no polynomial-time relative approximation algorithm unless P = NP. When the distances satisfy the triangle inequality, we analyze an efficient heuristic and show that it provides a performance guarantee of two. We also prove that obtaining a performance guarantee of less than two is NP-hard. for MAX-AVG, we analyze an efficient heuristic and show that it provides a performance guarantee of four when the distances satisfy the triangle inequality. We also present a polynomial-ti...},
	language = {en},
	urldate = {2014-02-17},
	author = {Ravi, S. S. and Rosenkrantz, D. J. and Tayi, G. K.},
	month = apr,
	year = {1994},
	keywords = {analysis of algorithms: computational complexity, facilities/equipment planning: discrete location, programming: heuristic},
	file = {Snapshot:/home/edecenciere/Zotero/storage/UWPD32HQ/opre.42.2.html:text/html},
}

@article{monga_optimal_1987,
	title = {{AN} {OPTIMAL} {REGION} {GROWING} {ALGORITHM} {FOR} {IMAGE} {SEGMENTATION}},
	volume = {01},
	issn = {0218-0014, 1793-6381},
	url = {http://www.worldscientific.com/doi/abs/10.1142/S0218001487000242},
	doi = {10.1142/S0218001487000242},
	number = {03n04},
	urldate = {2014-02-11},
	journal = {International Journal of Pattern Recognition and Artificial Intelligence},
	author = {Monga, Olivier},
	month = dec,
	year = {1987},
	pages = {351--375},
	file = {AN OPTIMAL REGION GROWING ALGORITHM FOR IMAGE SEGMENTATION (World Scientific):/home/edecenciere/Zotero/storage/KI5MMK6K/S0218001487000242.html:text/html},
}

@article{marcotegui_bottom-up_1997,
	title = {Bottom-up segmentation of image sequences for coding},
	volume = {52},
	issn = {0003-4347, 1958-9395},
	url = {http://link.springer.com/article/10.1007/BF02998459},
	doi = {10.1007/BF02998459},
	abstract = {A bottom-up segmentation method is presented as a first step of object based coding. An initial partition is created based on connected filters. The iterative fusion algorithm merges the most similar regions until the target is reached. As the regions become bigger, more complex criterion, like similarity of texture or of motion are used. The algorithm offers a good balance between time stability and the ability to cope with the apparition of new regions.},
	language = {fr},
	number = {7-8},
	urldate = {2014-02-11},
	journal = {Annales Des Télécommunications},
	author = {Marcotegui, Beatriz and Meyer, Fernand},
	month = jul,
	year = {1997},
	keywords = {segmentation, Codage image, Communications Engineering, Networks, Compensation mouvement, Computer Communication Networks, Contrast, Contraste, Détection bord, Edge detection, Image animée, Image coding, Image fixe, Image Processing, Information and Communication, Circuits, Information Systems and Communication Service, Lissage, Méthode orientée objet, Motion compensation, Moving image, Object oriented method, Preprocessing, Prétraitement, R \& D/Technology Policy, Signal, Image and Speech Processing, Smoothing, Still image, Texture, Traitement image},
	pages = {397--407},
	file = {Snapshot:/home/edecenciere/Zotero/storage/SC2KZA65/BF02998459.html:text/html},
}

@incollection{veksler_superpixels_2010,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Superpixels and {Supervoxels} in an {Energy} {Optimization} {Framework}},
	copyright = {©2010 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-15554-3 978-3-642-15555-0},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-15555-0_16},
	abstract = {Many methods for object recognition, segmentation, etc., rely on a tessellation of an image into “superpixels”. A superpixel is an image patch which is better aligned with intensity edges than a rectangular patch. Superpixels can be extracted with any segmentation algorithm, however, most of them produce highly irregular superpixels, with widely varying sizes and shapes. A more regular space tessellation may be desired. We formulate the superpixel partitioning problem in an energy minimization framework, and optimize with graph cuts. Our energy function explicitly encourages regular superpixels. We explore variations of the basic energy, which allow a trade-off between a less regular tessellation but more accurate boundaries or better efficiency. Our advantage over previous work is computational efficiency, principled optimization, and applicability to 3D “supervoxel” segmentation. We achieve high boundary recall on images and spatial coherence on video. We also show that compact superpixels improve accuracy on a simple application of salient object segmentation.},
	number = {6315},
	urldate = {2014-02-11},
	booktitle = {Computer {Vision} – {ECCV} 2010},
	publisher = {Springer Berlin Heidelberg},
	author = {Veksler, Olga and Boykov, Yuri and Mehrani, Paria},
	editor = {Daniilidis, Kostas and Maragos, Petros and Paragios, Nikos},
	month = jan,
	year = {2010},
	keywords = {Computer Graphics, Image Processing and Computer Vision, Pattern recognition, Algorithm Analysis and Problem Complexity, Biometrics, Computer Imaging, Vision, Pattern Recognition and Graphics},
	pages = {211--224},
	file = {Snapshot:/home/edecenciere/Zotero/storage/M5NC2VA3/978-3-642-15555-0_16.html:text/html},
}

@article{achanta_slic_2012,
	title = {{SLIC} {Superpixels} {Compared} to {State}-of-the-{Art} {Superpixel} {Methods}},
	volume = {34},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2012.120},
	abstract = {Computer vision applications have come to rely increasingly on superpixels in recent years, but it is not always clear what constitutes a good superpixel algorithm. In an effort to understand the benefits and drawbacks of existing methods, we empirically compare five state-of-the-art superpixel algorithms for their ability to adhere to image boundaries, speed, memory efficiency, and their impact on segmentation performance. We then introduce a new superpixel algorithm, simple linear iterative clustering (SLIC), which adapts a k-means clustering approach to efficiently generate superpixels. Despite its simplicity, SLIC adheres to boundaries as well as or better than previous methods. At the same time, it is faster and more memory efficient, improves segmentation performance, and is straightforward to extend to supervoxel generation.},
	number = {11},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Achanta, R. and Shaji, A. and Smith, K. and Lucchi, A. and Fua, P. and Süsstrunk, S.},
	month = nov,
	year = {2012},
	keywords = {Image segmentation, Algorithms, computer vision, Image Enhancement, Image Interpretation, Computer-Assisted, Pattern Recognition, Automated, Reproducibility of Results, Sensitivity and Specificity, Image color analysis, segmentation, Approximation algorithms, clustering, Clustering algorithms, Complexity theory, image boundary, Image edge detection, iterative methods, k-means, k-means clustering approach, Measurement uncertainty, memory efficiency, pattern clustering, segmentation performance, Signal Processing, Computer-Assisted, simple linear iterative clustering, SLIC superpixels, superpixel generation, Superpixels, supervoxel generation},
	pages = {2274--2282},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/RM52ANWH/abs_all.html:text/html},
}

@inproceedings{louppe_understanding_2013,
	title = {Understanding variable importances in forests of randomized trees},
	url = {http://papers.nips.cc/paper/4928-understanding-variable-importances-in-forests-of-randomized-trees},
	abstract = {Eletronic Proceedings of Neural Information Processing Systems},
	urldate = {2013-12-17},
	author = {Louppe, Gilles and Wehenkel, Louis and Sutera, Antonio and Geurts, Pierre},
	year = {2013},
	pages = {431--439},
	file = {Snapshot:/home/edecenciere/Zotero/storage/VHV3C66X/4928-understanding-variable-importances-in-forests-of-randomized-trees.html:text/html},
}

@inproceedings{giancardo_automatic_2011,
	title = {Automatic retina exudates segmentation without a manually labelled training set},
	doi = {10.1109/ISBI.2011.5872661},
	abstract = {Diabetic macular edema (DME) is a common vision threatening complication of diabetic retinopathy which can be assessed by detecting exudates (a type of bright lesion) in fundus images. In this work, two new methods for the detection of exudates are presented which do not use a supervised learning step; therefore, they do not require labelled lesion training sets which are time consuming to create, difficult to obtain and prone to human error. We introduce a new dataset of fundus images from various ethnic groups and levels of DME which we have made publicly available. We evaluate our algorithm with this dataset and compare our results with two recent exudate segmentation algorithms. In all of our tests, our algorithms perform better or comparable with an order of magnitude reduction in computational time.},
	booktitle = {2011 {IEEE} {International} {Symposium} on {Biomedical} {Imaging}: {From} {Nano} to {Macro}},
	author = {Giancardo, L. and Meriaudeau, F. and Karnowski, T.P. and Li, Y. and Tobin, K.W. and Chaum, E.},
	year = {2011},
	keywords = {Image segmentation, medical image processing, segmentation, Diabetic Retinopathy, eye, Biomedical imaging, automatic retina exudate segmentation, bright lesion, computer-aided diagnosis, diabetic macular edema, diseases, ethnic groups, exudate segmentation algorithms, fundus image database, fundus images, Gold, manually labelled training set, Radiography, retina normalisation, Variable speed drives, vision defects, vision threatening complication},
	pages = {1396--1400},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/9UWSNBR9/abs_all.html:text/html},
}

@article{pedregosa_scikit-learn:_2011,
	title = {Scikit-learn: {Machine} learning in {Python}},
	volume = {12},
	journal = {The Journal of Machine Learning Research},
	author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
	year = {2011},
	pages = {2825--2830},
}

@article{noauthor_scikit-learn:_nodate,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
}

@article{pedregosa_scikit-learn:_2011-1,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	volume = {12},
	issn = {1532-4435},
	shorttitle = {Scikit-learn},
	url = {http://dl.acm.org/citation.cfm?id=1953048.2078195},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
	urldate = {2013-11-12},
	journal = {J. Mach. Learn. Res.},
	author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
	month = nov,
	year = {2011},
	pages = {2825--2830},
}

@inproceedings{bancelin_time-lapsed_2013,
	address = {Maastricht, Netherlands},
	title = {Time-lapsed {SHG} imaging of collagen fibrillogenesis and correlation to electronic microscopy},
	booktitle = {Focus on microscopy 2013},
	author = {Bancelin, S. and Aimé, C. and Machairas, V. and Decencière, E. and Coradin, T. and Schanne-Klein, M.-C.},
	year = {2013},
}

@misc{noauthor_etienne_nodate,
	title = {Etienne {DECENCIERE} - {Citations} {Google} {Scholar}},
	url = {http://scholar.google.fr/citations?hl=fr&user=5eLId8QAAAAJ&pagesize=100&citation_for_view=5eLId8QAAAAJ:J_g5lzvAfSwC&view_op=view_citation},
	urldate = {2013-10-15},
	file = {Etienne DECENCIERE - Citations Google Scholar:/home/edecenciere/Zotero/storage/JKSHWQHM/citations.html:text/html},
}

@article{kirkpatrick_endogenous_2007,
	title = {Endogenous optical biomarkers of ovarian cancer evaluated with multiphoton microscopy},
	volume = {16},
	issn = {1055-9965},
	doi = {10.1158/1055-9965.EPI-07-0009},
	abstract = {PURPOSE: Among gynecologic cancers, ovarian cancer is the second most common and has the highest mortality. Currently, there is no accurate early diagnostic technique for ovarian cancer. Furthermore, little is understood regarding the early progression of this disease. We have imaged multiphoton interactions of endogenous tissue constituents from normal and abnormal ovarian biopsies that were kept viable during transport from the operating room and microscopy. Experimental Design: The ovarian surface and underlying stroma were assessed with two-photon excited fluorescence (2PEF) and second harmonic generation (SHG). High-resolution, optically sectioned images were analyzed for epithelial morphology based on 2PEF and collagen density and structural integrity based on SHG. Additionally, multiwavelength 2PEF provided an estimation of the cellular redox ratio of epithelial cells.
RESULTS: Normal tissue exhibited a uniform epithelial layer with highly structured collagen in the stroma, whereas abnormal tissue exhibited varied epithelium with large cells and substantial quantitative changes to the collagen structure. Samples from patients at high risk for developing ovarian cancer (based on their personal/family history of cancer) exhibited highly variable cellular redox ratios and changes in collagen structure that trended toward cancer samples.
CONCLUSION: This study highlights differences in endogenous signals in viable ovarian biopsies based on quantitative collagen structural changes and redox ratio estimates that may lead to improved detection and further insights in ovarian cancer, particularly in the early stages of the disease.},
	language = {eng},
	number = {10},
	journal = {Cancer epidemiology, biomarkers \& prevention: a publication of the American Association for Cancer Research, cosponsored by the American Society of Preventive Oncology},
	author = {Kirkpatrick, Nathaniel D and Brewer, Molly A and Utzinger, Urs},
	month = oct,
	year = {2007},
	pmid = {17932352},
	keywords = {Humans, Epithelium, Female, Image Processing, Computer-Assisted, Biopsy, Collagen, Genetic Predisposition to Disease, Microscopy, Fluorescence, Multiphoton, NAD, NADP, Ovarian Neoplasms, Ovary, Oxidation-Reduction, Reference Values, Risk Factors, Stromal Cells, Tumor Markers, Biological},
	pages = {2048--2057},
}

@article{kirkpatrick_endogenous_2007-1,
	title = {Endogenous {Optical} {Biomarkers} of {Ovarian} {Cancer} {Evaluated} with {Multiphoton} {Microscopy}},
	volume = {16},
	issn = {1055-9965, 1538-7755},
	url = {http://cebp.aacrjournals.org/content/16/10/2048},
	doi = {10.1158/1055-9965.EPI-07-0009},
	abstract = {Purpose: Among gynecologic cancers, ovarian cancer is the second most common and has the highest mortality. Currently, there is no accurate early diagnostic technique for ovarian cancer. Furthermore, little is understood regarding the early progression of this disease. We have imaged multiphoton interactions of endogenous tissue constituents from normal and abnormal ovarian biopsies that were kept viable during transport from the operating room and microscopy.
Experimental Design: The ovarian surface and underlying stroma were assessed with two-photon excited fluorescence (2PEF) and second harmonic generation (SHG). High-resolution, optically sectioned images were analyzed for epithelial morphology based on 2PEF and collagen density and structural integrity based on SHG. Additionally, multiwavelength 2PEF provided an estimation of the cellular redox ratio of epithelial cells.
Results: Normal tissue exhibited a uniform epithelial layer with highly structured collagen in the stroma, whereas abnormal tissue exhibited varied epithelium with large cells and substantial quantitative changes to the collagen structure. Samples from patients at high risk for developing ovarian cancer (based on their personal/family history of cancer) exhibited highly variable cellular redox ratios and changes in collagen structure that trended toward cancer samples.
Conclusion: This study highlights differences in endogenous signals in viable ovarian biopsies based on quantitative collagen structural changes and redox ratio estimates that may lead to improved detection and further insights in ovarian cancer, particularly in the early stages of the disease. (Cancer Epidemiol Biomarkers Prev 2007;16(10):2048–55)},
	language = {en},
	number = {10},
	urldate = {2013-10-10},
	journal = {Cancer Epidemiology Biomarkers \& Prevention},
	author = {Kirkpatrick, Nathaniel D. and Brewer, Molly A. and Utzinger, Urs},
	month = jan,
	year = {2007},
	pmid = {17932352},
	keywords = {Microscopy, Diagnostic Imaging, Extracellular Matrix, Gynecologic cancers: ovarian, Imaging of tumor progression and metastasis, Metabolism, Tumor microenvironment and modification},
	pages = {2048--2057},
	file = {Snapshot:/home/edecenciere/Zotero/storage/ZA529BQ2/2048.html:text/html},
}

@article{kirkpatrick_endogenous_2007-2,
	title = {Endogenous {Optical} {Biomarkers} of {Ovarian} {Cancer} {Evaluated} with {Multiphoton} {Microscopy}},
	volume = {16},
	issn = {1055-9965, 1538-7755},
	url = {http://cebp.aacrjournals.org/content/16/10/2048},
	doi = {10.1158/1055-9965.EPI-07-0009},
	abstract = {Purpose: Among gynecologic cancers, ovarian cancer is the second most common and has the highest mortality. Currently, there is no accurate early diagnostic technique for ovarian cancer. Furthermore, little is understood regarding the early progression of this disease. We have imaged multiphoton interactions of endogenous tissue constituents from normal and abnormal ovarian biopsies that were kept viable during transport from the operating room and microscopy.
Experimental Design: The ovarian surface and underlying stroma were assessed with two-photon excited fluorescence (2PEF) and second harmonic generation (SHG). High-resolution, optically sectioned images were analyzed for epithelial morphology based on 2PEF and collagen density and structural integrity based on SHG. Additionally, multiwavelength 2PEF provided an estimation of the cellular redox ratio of epithelial cells.
Results: Normal tissue exhibited a uniform epithelial layer with highly structured collagen in the stroma, whereas abnormal tissue exhibited varied epithelium with large cells and substantial quantitative changes to the collagen structure. Samples from patients at high risk for developing ovarian cancer (based on their personal/family history of cancer) exhibited highly variable cellular redox ratios and changes in collagen structure that trended toward cancer samples.
Conclusion: This study highlights differences in endogenous signals in viable ovarian biopsies based on quantitative collagen structural changes and redox ratio estimates that may lead to improved detection and further insights in ovarian cancer, particularly in the early stages of the disease. (Cancer Epidemiol Biomarkers Prev 2007;16(10):2048–55)},
	language = {en},
	number = {10},
	urldate = {2013-10-10},
	journal = {Cancer Epidemiology Biomarkers \& Prevention},
	author = {Kirkpatrick, Nathaniel D. and Brewer, Molly A. and Utzinger, Urs},
	month = jan,
	year = {2007},
	pmid = {17932352},
	keywords = {Microscopy, Diagnostic Imaging, Extracellular Matrix, Gynecologic cancers: ovarian, Imaging of tumor progression and metastasis, Metabolism, Tumor microenvironment and modification},
	pages = {2048--2057},
	file = {Snapshot:/home/edecenciere/Zotero/storage/P3WKTNVE/2048.html:text/html},
}

@article{provenzano_collagen_2006,
	title = {Collagen reorganization at the tumor-stromal interface facilitates local invasion},
	volume = {4},
	issn = {1741-7015},
	url = {http://link.springer.com/article/10.1186/1741-7015-4-38},
	doi = {10.1186/1741-7015-4-38},
	abstract = {Background Stromal-epithelial interactions are of particular significance in breast tissue as misregulation of these interactions can promote tumorigenesis and invasion. Moreover, collagen-dense breast tissue increases the risk of breast carcinoma, although the relationship between collagen density and tumorigenesis is not well understood. As little is known about epithelial-stromal interactions in vivo, it is necessary to visualize the stroma surrounding normal epithelium and mammary tumors in intact tissues to better understand how matrix organization, density, and composition affect tumor formation and progression. Methods Epithelial-stromal interactions in normal mammary glands, mammary tumors, and tumor explants in three-dimensional culture were studied with histology, electron microscopy, and nonlinear optical imaging methodologies. Imaging of the tumor-stromal interface in live tumor tissue ex vivo was performed with multiphoton laser-scanning microscopy (MPLSM) to generate multiphoton excitation (MPE) of endogenous fluorophores and second harmonic generation (SHG) to image stromal collagen. Results We used both laser-scanning multiphoton and second harmonic generation microscopy to determine the organization of specific collagen structures around ducts and tumors in intact, unfixed and unsectioned mammary glands. Local alterations in collagen density were clearly seen, allowing us to obtain three-dimensional information regarding the organization of the mammary stroma, such as radiating collagen fibers that could not have been obtained using classical histological techniques. Moreover, we observed and defined three tumor-associated collagen signatures (TACS) that provide novel markers to locate and characterize tumors. In particular, local cell invasion was found predominantly to be oriented along certain aligned collagen fibers, suggesting that radial alignment of collagen fibers relative to tumors facilitates invasion. Consistent with this observation, primary tumor explants cultured in a randomly organized collagen matrix realigned the collagen fibers, allowing individual tumor cells to migrate out along radially aligned fibers. Conclusion The presentation of these tumor-associated collagen signatures allowed us to identify pre-palpable tumors and see cells at the tumor-stromal boundary invading into the stroma along radially aligned collagen fibers. As such, TACS should provide indications that a tumor is, or could become, invasive, and may serve as part of a strategy to help identify and characterize breast tumors in animal and human tissues.},
	language = {en},
	number = {1},
	urldate = {2013-10-10},
	journal = {BMC Medicine},
	author = {Provenzano, Paolo P. and Eliceiri, Kevin W. and Campbell, Jay M. and Inman, David R. and White, John G. and Keely, Patricia J.},
	month = dec,
	year = {2006},
	keywords = {Biomedicine general, Medicine/Public Health, general},
	pages = {1--15},
	file = {Snapshot:/home/edecenciere/Zotero/storage/XMQ42WM8/1741-7015-4-38.html:text/html},
}

@article{kirkpatrick_live_2007,
	title = {Live imaging of collagen remodeling during angiogenesis},
	volume = {292},
	copyright = {Copyright © 2007 by the American Physiological Society},
	url = {http://ajpheart.physiology.org/content/292/6/H3198},
	doi = {10.1152/ajpheart.01234.2006},
	abstract = {To better understand interstitial matrix remodeling during angiogenesis, we probed endogenous optical signatures of collagen fibrils and cells with multiphoton microscopy to noninvasively visualize, in real-time, changes to fibril organization around angiogenic sprouts and growing neovessels. From analyses of the second-harmonic generation signal from fibrillar collagen and two-photon excited fluorescence, as well as coherent transmitted light from vascular cells, we found that microvessel fragments interacting with the collagen matrix exhibited two key features: a strong association of fibrillar collagen around the parent vessel fragment during vessel construct reconstitution and a substantial collagen fibril reorganization by sprout and neovessel tips. Results indicate that angiogenic sprouts and growing neovessels actively and differentially remodel existing collagen fibrils. This imaging approach to assess local changes in matrix organization may have a broader impact on tissue biology and mechanics during angiogenesis and allow for new insights in cardiovascular, diabetes, and cancer research.},
	language = {en},
	number = {6},
	urldate = {2013-10-10},
	journal = {American Journal of Physiology - Heart and Circulatory Physiology},
	author = {Kirkpatrick, Nathaniel D. and Andreou, Stylianos and Hoying, James B. and Utzinger, Urs},
	month = jan,
	year = {2007},
	pmid = {17307995},
	note = {To better understand interstitial matrix remodeling during angiogenesis, we probed endogenous optical signatures of collagen fibrils and cells with multiphoton microscopy to noninvasively visualize, in real-time, changes to fibril organization around angiogenic sprouts and growing neovessels. From analyses of the second-harmonic generation signal from fibrillar collagen and two-photon excited fluorescence, as well as coherent transmitted light from vascular cells, we found that microvessel fragments interacting with the collagen matrix exhibited two key features: a strong association of fibrillar collagen around the parent vessel fragment during vessel construct reconstitution and a substantial collagen fibril reorganization by sprout and neovessel tips. Results indicate that angiogenic sprouts and growing neovessels actively and differentially remodel existing collagen fibrils. This imaging approach to assess local changes in matrix organization may have a broader impact on tissue biology and mechanics during angiogenesis and allow for new insights in cardiovascular, diabetes, and cancer research.},
	pages = {H3198--H3206},
	file = {Snapshot:/home/edecenciere/Zotero/storage/TVF7DRND/H3198.html:text/html},
}

@article{lin_evaluating_2005,
	title = {Evaluating cutaneous photoaging by use of multiphoton fluorescence and second-harmonic generation microscopy},
	volume = {30},
	url = {http://ol.osa.org/abstract.cfm?URI=ol-30-17-2275},
	doi = {10.1364/OL.30.002275},
	abstract = {The photoaging process of facial skin is investigated by use of multiphoton fluorescence and second-harmonic generation (SHG) microscopy. We obtain the autofluorescence (AF) and SHG images of the superficial dermis from the facial skin of three patients aged 20, 40, and 70 years. The results show that areas of AF increase with age, whereas areas of SHG decrease with age. The results are consistent with the histological findings in which collagen is progressively replaced by elastic fibers. The AF and SHG changes in photoaging are quantified by a SHG to autofluorescence aging index of dermis (SAAID). Our results suggest that SAAID can be a good indicator of the severity of photoaging.},
	number = {17},
	urldate = {2013-10-10},
	journal = {Optics Letters},
	author = {Lin, Sung-Jan and Wu, Ruei-Jr and Tan, Hsin-Yuan and Lo, Wen and Lin, Wei-Chou and Young, Tai-Horng and Hsu, Chih-Jung and Chen, Jau-Shiuh and Jee, Shiou-Hwa and Dong, Chen-Yuan},
	month = sep,
	year = {2005},
	keywords = {Microscopy, Medical and biological imaging, Multiharmonic generation},
	pages = {2275--2277},
	file = {Opt. Lett. Snapshot:/home/edecenciere/Zotero/storage/M4W4HHH7/abstract.html:text/html},
}

@article{chen_quantitative_2012,
	title = {Quantitative analysis of multiphoton excitation autofluorescence and second harmonic generation imaging for medical diagnosis},
	volume = {36},
	issn = {0895-6111},
	url = {http://www.medicalimagingandgraphics.com/article/S0895-6111(12)00105-X/abstract},
	doi = {10.1016/j.compmedimag.2012.06.003},
	number = {7},
	urldate = {2013-10-10},
	journal = {Computerized Medical Imaging and Graphics},
	author = {Chen, Wei-Liang and Hu, Po-Sheng and Ghazaryan, Ara and Chen, Shean-Jen and Tsai, Tsung-Hua and Dong, Chen-Yuan},
	month = oct,
	year = {2012},
	pages = {519--526},
	file = {Snapshot:/home/edecenciere/Zotero/storage/TPMAPPR7/fulltext.html:text/html},
}

@article{bayan_fully_2009,
	title = {Fully automated, quantitative, noninvasive assessment of collagen fiber content and organization in thick collagen gels},
	volume = {105},
	issn = {0021-8979},
	doi = {10.1063/1.3116626},
	abstract = {Collagen is the most prominent protein of human tissues. Its content and organization define to a large extent the mechanical properties of tissue as well as its function. Methods that have been used traditionally to visualize and analyze collagen are invasive, provide only qualitative or indirect information, and have limited use in studies that aim to understand the dynamic nature of collagen remodeling and its interactions with the surrounding cells and other matrix components. Second harmonic generation (SHG) imaging emerged as a promising noninvasive modality for providing high-resolution images of collagen fibers within thick specimens, such as tissues. In this article, we present a fully automated procedure to acquire quantitative information on the content, orientation, and organization of collagen fibers. We use this procedure to monitor the dynamic remodeling of collagen gels in the absence or presence of fibroblasts over periods of 12 or 14 days. We find that an adaptive thresholding and stretching approach provides great insight to the content of collagen fibers within SHG images without the need for user input. An additional feature-erosion and feature-dilation step is useful for preserving structure and noise removal in images with low signal. To quantitatively assess the orientation of collagen fibers, we extract the orientation index (OI), a parameter based on the power distribution of the spatial-frequency-averaged, two-dimensional Fourier transform of the SHG images. To measure the local organization of the collagen fibers, we access the Hough transform of small tiles of the image and compute the entropy distribution, which represents the probability of finding the direction of fibers along a dominant direction. Using these methods we observed that the presence and number of fibroblasts within the collagen gel significantly affects the remodeling of the collagen matrix. In the absence of fibroblasts, gels contract, especially during the first few d- ays, in a manner that allows the fibers to remain mostly disoriented, as indicated by small OI values. Subtle changes in the local organization of fibers may be taking place as the corresponding entropy values of these gels show a small decrease. The presence of fibroblasts affects the collagen matrix in a manner that is highly dependent on their number. A low density of fibroblasts enhances the rate of initial gel contraction, but ultimately leads to degradation of collagen fibers, which start to organize in localized clumps. This degradation and reorganization is seen within the first days of incubation with fibroblasts at a high density and is followed by de novo collagen fiber deposition by the fibroblasts. These collagen fibers are more highly oriented and organized than the fibers of the original collagen gel. These initial studies demonstrate that SHG imaging in combination with automated image analysis approaches offer a noninvasive and easily implementable method for characterizing important features of the content and organization of collagen in tissuelike specimens. Therefore, these studies could offer important insights for improving tissue engineering and disease diagnostic efforts.},
	number = {10},
	journal = {Journal of Applied Physics},
	author = {Bayan, Christopher and Levitt, Jonathan M. and Miller, Eric and Kaplan, D. and Georgakoudi, Irene},
	year = {2009},
	keywords = {Feature extraction, cellular biophysics, biomedical optical imaging, medical image processing, diseases, 4265Ky, 8714E-, 8763lt, 8764mk, 8785Lf, Fourier transforms, Hough transforms, laser applications in medicine, molecular biophysics, optical harmonic generation, proteins, tissue engineering},
	pages = {102042--102042--11},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/E8P8SZB2/freeabs_all.html:text/html},
}

@article{altendorf_imaging_2012,
	title = {Imaging and {3D} morphological analysis of collagen fibrils},
	volume = {247},
	copyright = {© 2012 The Authors Journal of Microscopy © 2012 Royal Microscopical Society},
	issn = {1365-2818},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1365-2818.2012.03629.x/abstract},
	doi = {10.1111/j.1365-2818.2012.03629.x},
	abstract = {The recent booming of multiphoton imaging of collagen fibrils by means of second harmonic generation microscopy generates the need for the development and automation of quantitative methods for image analysis. Standard approaches sequentially analyse two-dimensional (2D) slices to gain knowledge on the spatial arrangement and dimension of the fibrils, whereas the reconstructed three-dimensional (3D) image yields better information about these characteristics. In this work, a 3D analysis method is proposed for second harmonic generation images of collagen fibrils, based on a recently developed 3D fibre quantification method. This analysis uses operators from mathematical morphology. The fibril structure is scanned with a directional distance transform. Inertia moments of the directional distances yield the main fibre orientation, corresponding to the main inertia axis. The collaboration of directional distances and fibre orientation delivers a geometrical estimate of the fibre radius. The results include local maps as well as global distribution of orientation and radius of the fibrils over the 3D image. They also bring a segmentation of the image into foreground and background, as well as a classification of the foreground pixels into the preferred orientations. This accurate determination of the spatial arrangement of the fibrils within a 3D data set will be most relevant in biomedical applications. It brings the possibility to monitor remodelling of collagen tissues upon a variety of injuries and to guide tissues engineering because biomimetic 3D organizations and density are requested for better integration of implants.},
	language = {en},
	number = {2},
	urldate = {2013-10-10},
	journal = {Journal of Microscopy},
	author = {Altendorf, H. and Decencière, E. and Jeulin, D. and Peixoto, P. De Sa and Deniset-Besseau, A. and Angelini, E. and Mosser, G. and Schanne-Klein, M.-C.},
	year = {2012},
	keywords = {biopolymers, collagen fibrils, fibre segmentation, Fibre System, mathematical morphology, second harmonic microscopy, three-dimensional imaging},
	pages = {161--175},
	file = {Snapshot:/home/edecenciere/Zotero/storage/4G5DP8R8/full.html:text/html},
}

@article{noauthor_surface_2013,
	title = {Surface fitting for individual image thresholding and beyond},
	volume = {7},
	issn = {1751-9659},
	doi = {10.1049/iet-ipr.2012.0690},
	abstract = {In this study, the authors propose a novel algorithm for background??foreground segmentation. The work is motivated by the need for information about the background that is obscured by objects, in order to achieve accurate segmentation. The algorithm utilises the principle of estimating the occluded background by surface fitting. Edge detection methods are used to detect boundaries between foreground and background, identifying background points as well as foreground points. This categorisation will guarantee that most points used for surface fitting are from the same category and thus the proposed surface fitting with random sample consensus (RANSAC) algorithm will produce an accurate estimate of the surface. The authors algorithm has been applied to the real-world applications of segmenting plant images with inhomogeneous but smooth background and measuring the relative temperature of plants. Comparisons with experimental results show that the proposed algorithm is able to reduce significantly background inhomogeneities in infra-red images for the accurate estimation of temperature differences between background and plants, which provides important clues for fast and cheap genetic screening. The proposed algorithm is also able to overcome the intensity inhomogeneities for accurate image segmentation, particularly for plant root image segmentation with the preservation of lateral plant roots.},
	number = {6},
	journal = {IET Image Processing},
	year = {2013},
	pages = {596--605},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/ICF22AIB/abs_all.html:text/html},
}

@article{noauthor_surface_2013-1,
	title = {Surface fitting for individual image thresholding and beyond},
	volume = {7},
	issn = {1751-9659},
	doi = {10.1049/iet-ipr.2012.0690},
	abstract = {In this study, the authors propose a novel algorithm for background??foreground segmentation. The work is motivated by the need for information about the background that is obscured by objects, in order to achieve accurate segmentation. The algorithm utilises the principle of estimating the occluded background by surface fitting. Edge detection methods are used to detect boundaries between foreground and background, identifying background points as well as foreground points. This categorisation will guarantee that most points used for surface fitting are from the same category and thus the proposed surface fitting with random sample consensus (RANSAC) algorithm will produce an accurate estimate of the surface. The authors algorithm has been applied to the real-world applications of segmenting plant images with inhomogeneous but smooth background and measuring the relative temperature of plants. Comparisons with experimental results show that the proposed algorithm is able to reduce significantly background inhomogeneities in infra-red images for the accurate estimation of temperature differences between background and plants, which provides important clues for fast and cheap genetic screening. The proposed algorithm is also able to overcome the intensity inhomogeneities for accurate image segmentation, particularly for plant root image segmentation with the preservation of lateral plant roots.},
	number = {6},
	journal = {IET Image Processing},
	year = {2013},
	pages = {596--605},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/S4RE2GH4/abs_all.html:text/html},
}

@article{decenciere_automatic_2013,
	title = {Automatic {3D} segmentation of multiphoton images: a key step for the quantification of human skin},
	volume = {19},
	issn = {1600-0846},
	shorttitle = {Automatic {3D} segmentation of multiphoton images},
	doi = {10.1111/srt.12019},
	abstract = {BACKGROUND/PURPOSE: Multiphoton microscopy has emerged in the past decade as a useful noninvasive imaging technique for in vivo human skin characterization. However, it has not been used until now in evaluation clinical trials, mainly because of the lack of specific image processing tools that would allow the investigator to extract pertinent quantitative three-dimensional (3D) information from the different skin components.
METHODS: We propose a 3D automatic segmentation method of multiphoton images which is a key step for epidermis and dermis quantification. This method, based on the morphological watershed and graph cuts algorithms, takes into account the real shape of the skin surface and of the dermal-epidermal junction, and allows separating in 3D the epidermis and the superficial dermis.
RESULTS: The automatic segmentation method and the associated quantitative measurements have been developed and validated on a clinical database designed for aging characterization. The segmentation achieves its goals for epidermis-dermis separation and allows quantitative measurements inside the different skin compartments with sufficient relevance.
CONCLUSIONS: This study shows that multiphoton microscopy associated with specific image processing tools provides access to new quantitative measurements on the various skin components. The proposed 3D automatic segmentation method will contribute to build a powerful tool for characterizing human skin condition. To our knowledge, this is the first 3D approach to the segmentation and quantification of these original images.},
	language = {eng},
	number = {2},
	journal = {Skin research and technology: official journal of International Society for Bioengineering and the Skin (ISBS) [and] International Society for Digital Imaging of Skin (ISDIS) [and] International Society for Skin Imaging (ISSI)},
	author = {Decencière, Etienne and Tancrède-Bohin, Emmanuelle and Dokládal, Petr and Koudoro, Serge and Pena, Ana-Maria and Baldeweck, Thérèse},
	month = may,
	year = {2013},
	pmid = {23441573},
	pages = {115--124},
}

@article{altendorf_imaging_2012-1,
	title = {Imaging and {3D} morphological analysis of collagen fibrils},
	volume = {247},
	issn = {1365-2818},
	doi = {10.1111/j.1365-2818.2012.03629.x},
	abstract = {The recent booming of multiphoton imaging of collagen fibrils by means of second harmonic generation microscopy generates the need for the development and automation of quantitative methods for image analysis. Standard approaches sequentially analyse two-dimensional (2D) slices to gain knowledge on the spatial arrangement and dimension of the fibrils, whereas the reconstructed three-dimensional (3D) image yields better information about these characteristics. In this work, a 3D analysis method is proposed for second harmonic generation images of collagen fibrils, based on a recently developed 3D fibre quantification method. This analysis uses operators from mathematical morphology. The fibril structure is scanned with a directional distance transform. Inertia moments of the directional distances yield the main fibre orientation, corresponding to the main inertia axis. The collaboration of directional distances and fibre orientation delivers a geometrical estimate of the fibre radius. The results include local maps as well as global distribution of orientation and radius of the fibrils over the 3D image. They also bring a segmentation of the image into foreground and background, as well as a classification of the foreground pixels into the preferred orientations. This accurate determination of the spatial arrangement of the fibrils within a 3D data set will be most relevant in biomedical applications. It brings the possibility to monitor remodelling of collagen tissues upon a variety of injuries and to guide tissues engineering because biomimetic 3D organizations and density are requested for better integration of implants.},
	language = {eng},
	number = {2},
	journal = {Journal of microscopy},
	author = {Altendorf, H and Decencière, E and Jeulin, D and De sa Peixoto, P and Deniset-Besseau, A and Angelini, E and Mosser, G and Schanne-Klein, M-C},
	month = aug,
	year = {2012},
	pmid = {22670759},
	keywords = {Animals, Microscopy, Collagen, Imaging, Three-Dimensional, Macromolecular Substances, Protein Multimerization, Rats, Rats, Wistar},
	pages = {161--175},
}

@article{wolf_object_2006,
	title = {Object count/area graphs for the evaluation of object detection and segmentation algorithms},
	volume = {8},
	issn = {1433-2833, 1433-2825},
	url = {http://link.springer.com/article/10.1007/s10032-006-0014-0},
	doi = {10.1007/s10032-006-0014-0},
	abstract = {Evaluation of object detection algorithms is a non-trivial task: a detection result is usually evaluated by comparing the bounding box of the detected object with the bounding box of the ground truth object. The commonly used precision and recall measures are computed from the overlap area of these two rectangles. However, these measures have several drawbacks: they don't give intuitive information about the proportion of the correctly detected objects and the number of false alarms, and they cannot be accumulated across multiple images without creating ambiguity in their interpretation. Furthermore, quantitative and qualitative evaluation is often mixed resulting in ambiguous measures. In this paper we propose a new approach which tackles these problems. The performance of a detection algorithm is illustrated intuitively by performance graphs which present object level precision and recall depending on constraints on detection quality. In order to compare different detection algorithms, a representative single performance value is computed from the graphs. The influence of the test database on the detection performance is illustrated by performance/generality graphs. The evaluation method can be applied to different types of object detection algorithms. It has been tested on different text detection algorithms, among which are the participants of the ICDAR 2003 text detection competition.},
	language = {en},
	number = {4},
	urldate = {2013-05-17},
	journal = {International Journal of Document Analysis and Recognition (IJDAR)},
	author = {Wolf, Christian and Jolion, Jean-Michel},
	month = sep,
	year = {2006},
	keywords = {Image Processing and Computer Vision, Pattern recognition, object detection, Evaluation, Text detection},
	pages = {280--296},
	file = {Snapshot:/home/edecenciere/Zotero/storage/K6K93ZC4/s10032-006-0014-0.html:text/html},
}

@article{wolf_object_2006-1,
	title = {Object count/area graphs for the evaluation of object detection and segmentation algorithms},
	volume = {8},
	issn = {1433-2833, 1433-2825},
	url = {http://link.springer.com/article/10.1007/s10032-006-0014-0},
	doi = {10.1007/s10032-006-0014-0},
	abstract = {Evaluation of object detection algorithms is a non-trivial task: a detection result is usually evaluated by comparing the bounding box of the detected object with the bounding box of the ground truth object. The commonly used precision and recall measures are computed from the overlap area of these two rectangles. However, these measures have several drawbacks: they don't give intuitive information about the proportion of the correctly detected objects and the number of false alarms, and they cannot be accumulated across multiple images without creating ambiguity in their interpretation. Furthermore, quantitative and qualitative evaluation is often mixed resulting in ambiguous measures. In this paper we propose a new approach which tackles these problems. The performance of a detection algorithm is illustrated intuitively by performance graphs which present object level precision and recall depending on constraints on detection quality. In order to compare different detection algorithms, a representative single performance value is computed from the graphs. The influence of the test database on the detection performance is illustrated by performance/generality graphs. The evaluation method can be applied to different types of object detection algorithms. It has been tested on different text detection algorithms, among which are the participants of the ICDAR 2003 text detection competition.},
	language = {en},
	number = {4},
	urldate = {2013-05-17},
	journal = {International Journal of Document Analysis and Recognition (IJDAR)},
	author = {Wolf, Christian and Jolion, Jean-Michel},
	month = sep,
	year = {2006},
	keywords = {Image Processing and Computer Vision, Pattern recognition, object detection, Evaluation, Text detection},
	pages = {280--296},
	file = {Snapshot:/home/edecenciere/Zotero/storage/IFI87IR7/s10032-006-0014-0.html:text/html},
}

@article{wolf_object_2006-2,
	title = {Object count/area graphs for the evaluation of object detection and segmentation algorithms},
	volume = {8},
	issn = {1433-2833, 1433-2825},
	url = {http://link.springer.com/article/10.1007/s10032-006-0014-0},
	doi = {10.1007/s10032-006-0014-0},
	abstract = {Evaluation of object detection algorithms is a non-trivial task: a detection result is usually evaluated by comparing the bounding box of the detected object with the bounding box of the ground truth object. The commonly used precision and recall measures are computed from the overlap area of these two rectangles. However, these measures have several drawbacks: they don't give intuitive information about the proportion of the correctly detected objects and the number of false alarms, and they cannot be accumulated across multiple images without creating ambiguity in their interpretation. Furthermore, quantitative and qualitative evaluation is often mixed resulting in ambiguous measures. In this paper we propose a new approach which tackles these problems. The performance of a detection algorithm is illustrated intuitively by performance graphs which present object level precision and recall depending on constraints on detection quality. In order to compare different detection algorithms, a representative single performance value is computed from the graphs. The influence of the test database on the detection performance is illustrated by performance/generality graphs. The evaluation method can be applied to different types of object detection algorithms. It has been tested on different text detection algorithms, among which are the participants of the ICDAR 2003 text detection competition.},
	language = {en},
	number = {4},
	urldate = {2013-05-17},
	journal = {International Journal of Document Analysis and Recognition (IJDAR)},
	author = {Wolf, Christian and Jolion, Jean-Michel},
	month = sep,
	year = {2006},
	keywords = {Image Processing and Computer Vision, Pattern recognition, object detection, Evaluation, Text detection},
	pages = {280--296},
	file = {Snapshot:/home/edecenciere/Zotero/storage/4DKNMKVZ/s10032-006-0014-0.html:text/html},
}

@article{stewart_dual-bootstrap_2003,
	title = {The dual-bootstrap iterative closest point algorithm with application to retinal image registration},
	volume = {22},
	issn = {0278-0062},
	doi = {10.1109/TMI.2003.819276},
	abstract = {Motivated by the problem of retinal image registration, this paper introduces and analyzes a new registration algorithm called Dual-Bootstrap Iterative Closest Point (Dual-Bootstrap ICP). The approach is to start from one or more initial, low-order estimates that are only accurate in small image regions, called bootstrap regions. In each bootstrap region, the algorithm iteratively: 1) refines the transformation estimate using constraints only from within the bootstrap region; 2) expands the bootstrap region; and 3) tests to see if a higher order transformation model can be used, stopping when the region expands to cover the overlap between images. Steps 1): and 3), the bootstrap steps, are governed by the covariance matrix of the estimated transformation. Estimation refinement [Step 2)] uses a novel robust version of the ICP algorithm. In registering retinal image pairs, Dual-Bootstrap ICP is initialized by automatically matching individual vascular landmarks, and it aligns images based on detected blood vessel centerlines. The resulting quadratic transformations are accurate to less than a pixel. On tests involving approximately 6000 image pairs, it successfully registered 99.5\% of the pairs containing at least one common landmark, and 100\% of the pairs containing at least one common landmark and at least 35\% image overlap.},
	number = {11},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Stewart, C.V. and Tsai, Chia-Ling and Roysam, B.},
	year = {2003},
	keywords = {Algorithms, Robustness, Image analysis, Humans, Image Enhancement, Image Interpretation, Computer-Assisted, Pattern Recognition, Automated, Reproducibility of Results, Sensitivity and Specificity, Testing, medical image processing, eye, Fluorescein Angiography, Retina, Retinal Vessels, blood vessels, Retinal Diseases, iterative methods, Algorithm design and analysis, blood vessel centerlines, covariance matrices, covariance matrix, dual-bootstrap iterative closest point algorithm, estimation refinement, image alignment, image matching, image registration, individual vascular landmarks, Iterative algorithms, Iterative closest point algorithm, quadratic transformations, retinal image registration, Subtraction Technique},
	pages = {1379--1394},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/ARMXBDBN/articleDetails.html:text/html},
}

@article{erginay_ophdiat:_2008,
	title = {{OPHDIAT}©: {Quality}-assurance programme plan and performance of the network},
	volume = {34},
	issn = {1262-3636},
	shorttitle = {{OPHDIAT}©},
	url = {http://www.sciencedirect.com/science/article/pii/S1262363608000542},
	doi = {10.1016/j.diabet.2008.01.004},
	abstract = {Aims 
There is a need for evaluation of screening and grading services for diabetic retinopathy (DR) in compliance with quality-assurance (QA) standards. We describe the screening/grading QA programme set up for OPHDIAT© over the 2005–2006 period. 
Methods 
Screening and grading objectives, evaluation criteria and minimum acceptable QA standards were set. To ensure the quality of DR photos, the proportion of nongradable photos in at least one eye had to be less than 10\%. To ensure grading accuracy, intergrading agreement had to be greater than 90\%. Grader-generated reports had to be available in less than 48 h for more than 80\% photos. Readers had to grade 500 to 3000 photos per year. 
Results 
Sixteen screening centres were opened between June 2004 and December 2006, and 14,769 patients were screened. Percentages of nongradable photos were consistently below the QA requirement (less than 10\%). Overall, 800 photos were graded a second time by a reader blinded to original grading; agreement between graders ranged from 92 to 99\%. More than 90\% of grader-generated reports were produced within 48 h. The number of readings by each grader nearly achieved the QA standard. 
Conclusion 
QA for DR telescreening should be a continuous process to provide performance feedback, thus guaranteeing a high standard for delivered results. Almost all of the predetermined QA standards in OPHDIAT© for screening and grading were met. Besides the quality/sensitivity of the screening/grading modalities, it is important to evaluate at-risk patients so that they can be treated efficiently; this should be addressed in a global QA programme.},
	number = {3},
	urldate = {2013-04-03},
	journal = {Diabetes \& Metabolism},
	author = {Erginay, A. and Chabouis, A. and Viens-Bitker, C. and Robert, N. and Lecleire-Collet, A. and Massin, P.},
	month = jun,
	year = {2008},
	keywords = {Diabetic Retinopathy, Assurance Qualité, Dépistage, OPHDIAT©, Quality assurance, Rétinopathie diabétique, Screening, Télémédecine, Telemedicine},
	pages = {235--242},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/SWR4VGQK/S1262363608000542.html:text/html},
}

@article{abramoff_md_automated_2013,
	title = {{AUtomated} analysis of retinal images for detection of referable diabetic retinopathy},
	volume = {131},
	issn = {2168-6165},
	url = {http://dx.doi.org/10.1001/jamaophthalmol.2013.1743},
	doi = {10.1001/jamaophthalmol.2013.1743},
	abstract = {Importance  
                  The diagnostic accuracy of computer detection programs has been reported to be comparable to that of specialists and expert readers, but no computer detection programs have been validated in an independent cohort using an internationally recognized diabetic retinopathy (DR) standard.Objective  
                  To determine the sensitivity and specificity of the Iowa Detection Program (IDP) to detect referable diabetic retinopathy (RDR).Design and Setting  
                  In primary care DR clinics in France, from January 1, 2005, through December 31, 2010, patients were photographed consecutively, and retinal color images were graded for retinopathy severity according to the International Clinical Diabetic Retinopathy scale and macular edema by 3 masked independent retinal specialists and regraded with adjudication until consensus. The IDP analyzed the same images at a predetermined and fixed set point. We defined RDR as more than mild nonproliferative retinopathy and/or macular edema.Participants  
                  A total of 874 people with diabetes at risk for DR.Main Outcome Measures  
                  Sensitivity and specificity of the IDP to detect RDR, area under the receiver operating characteristic curve, sensitivity and specificity of the retinal specialists' readings, and mean interobserver difference (κ).Results  
                  The RDR prevalence was 21.7\% (95\% CI, 19.0\%-24.5\%). The IDP sensitivity was 96.8\% (95\% CI, 94.4\%-99.3\%) and specificity was 59.4\% (95\% CI, 55.7\%-63.0\%), corresponding to 6 of 874 false-negative results (none met treatment criteria). The area under the receiver operating characteristic curve was 0.937 (95\% CI, 0.916-0.959). Before adjudication and consensus, the sensitivity/specificity of the retinal specialists were 0.80/0.98, 0.71/1.00, and 0.91/0.95, and the mean intergrader κ was 0.822.Conclusions  
                  The IDP has high sensitivity and specificity to detect RDR. Computer analysis of retinal photographs for DR and automated detection of RDR can be implemented safely into the DR screening pipeline, potentially improving access to screening and health care productivity and reducing visual loss through early treatment.},
	number = {3},
	urldate = {2013-04-03},
	journal = {JAMA Ophthalmology},
	author = {Abràmoff MD, Folk JC},
	month = mar,
	year = {2013},
	pages = {351--357},
}

@article{wang_structure-sensitive_nodate,
	title = {Structure-{Sensitive} {Superpixels} via {Geodesic} {Distance}},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/article/10.1007/s11263-012-0588-6},
	doi = {10.1007/s11263-012-0588-6},
	abstract = {Segmenting images into superpixels as supporting regions for feature vectors and primitives to reduce computational complexity has been commonly used as a fundamental step in various image analysis and computer vision tasks. In this paper, we describe the structure-sensitive superpixel technique by exploiting Lloyd’s algorithm with the geodesic distance. Our method generates smaller superpixels to achieve relatively low under-segmentation in structure-dense regions with high intensity or color variation, and produces larger segments to increase computational efficiency in structure-sparse regions with homogeneous appearance. We adopt geometric flows to compute geodesic distances amongst pixels. In the segmentation procedure, the density of over-segments is automatically adjusted through iteratively optimizing an energy functional that embeds color homogeneity, structure density. Comparative experiments with the Berkeley database show that the proposed algorithm outperforms the prior arts while offering a comparable computational efficiency as TurboPixels. Further applications in image compression, object closure extraction and video segmentation demonstrate the effective extensions of our approach.},
	language = {en},
	urldate = {2013-03-14},
	journal = {International Journal of Computer Vision},
	author = {Wang, Peng and Zeng, Gang and Gan, Rui and Wang, Jingdong and Zha, Hongbin},
	keywords = {Artificial Intelligence (incl. Robotics), Image Processing and Computer Vision, Pattern recognition, Computer Imaging, Vision, Pattern Recognition and Graphics, Geodesic distance, Iterative optimization, Structure-sensitivity, Superpixel segmentation},
	pages = {1--21},
	file = {Snapshot:/home/edecenciere/Zotero/storage/DNFNS7A2/s11263-012-0588-6.html:text/html},
}

@article{tobin_detection_2007,
	title = {Detection of {Anatomic} {Structures} in {Human} {Retinal} {Imagery}},
	volume = {26},
	issn = {0278-0062},
	doi = {10.1109/TMI.2007.902801},
	abstract = {The widespread availability of electronic imaging devices throughout the medical community is leading to a growing body of research on image processing and analysis to diagnose retinal disease such as diabetic retinopathy (DR). Productive computer-based screening of large, at-risk populations at low cost requires robust, automated image analysis. In this paper we present results for the automatic detection of the optic nerve and localization of the macula using digital red-free fundus photography. Our method relies on the accurate segmentation of the vasculature of the retina followed by the determination of spatial features describing the density, average thickness, and average orientation of the vasculature in relation to the position of the optic nerve. Localization of the macula follows using knowledge of the optic nerve location to detect the horizontal raphe of the retina using a geometric model of the vasculature. We report 90.4\% detection performance for the optic nerve and 92.5\% localization performance for the macula for red-free fundus images representing a population of 345 images corresponding to 269 patients with 18 different pathologies associated with DR and other common retinal diseases such as age-related macular degeneration.},
	number = {12},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Tobin, Kenneth W. and Chaum, Edward and Govindasamy, V.P. and Karnowski, T.P.},
	month = dec,
	year = {2007},
	keywords = {Image segmentation, Algorithms, Feature extraction, Humans, Artificial Intelligence, Image Interpretation, Computer-Assisted, Pattern Recognition, Automated, Sensitivity and Specificity, biomedical optical imaging, Image Processing, Computer-Assisted, medical image processing, Diabetic Retinopathy, eye, Fluorescein Angiography, Retina, Retinal Vessels, Retinal Diseases, Image Processing, diseases, anatomic structures, Automated image analysis, automatic detection, Bayesian classifier, computer-based screening, digital fundus photography, feature analysis, Fundus Oculi, human retinal imagery, IEEE electronic imaging devices, macula localization, Macula Lutea, optic nerve, optic nerve detection, Photography, red-free fundus imagery, red-free fundus photography, retinal disease diagnosis, vascular segmentation, vasculature segmentation},
	pages = {1729--1739},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/HKG5TIGR/abs_all.html:text/html},
}

@article{tobin_detection_nodate,
	title = {Detection of {Anatomic} {Structures} in {Human} {Retinal} {Imagery}},
	volume = {26},
	issn = {0278-0062},
	doi = {10.1109/TMI.2007.902801},
	abstract = {The widespread availability of electronic imaging devices throughout the medical community is leading to a growing body of research on image processing and analysis to diagnose retinal disease such as diabetic retinopathy (DR). Productive computer-based screening of large, at-risk populations at low cost requires robust, automated image analysis. In this paper we present results for the automatic detection of the optic nerve and localization of the macula using digital red-free fundus photography. Our method relies on the accurate segmentation of the vasculature of the retina followed by the determination of spatial features describing the density, average thickness, and average orientation of the vasculature in relation to the position of the optic nerve. Localization of the macula follows using knowledge of the optic nerve location to detect the horizontal raphe of the retina using a geometric model of the vasculature. We report 90.4\% detection performance for the optic nerve and 92.5\% localization performance for the macula for red-free fundus images representing a population of 345 images corresponding to 269 patients with 18 different pathologies associated with DR and other common retinal diseases such as age-related macular degeneration.},
	number = {12},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Tobin, Kenneth W. and Chaum, Edward and Govindasamy, V.P. and Karnowski, T.P.},
	month = dec,
	keywords = {Image segmentation, Algorithms, Feature extraction, Humans, Artificial Intelligence, Image Interpretation, Computer-Assisted, Pattern Recognition, Automated, Sensitivity and Specificity, biomedical optical imaging, Image Processing, Computer-Assisted, medical image processing, Diabetic Retinopathy, eye, Fluorescein Angiography, Retina, Retinal Vessels, Retinal Diseases, Image Processing, diseases, anatomic structures, Automated image analysis, automatic detection, Bayesian classifier, computer-based screening, digital fundus photography, feature analysis, Fundus Oculi, human retinal imagery, IEEE electronic imaging devices, macula localization, Macula Lutea, optic nerve, optic nerve detection, Photography, red-free fundus imagery, red-free fundus photography, retinal disease diagnosis, vascular segmentation, vasculature segmentation},
	pages = {1729--1739},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/DQSTSNBI/abs_all.html:text/html},
}

@article{wolf_ja_diagnostic_2013,
	title = {{DIagnostic} inaccuracy of smartphone applications for melanoma detection},
	issn = {2168-6068},
	url = {http://dx.doi.org/10.1001/jamadermatol.2013.2382},
	doi = {10.1001/jamadermatol.2013.2382},
	abstract = {Objective  
                  To measure the performance of smartphone applications that evaluate photographs of skin lesions and provide the user with feedback about the likelihood of malignancy.Design  
                  Case-control diagnostic accuracy study.Setting  
                  Academic dermatology department.Participants and Materials  
                  Digital clinical images of pigmented cutaneous lesions (60 melanoma and 128 benign control lesions) with a histologic diagnosis rendered by a board-certified dermatopathologist, obtained before biopsy from patients undergoing lesion removal as a part of routine care.Main Outcome Measures  
                  Sensitivity, specificity, and positive and negative predictive values of 4 smartphone applications designed to aid nonclinician users in determining whether their skin lesion is benign or malignant.Results  
                  Sensitivity of the 4 tested applications ranged from 6.8\% to 98.1\%; specificity, 30.4\% to 93.7\%; positive predictive value, 33.3\% to 42.1\%; and negative predictive value, 65.4\% to 97.0\%. The highest sensitivity for melanoma diagnosis was observed for an application that sends the image directly to a board-certified dermatologist for analysis; the lowest, for applications that use automated algorithms to analyze images.Conclusions  
                  The performance of smartphone applications in assessing melanoma risk is highly variable, and 3 of 4 smartphone applications incorrectly classified 30\% or more of melanomas as unconcerning. Reliance on these applications, which are not subject to regulatory oversight, in lieu of medical consultation can delay the diagnosis of melanoma and harm users.},
	urldate = {2013-03-08},
	journal = {JAMA Dermatology},
	author = {Wolf JA, Moreau J},
	month = jan,
	year = {2013},
	pages = {1--4},
}

@article{agurto_automatic_2011,
	title = {Automatic {Detection} of {Diabetic} {Retinopathy} and {Age}-{Related} {Macular} {Degeneration} in {Digital} {Fundus} {Images}},
	volume = {52},
	issn = {, 1552-5783},
	url = {http://www.iovs.org/content/52/8/5862},
	doi = {10.1167/iovs.10-7075},
	abstract = {Purpose. To describe and evaluate the performance of an algorithm that automatically classifies images with pathologic features commonly found in diabetic retinopathy (DR) and age-related macular degeneration (AMD).
Methods. Retinal digital photographs (N = 2247) of three fields of view (FOV) were obtained of the eyes of 822 patients at two centers: The Retina Institute of South Texas (RIST, San Antonio, TX) and The University of Texas Health Science Center San Antonio (UTHSCSA). Ground truth was provided for the presence of pathologic conditions, including microaneurysms, hemorrhages, exudates, neovascularization in the optic disc and elsewhere, drusen, abnormal pigmentation, and geographic atrophy. The algorithm was used to report on the presence or absence of disease. A detection threshold was applied to obtain different values of sensitivity and specificity with respect to ground truth and to construct a receiver operating characteristic (ROC) curve.
Results. The system achieved an average area under the ROC curve (AUC) of 0.89 for detection of DR and of 0.92 for detection of sight-threatening DR (STDR). With a fixed specificity of 0.50, the system's sensitivity ranged from 0.92 for all DR cases to 1.00 for clinically significant macular edema (CSME).
Conclusions. A computer-aided algorithm was trained to detect different types of pathologic retinal conditions. The cases of hard exudates within 1 disc diameter (DD) of the fovea (surrogate for CSME) were detected with very high accuracy (sensitivity = 1, specificity = 0.50), whereas mild nonproliferative DR was the most challenging condition (sensitivity= 0.92, specificity = 0.50). The algorithm was also tested on images with signs of AMD, achieving a performance of AUC of 0.84 (sensitivity = 0.94, specificity = 0.50).},
	language = {en},
	number = {8},
	urldate = {2013-03-08},
	journal = {Investigative Ophthalmology \& Visual Science},
	author = {Agurto, Carla and Barriga, E. Simon and Murray, Victor and Nemeth, Sheila and Crammer, Robert and Bauman, Wendall and Zamora, Gilberto and Pattichis, Marios S. and Soliz, Peter},
	month = jan,
	year = {2011},
	pages = {5862--5871},
	file = {Snapshot:/home/edecenciere/Zotero/storage/KBQJFDHQ/5862.html:text/html},
}

@article{abramoff_evaluation_2008,
	title = {Evaluation of a {System} for {Automatic} {Detection} of {Diabetic} {Retinopathy} {From} {Color} {Fundus} {Photographs} in a {Large} {Population} of {Patients} {With} {Diabetes}},
	volume = {31},
	issn = {0149-5992, 1935-5548},
	url = {http://care.diabetesjournals.org/content/31/2/193},
	doi = {10.2337/dc07-1312},
	abstract = {OBJECTIVE—To evaluate the performance of a system for automated detection of diabetic retinopathy in digital retinal photographs, built from published algorithms, in a large, representative, screening population.
RESEARCH DESIGN AND METHODS—We conducted a retrospective analysis of 10,000 consecutive patient visits, specifically exams (four retinal photographs, two left and two right) from 5,692 unique patients from the EyeCheck diabetic retinopathy screening project imaged with three types of cameras at 10 centers. Inclusion criteria included no previous diagnosis of diabetic retinopathy, no previous visit to ophthalmologist for dilated eye exam, and both eyes photographed. One of three retinal specialists evaluated each exam as unacceptable quality, no referable retinopathy, or referable retinopathy. We then selected exams with sufficient image quality and determined presence or absence of referable retinopathy. Outcome measures included area under the receiver operating characteristic curve (number needed to miss one case [NNM]) and type of false negative.
RESULTS—Total area under the receiver operating characteristic curve was 0.84, and NNM was 80 at a sensitivity of 0.84 and a specificity of 0.64. At this point, 7,689 of 10,000 exams had sufficient image quality, 4,648 of 7,689 (60\%) were true negatives, 59 of 7,689 (0.8\%) were false negatives, 319 of 7,689 (4\%) were true positives, and 2,581 of 7,689 (33\%) were false positives. Twenty-seven percent of false negatives contained large hemorrhages and/or neovascularizations.
CONCLUSIONS—Automated detection of diabetic retinopathy using published algorithms cannot yet be recommended for clinical practice. However, performance is such that evaluation on validated, publicly available datasets should be pursued. If algorithms can be improved, such a system may in the future lead to improved prevention of blindness and vision loss in patients with diabetes.},
	language = {en},
	number = {2},
	urldate = {2013-03-08},
	journal = {Diabetes Care},
	author = {Abràmoff, Michael D. and Niemeijer, Meindert and Suttorp-Schulten, Maria S. A. and Viergever, Max A. and Russell, Stephen R. and Ginneken, Bram van},
	month = jan,
	year = {2008},
	keywords = {ETDRS, Early Treatment Diabetic Retinopathy Study, NNM, number needed to miss one case, ROC, receiver operator characteristic},
	pages = {193--198},
	file = {Snapshot:/home/edecenciere/Zotero/storage/V3ZA324X/193.html:text/html},
}

@article{scotland_cost-effectiveness_2007,
	title = {Cost-effectiveness of implementing automated grading within the national screening programme for diabetic retinopathy in {Scotland}},
	volume = {91},
	issn = {, 1468-2079},
	url = {http://bjo.bmj.com/content/91/11/1518},
	doi = {10.1136/bjo.2007.120972},
	abstract = {Aims: National screening programmes for diabetic retinopathy using digital photography and multi-level manual grading systems are currently being implemented in the UK. Here, we assess the cost-effectiveness of replacing first level manual grading in the National Screening Programme in Scotland with an automated system developed to assess image quality and detect the presence of any retinopathy.
Methods: A decision tree model was developed and populated using sensitivity/specificity and cost data based on a study of 6722 patients in the Grampian region. Costs to the NHS, and the number of appropriate screening outcomes and true referable cases detected in 1 year were assessed.
Results: For the diabetic population of Scotland (approximately 160 000), with prevalence of referable retinopathy at 4\% (6400 true cases), the automated strategy would be expected to identify 5560 cases (86.9\%) and the manual strategy 5610 cases (87.7\%). However, the automated system led to savings in grading and quality assurance costs to the NHS of £201 600 per year. The additional cost per additional referable case detected (manual vs automated) totalled £4088 and the additional cost per additional appropriate screening outcome (manual vs automated) was £1990.
Conclusions: Given that automated grading is less costly and of similar effectiveness, it is likely to be considered a cost-effective alternative to manual grading.},
	language = {en},
	number = {11},
	urldate = {2013-03-08},
	journal = {British Journal of Ophthalmology},
	author = {Scotland, G. S. and McNamee, P. and Philip, S. and Fleming, A. D. and Goatman, K. A. and Prescott, G. J. and Fonseca, S. and Sharp, P. F. and Olson, J. A.},
	month = jan,
	year = {2007},
	pages = {1518--1523},
	file = {Snapshot:/home/edecenciere/Zotero/storage/7H8C5CBF/1518.html:text/html},
}

@article{ram_successive_2011,
	title = {A {Successive} {Clutter}-{Rejection}-{Based} {Approach} for {Early} {Detection} of {Diabetic} {Retinopathy}},
	volume = {58},
	issn = {0018-9294},
	doi = {10.1109/TBME.2010.2096223},
	abstract = {The presence of microaneurysms (MAs) is usually an early sign of diabetic retinopathy and their automatic detection from color retinal images is of clinical interest. In this paper, we present a new approach for automatic MA detection from digital color fundus images. We formulate MA detection as a problem of target detection from clutter, where the probability of occurrence of target is considerably smaller compared to the clutter. A successive rejection-based strategy is proposed to progressively lower the number of clutter responses. The processing stages are designed to reject specific classes of clutter while passing majority of true MAs, using a set of specialized features. The true positives that remain after the final rejector are assigned a score which is based on its similarity to a true MA. Results of extensive evaluation of the proposed approach on three different retinal image datasets are reported, and used to highlight the promise in the presented strategy.},
	number = {3},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Ram, K. and Joshi, G.D. and Sivaswamy, J.},
	month = mar,
	year = {2011},
	keywords = {Algorithms, object detection, Pixel, Feature extraction, target detection, Humans, Image color analysis, Image Processing, Computer-Assisted, medical image processing, image colour analysis, Diabetic Retinopathy, eye, Retina, Retinal Vessels, diseases, Aneurysm, Clutter, Clutter-rejection, color retinal image, Context, Diagnostic Techniques, Ophthalmological, digital color fundus image, microaneurysm, Noise, retinal image, successive clutter-rejection-based approach},
	pages = {664 --673},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/RC7TWJFK/abs_all.html:text/html},
}

@article{dupas_evaluation_2010,
	title = {Evaluation of automated fundus photograph analysis algorithms for detecting microaneurysms, haemorrhages and exudates, and of a computer-assisted diagnostic system for grading diabetic retinopathy},
	volume = {36},
	issn = {1262-3636},
	url = {http://www.sciencedirect.com/science/article/pii/S126236361000042X},
	doi = {10.1016/j.diabet.2010.01.002},
	abstract = {Aims 
This study aimed to evaluate automated fundus photograph analysis algorithms for the detection of primary lesions and a computer-assisted diagnostic system for grading diabetic retinopathy (DR) and the risk of macular edema (ME). 
Methods 
Two prospective analyses were conducted on fundus images from diabetic patients. Automated detection of microaneurysms and exudates was applied to two small image databases on which these lesions were manually marked. A computer-assisted diagnostic system for the detection and grading of DR and the risk of ME was then developed and evaluated, using a large database containing both normal and pathological images, and compared with manual grading. 
Results 
The algorithm for the automated detection of microaneurysms demonstrated a sensitivity of 88.5\%, with an average number of 2.13 false positives per image. The pixel-based evaluation of the algorithm for automated detection of exudates had a sensitivity of 92.8\% and a positive predictive value of 92.4\%. Combined automated grading of DR and risk of ME was performed on 761 images from a large database. For DR detection, the sensitivity and specificity of the algorithm were 83.9\% and 72.7\%, respectively, and, for detection of the risk of ME, the sensitivity and specificity were 72.8\% and 70.8\%, respectively. 
Conclusion 
This study shows that previously published algorithms for computer-aided diagnosis is a reliable alternative to time-consuming manual analysis of fundus photographs when screening for DR. The use of this system would allow considerable timesavings for physicians and, therefore, alleviate the time spent on a mass-screening programme.},
	number = {3},
	urldate = {2013-02-26},
	journal = {Diabetes \& Metabolism},
	author = {Dupas, B. and Walter, T. and Erginay, A. and Ordonez, R. and Deb-Joardar, N. and Gain, P. and Klein, J.-C. and Massin, P.},
	month = jun,
	year = {2010},
	keywords = {Diabetic Retinopathy, Dépistage, Rétinopathie diabétique, Screening, Automated image analysis, Analyse automatique d’image, Fundus photography, Macular edema, Œdème maculaire, Photographies du fond d’œil},
	pages = {213--220},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/F84KHQ5K/S126236361000042X.html:text/html},
}

@article{anitha_automated_2012,
	title = {Automated multi-level pathology identification techniques for abnormal retinal images using artificial neural networks},
	volume = {96},
	issn = {, 1468-2079},
	url = {http://bjo.bmj.com/content/96/2/220},
	doi = {10.1136/bjophthalmol-2011-300032},
	abstract = {Aim To automatically classify abnormal retinal images from four different categories using artificial neural networks with a high degree of accuracy in minimal time to assist the ophthalmologist in subsequent treatment planning.
Methods We used 420 abnormal retinal images from four different categories (non-proliferative diabetic retinopathy, central retinal vein occlusion, central serous retinopathy and central neo-vascularisation membrane). Green channel extraction, histogram equalisation and median filtering were used as image pre-processing techniques, followed by texture-based feature extraction. The application of Kohonen neural networks for pathology identification was also explored.
Results The approach described yielded an average classification accuracy of 97.7\% with ±0.8\% deviation for individual categories. The average sensitivity and the specificity values are 96\% and 98\%, respectively. The time taken by the Kohonen neural network to achieve these accurate results was 300±40 s for the 420 images.
Conclusion This study suggests that the approach described can act as a diagnostic tool for retinal disease identification. Simultaneous multi-level classification of abnormal images is possible with high accuracy using artificial neural networks. The results also suggest that the approach is time-efficient, which is essential for ophthalmologic applications.},
	language = {en},
	number = {2},
	urldate = {2013-02-26},
	journal = {British Journal of Ophthalmology},
	author = {Anitha, J. and Vijila, C. Kezi Selva and Selvakumar, A. Immanuel and Indumathy, A. and Hemanth, D. Jude},
	month = jan,
	year = {2012},
	keywords = {retinal images, diagnosis \& ANN, diagnostic tests/investigation, imaging, Pathologies, pathology},
	pages = {220--223},
	file = {Snapshot:/home/edecenciere/Zotero/storage/XBBBAHQ9/220.html:text/html},
}

@article{philip_efficacy_2007,
	title = {The efficacy of automated “disease/no disease” grading for diabetic retinopathy in a systematic screening programme},
	volume = {91},
	issn = {, 1468-2079},
	url = {http://bjo.bmj.com/content/91/11/1512},
	doi = {10.1136/bjo.2007.119453},
	language = {en},
	number = {11},
	urldate = {2013-02-26},
	journal = {British Journal of Ophthalmology},
	author = {Philip, S. and Fleming, A. D. and Goatman, K. A. and Fonseca, S. and Mcnamee, P. and Scotland, G. S. and Prescott, G. J. and Sharp, P. F. and Olson, J. A.},
	month = jan,
	year = {2007},
	pages = {1512--1517},
	file = {Snapshot:/home/edecenciere/Zotero/storage/KCSVMWMA/1512.html:text/html},
}

@article{felzenszwalb_efficient_2004,
	title = {Efficient {Graph}-{Based} {Image} {Segmentation}},
	volume = {59},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/article/10.1023/B%3AVISI.0000022288.19776.77},
	doi = {10.1023/B:VISI.0000022288.19776.77},
	abstract = {This paper addresses the problem of segmenting an image into regions. We define a predicate for measuring the evidence for a boundary between two regions using a graph-based representation of the image. We then develop an efficient segmentation algorithm based on this predicate, and show that although this algorithm makes greedy decisions it produces segmentations that satisfy global properties. We apply the algorithm to image segmentation using two different kinds of local neighborhoods in constructing the graph, and illustrate the results with both real and synthetic images. The algorithm runs in time nearly linear in the number of graph edges and is also fast in practice. An important characteristic of the method is its ability to preserve detail in low-variability image regions while ignoring detail in high-variability regions.},
	language = {en},
	number = {2},
	urldate = {2013-02-15},
	journal = {International Journal of Computer Vision},
	author = {Felzenszwalb, Pedro F. and Huttenlocher, Daniel P.},
	month = sep,
	year = {2004},
	keywords = {Image segmentation, Artificial Intelligence (incl. Robotics), Image Processing, clustering, Automation and Robotics, Computer Imaging, Graphics and Computer Vision, graph algorithm, perceptual organization},
	pages = {167--181},
	file = {Snapshot:/home/edecenciere/Zotero/storage/5FU54TEH/10.1023BVISI.0000022288.19776.html:text/html},
}

@inproceedings{boykov_fast_1999,
	address = {Kerkyra, Greece},
	title = {Fast {Approximate} {Energy} {Minimization} via {Graph} {Cuts}},
	volume = {1},
	booktitle = {Proceedings of the {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Boykov, Y. and Veksler, O. and Zabih, R.},
	month = sep,
	year = {1999},
	pages = {377--384},
}

@inproceedings{beucher_use_1979,
	address = {Rennes, France},
	title = {Use of watersheds in contour detection},
	booktitle = {International workshop on image processing, real-time edge and motion detection},
	author = {Beucher, S. and Lantuéjoul, C.},
	month = sep,
	year = {1979},
}

@article{morard_one-dimensional_2012,
	title = {One-dimensional openings, granulometries and component trees in {O}(1) per pixel},
	volume = {PP},
	issn = {1932-4553},
	doi = {10.1109/JSTSP.2012.2201694},
	abstract = {We introduce a new, efficient and adaptable algorithm to compute openings, granulometries and the component tree for onedimensional (1-D) signals. The algorithm requires only one scan of the signal, runs in place in O(1) per pixel, and supports any scalar data precision (integer or floating-point data). The algorithm is applied to two-dimensional images along straight lines, in arbitrary orientations. Oriented size distributions can thus be efficiently computed, and textures characterised. Extensive benchmarks are reported. They show that the proposed algorithm allows computing 1-D openings faster than existing algorithms for data precisions higher than 8 bits, and remains competitive with respect to the algorithm proposed by Van Droogenbroeck when dealing with 8-bit images. When computing granulometries, the new algorithm runs faster than any other method of the state of the art. Moreover, it allows efficient computation of 1-D component trees.},
	number = {99},
	journal = {IEEE Journal of Selected Topics in Signal Processing},
	author = {Morard, V. and Dokladal, P. and Decenciere, E.},
	year = {2012},
	pages = {1},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/FC99DASP/articleDetails.html:text/html},
}

@article{walter_automatic_2007,
	title = {Automatic detection of microaneurysms in color fundus images},
	volume = {11},
	issn = {1361-8415},
	doi = {10.1016/j.media.2007.05.001},
	abstract = {This paper addresses the automatic detection of microaneurysms in color fundus images, which plays a key role in computer assisted diagnosis of diabetic retinopathy, a serious and frequent eye disease. The algorithm can be divided into four steps. The first step consists in image enhancement, shade correction and image normalization of the green channel. The second step aims at detecting candidates, i.e. all patterns possibly corresponding to MA, which is achieved by diameter closing and an automatic threshold scheme. Then, features are extracted, which are used in the last step to automatically classify candidates into real MA and other objects; the classification relies on kernel density estimation with variable bandwidth. A database of 21 annotated images has been used to train the algorithm. The algorithm was compared to manually obtained gradings of 94 images; sensitivity was 88.5\% at an average number of 2.13 false positives per image.},
	number = {6},
	journal = {Medical image analysis},
	author = {Walter, Thomas and Massin, Pascale and Erginay, Ali and Ordonez, Richard and Jeulin, Clotilde and Klein, Jean-Claude},
	month = dec,
	year = {2007},
	pmid = {17950655},
	keywords = {Algorithms, Humans, Image Interpretation, Computer-Assisted, Sensitivity and Specificity, Diabetic Retinopathy, Retinal Vessels, Photography, Aneurysm, Diagnosis, Computer-Assisted, False Positive Reactions, Retinal Hemorrhage},
	pages = {555--566},
}

@article{querleux_skin_2009,
	title = {Skin from various ethnic origins and aging: an in vivo cross-sectional multimodality imaging study},
	volume = {15},
	issn = {1600-0846},
	shorttitle = {Skin from various ethnic origins and aging},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19624427},
	doi = {10.1111/j.1600-0846.2009.00365.x},
	abstract = {BACKGROUND

Ethnic differences in skin structural features have not been thoroughly investigated, and the few reported studies are contradictory. Thus, we have carried out a set of in vivo measurements on the skin of about 400 volunteers from various ethnic origins living in the same environment.


METHODS

Female subjects were distributed into four ethnic groups: African Americans, Mexicans, Caucasians, and Chinese. Inter- and intra-ethnic skin structural differences, according to age and anatomic site, were investigated using three non-invasive skin-imaging methods: ultrasound (US) at 25 and 150 MHz, and optical coherence tomography (OCT).


RESULTS

The thickness of the skin is higher on the cheek compared with the dorsal and ventral forearm, with no ethnic or age-related specificity. We confirm that the sub-epidermal non-echogenic band is a sensitive marker of skin aging, and reveal for the first time that it is less pronounced in African Americans. From OCT images, we bring out evidence that the thickness of the dermal-epidermal junction (DEJ) decreased with age, and was higher in African Americans than in Caucasians. Finally, by comparing US images at 150 MHz with OCT images, we show that papillary dermis thickness can be measured and appears to be quite constant irrespective of age or ethnic group.


CONCLUSION

Our study confirms that skin imaging is very attractive to further our knowledge of the morphology of skin from various ethnic origins. Regarding age effects, quantitative parameters have shown that they would be delayed in African Americans compared with all other ethnic populations.},
	number = {3},
	urldate = {2011-11-04},
	journal = {Skin Research and Technology},
	author = {Querleux, B. and Baldeweck, T. and Diridollou, S. and de Rigal, J. and Huguet, E. and Leroy, F. and Holloway Barbosa, V.},
	year = {2009},
	keywords = {Humans, Female, skin, Adolescent, Adult, African Americans, Age Distribution, Aged, Aging, Asian Americans, European Continental Ancestry Group, Male, Mexican Americans, Middle Aged, United States, Young Adult},
	pages = {306--313},
}

@article{lavker_aged_1987,
	title = {Aged skin: a study by light, transmission electron, and scanning electron microscopy},
	volume = {88},
	issn = {0022-202X},
	shorttitle = {Aged skin},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/3546515},
	abstract = {The fine structural organization of the epidermis, dermal/epidermal junction, and dermis from an unexposed site (upper inner arm) of elderly people was compared with the organization of a similar region of young people. Despite an overall thinning of the epidermis and focal areas of cytologic atypia, the characteristic morphological markers associated with the keratinization process are not markedly altered in appearance or amount. A well-formed stratum corneum consisting of flattened, enucleated horny cells enveloped by a thickened membrane, and intracellular spaces filled with electron-dense material provide structural evidence that barrier ability is not compromised in senile skin. The dermal/epidermal changes in aged skin are marked and have significant physiologic implications. The major change is a relatively flat dermal/epidermal junction resulting from the retraction of the epidermal papillae as well as the microprojections of basal cells into the dermis. This flattening results in a more fragile epidermal/dermal interface and, consequently, the epidermis is less resistant to shearing forces. Retraction of the epidermal downgrowths (preferential sites of the putative epidermal stem cell) may also explain the loss in proliferative capacity associated with the aged epidermis. The three-dimensional arrangements of collagen and elastic fibers showed marked alterations with age. Both fibrous components appear more compact because of a decrease in spaces between the fibers. Collagen bundles appear to unravel, and the individual elastic fibers show signs of elastosis. These changes may contribute to the loss of resilience that is one of the salient features of senile skin.},
	number = {3 Suppl},
	urldate = {2011-11-04},
	journal = {The Journal of Investigative Dermatology},
	author = {Lavker, R.M. and Zheng, P.S. and Dong, G.},
	year = {1987},
	keywords = {Humans, skin, Collagen, Adult, Aging, Elastin, epidermis, Microscopy, Electron, Microscopy, Electron, Scanning},
	pages = {44s--51s},
}

@article{kaatz_depth-resolved_2010,
	title = {Depth-resolved measurement of the dermal matrix composition by multiphoton laser tomography},
	volume = {16},
	issn = {1600-0846},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20456091},
	doi = {10.1111/j.1600-0846.2009.00423.x},
	abstract = {BACKGROUND

In the last years, multiphoton laser tomography (MLT) has emerged as a promising tool for non-invasive diagnostics in dermatology and other medical specialties. The present work is dedicated to the question to what degree the measurement depth and the thickness of the epidermis influence the evaluation of dermal matrix composition and if recommendations for future measurement procedures can be given.


METHODS

In a study group of 30 healthy volunteers aged 21-82 years multiphoton depth-resolved measurements of autofluorescence and second harmonics have been performed in order to evaluate the dermal matrix composition.


RESULTS

Characteristic intensity curves depending on the penetration depth were derived and differences between age groups were found.


CONCLUSION

With the present work we provide evidence for the accuracy of the measurement of dermal matrix composition by MLT and give detailed advice for the measurement procedure. Furthermore, we propose the use of depth-dependent emission intensity curves for monitoring of anti-aging treatment.},
	number = {2},
	urldate = {2011-11-04},
	journal = {Skin Research and Technology},
	author = {Kaatz, Martin and Sturm, Anne and Elsner, Peter and König, Karsten and Bückle, Rainer and Koehler, Martin Johannes},
	year = {2010},
	keywords = {Humans, Microscopy, Fluorescence, Multiphoton, Adult, Aged, Middle Aged, Young Adult, epidermis, Age Factors, Aged, 80 and over, Dermis, Dermoscopy, Lasers, Skin Aging},
	pages = {131--136},
}

@article{walter_contribution_2002,
	title = {A contribution of image processing to the diagnosis of diabetic retinopathy--detection of exudates in color fundus images of the human retina},
	volume = {21},
	issn = {0278-0062},
	doi = {10.1109/TMI.2002.806290},
	abstract = {In the framework of computer assisted diagnosis of diabetic retinopathy, a new algorithm for detection of exudates is presented and discussed. The presence of exudates within the macular region is a main hallmark of diabetic macular edema and allows its detection with a high sensitivity. Hence, detection of exudates is an important diagnostic task, in which computer assistance may play a major role. Exudates are found using their high grey level variation, and their contours are determined by means of morphological reconstruction techniques. The detection of the optic disc is indispensable for this approach. We detect the optic disc by means of morphological filtering techniques and the watershed transformation. The algorithm has been tested on a small image data base and compared with the performance of a human grader. As a result, we obtain a mean sensitivity of 92.8\% and a mean predictive value of 92.4\%. Robustness with respect to changes of the parameters of the algorithm has been evaluated.},
	number = {10},
	journal = {IEEE transactions on medical imaging},
	author = {Walter, Thomas and Klein, Jean-Claude and Massin, Pascale and Erginay, Ali},
	month = oct,
	year = {2002},
	pmid = {12585705},
	keywords = {Algorithms, Humans, Image Enhancement, Image Interpretation, Computer-Assisted, Pattern Recognition, Automated, Reproducibility of Results, Sensitivity and Specificity, Color, Diabetic Retinopathy, Fluorescein Angiography, Ophthalmoscopy, Retina, Fundus Oculi, Exudates and Transudates, Observer Variation, Ophthalmoscopes, Optic Disk, Quality Control},
	pages = {1236--1243},
}

@article{lin_evaluating_2005-1,
	title = {Evaluating cutaneous photoaging by use of multiphoton fluorescence and second-harmonic generation microscopy},
	volume = {30},
	issn = {0146-9592},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/16190442},
	abstract = {The photoaging process of facial skin is investigated by use of multiphoton fluorescence and second-harmonic generation (SHG) microscopy. We obtain the autofluorescence (AF) and SHG images of the superficial dermis from the facial skin of three patients aged 20, 40, and 70 years. The results show that areas of AF increase with age, whereas areas of SHG decrease with age. The results are consistent with the histological findings in which collagen is progressively replaced by elastic fibers. The AF and SHG changes in photoaging are quantified by a SHG to autofluorescence aging index of dermis (SAAID). Our results suggest that SAAID can be a good indicator of the severity of photoaging.},
	number = {17},
	urldate = {2012-05-29},
	journal = {Optics letters},
	author = {Lin, Sung-Jan and Wu, Jr, Ruei- and Tan, Hsin-Yuan and Lo, Wen and Lin, Wei-Chou and Young, Tai-Horng and Hsu, Chih-Jung and Chen, Jau-Shiuh and Jee, Shiou-Hwa and Dong, Chen-Yuan},
	month = sep,
	year = {2005},
	pmid = {16190442},
	keywords = {Humans, Image Enhancement, Image Interpretation, Computer-Assisted, Microscopy, Phase-Contrast, Microscopy, Fluorescence, Multiphoton, Adult, Aged, Skin Aging},
	pages = {2275--2277},
}

@article{piccolino_electronic_1979,
	title = {Electronic image analysis in retinal fluoroangiography},
	volume = {179},
	issn = {0030-3755},
	abstract = {The authors describe an original method of fluororetinographic densitometry based on electronic image analysis. They suggest practical applications of this method and report morphologic and quantitative results of their preliminary study.},
	number = {3},
	journal = {Ophthalmologica},
	author = {Piccolino, F C and Zingirian, M and Parodi, G C},
	year = {1979},
	pmid = {95040},
	keywords = {Humans, Color, Fluorescein Angiography, Macula Lutea, Densitometry, Neovascularization, Pathologic, Retinal Detachment},
	pages = {142--147},
}

@article{sauermann_age_2002,
	title = {Age related changes of human skin investigated with histometric measurements by confocal laser scanning microscopy in vivo},
	volume = {8},
	issn = {0909-752X},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/12005120},
	abstract = {BACKGROUND/AIMS

The confocal laser scanning microscope Vivascope (Lucid, Henrietta) allows skin to be studied in real-time with a resolution of 0.5 microm horizontal and 1.3 microm vertical in vivo. In this study, we present the results of a comparison between the skin of an older and a younger group of volunteers by in vivo histometric measurements.


METHODS

To investigate changes caused by age, 13 young (18-25years) and 13 older ({\textgreater}65years) volunteers were examined. The following parameters were measured using the Vivascope at the volar forearm: minimal thickness of the epidermis (E(min)), size of cells in the granular layer (A(gran)), thickness of the horny layer (DSC), thickness of the basal layer (DSB) and number of dermal papillae per area (Papl). The image analysis program image tool was used to measure the size of the cells and the thickness of the basal layer.


RESULTS

The older group of volunteers showed a significant increase in E(min), no significant change in DSC, a significant decrease in dermal papillae and in the thickness of the basal layer, and an increase in A(gran) compared to the younger group.


CONCLUSIONS

Histometric measurements by in vivo confocal laser scanning microscopy are a sensitive and non-invasive tool for characterizing and quantifying histological changes of the epidermis and papillary dermis due to ageing.},
	number = {1},
	urldate = {2011-11-04},
	journal = {Skin Research and Technology},
	author = {Sauermann, K. and Clemann, S. and Jaspers, S. and Gambichler, T. and Altmeyer, P. and Hoffmann, K. and Ennen, J.},
	year = {2002},
	keywords = {Humans, Female, Image Processing, Computer-Assisted, Adolescent, Adult, Aged, Male, epidermis, Dermis, Skin Aging, Evaluation Studies as Topic, Microscopy, Confocal},
	pages = {52--56},
}

@article{koehler_vivo_2006,
	title = {In vivo assessment of human skin aging by multiphoton laser scanning tomography},
	volume = {31},
	issn = {0146-9592},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/16969409},
	abstract = {Changes of dermal collagen and elastin content are characteristic for skin aging as well as for pathological skin conditions. To evaluate these changes, we used in vivo multiphoton laser tomography to measure two-photon excited autofluorescence (AF) and second harmonic generation (SHG). We tested 18 patients of all ages and calculated the SHG-to-AF aging index of dermis (SAAID). We observed a negative relationship between the SAAID and age, which was accelerated for the female (n=7) subgroup. The current findings are the first in vivo demonstration of this relationship, and they show that specific characteristics of aged skin such as the ratio of extracellular matrix components collagen and elastin can be evaluated by in vivo AF and SHG measurements using near-IR femtosecond laser pulses.},
	number = {19},
	urldate = {2011-11-04},
	journal = {Optics Letters},
	author = {Koehler, M. J. and König, K. and Elsner, P. and Bückle, R. and Kaatz, M.},
	year = {2006},
	keywords = {Humans, Image Interpretation, Computer-Assisted, Female, Microscopy, Fluorescence, Multiphoton, Adult, Aged, Aging, Male, Middle Aged, Aged, 80 and over, Dermoscopy, Microscopy, Confocal, Skin Physiological Phenomena, Tomography, Optical Coherence},
	pages = {2879--2881},
}

@article{piccolino_electronic_1979-1,
	title = {Electronic image analysis in retinal fluoroangiography. {With} 1 colour plate},
	volume = {179},
	issn = {0030-3755},
	abstract = {The authors describe an original method of fluororetinographic densitometry based on electronic image analysis. They suggest practical applications of this method and report morphologic and quantitative results of their preliminary study.},
	number = {3},
	journal = {Ophthalmologica. Journal international d'ophtalmologie. International journal of ophthalmology. Zeitschrift für Augenheilkunde},
	author = {Piccolino, F C and Zingirian, M and Parodi, G C},
	year = {1979},
	pmid = {95040},
	keywords = {Humans, Color, Fluorescein Angiography, Macula Lutea, Densitometry, Neovascularization, Pathologic, Retinal Detachment},
	pages = {142--147},
}

@article{koehler_intrinsic_2009,
	title = {Intrinsic, solar and sunbed-induced skin aging measured in vivo by multiphoton laser tomography and biophysical methods},
	volume = {15},
	issn = {1600-0846},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19624433},
	doi = {10.1111/j.1600-0846.2009.00372.x},
	abstract = {BACKGROUND

Skin aging is accelerated by extrinsic factors, particularly actinic damage. Over the last decades, both clinical and pathological differences between intrinsic and actinic aging have been characterized. In this work, we aimed at quantifying skin aging by non-invasive in vivo methods.


METHODS

Young healthy volunteers using indoor tanning facilities and aged people were compared with appropriate controls by measurements of skin elasticity with the Cutometer and the Reviscometer and by semi-quantitative evaluation of the dermal matrix composition by the multiphoton laser tomograph DermaInspect.


RESULTS

We found differences between the sun-protected volar forearm and the dorsal side as well as between young and old test persons with all three methods. No significant differences were found between the skin of indoor-tanned test persons and control. Also, gender had no influence on the severity of skin aging.


CONCLUSION

The most consistent results were obtained with the DermaInspect. The considerable inter-individual variation due to the cross-sectional design of the study may have disguised the factual skin damage caused by tanning beds.},
	number = {3},
	urldate = {2012-05-29},
	journal = {Skin research and technology: official journal of International Society for Bioengineering and the Skin (ISBS) [and] International Society for Digital Imaging of Skin (ISDIS) [and] International Society for Skin Imaging (ISSI)},
	author = {Koehler, Martin Johannes and Preller, Anja and Kindler, Nadja and Elsner, Peter and König, Karsten and Bückle, Rainer and Kaatz, Martin},
	month = aug,
	year = {2009},
	pmid = {19624433},
	keywords = {Humans, Female, skin, Microscopy, Fluorescence, Multiphoton, Adult, Aged, Male, Middle Aged, Dermoscopy, Lasers, Skin Aging, Radiation Dosage, Solar Energy, Sunbathing},
	pages = {357--363},
}

@article{walter_contribution_2002-1,
	title = {A {Contribution} of {Image} {Processing} to the {Diagnosis} of {Diabetic}                {Retinopathy} - {Detection} of {Exudates} in {Color} {Fundus} {Images}                of the {Human} {Retina}},
	volume = {21},
	url = {http://dblp.uni-trier.de/rec/bibtex/journals/tmi/WalterKME02},
	number = {10},
	urldate = {2012-10-12},
	journal = {IEEE Trans. Med. Imaging},
	author = {Walter, Thomas and Klein, Jean-Claude and Massin, Pascale and Erginay, Ali},
	year = {2002},
	pages = {1236--1243},
}

@inproceedings{walter_segmentation_2001,
	address = {London, UK, UK},
	series = {{ISMDA} '01},
	title = {Segmentation of {Color} {Fundus} {Images} of the {Human} {Retina}: {Detection} of the {Optic} {Disc} and the {Vascular} {Tree} {Using} {Morphological} {Techniques}},
	isbn = {3-540-42734-1},
	shorttitle = {Segmentation of {Color} {Fundus} {Images} of the {Human} {Retina}},
	url = {http://dl.acm.org/citation.cfm?id=646351.691036},
	abstract = {This paper presents new algorithms based on mathematical morphology for the detection of the optic disc and the vascular tree in noisy low contrast color fundus photographs. Both features - vessels and optic disc - deliver landmarks for image registration and are indispensable to the understanding of retinal fundus images. For the detection of the optic disc, we first find the position approximately. Then we find the exact contours by means of the watershed transformation. The algorithm for vessel detection consists in contrast enhancement, application of the morphological top-hat-transform and a post-filtering step in order to distinguish the vessels from other blood containing features.},
	urldate = {2012-10-12},
	booktitle = {Proceedings of the {Second} {International} {Symposium} on {Medical} {Data} {Analysis}},
	publisher = {Springer-Verlag},
	author = {Walter, Thomas and Klein, Jean-Claude},
	year = {2001},
	pages = {282--287},
}

@article{quellec_multiple-instance_2012,
	title = {A multiple-instance learning framework for diabetic retinopathy screening},
	volume = {16},
	issn = {1361-8423},
	doi = {10.1016/j.media.2012.06.003},
	abstract = {A novel multiple-instance learning framework, for automated image classification, is presented in this paper. Given reference images marked by clinicians as relevant or irrelevant, the image classifier is trained to detect patterns, of arbitrary size, that only appear in relevant images. After training, similar patterns are sought in new images in order to classify them as either relevant or irrelevant images. Therefore, no manual segmentations are required. As a consequence, large image datasets are available for training. The proposed framework was applied to diabetic retinopathy screening in 2-D retinal image datasets: Messidor (1200 images) and e-ophtha, a dataset of 25,702 examination records from the Ophdiat screening network (107,799 images). In this application, an image (or an examination record) is relevant if the patient should be referred to an ophthalmologist. Trained on one half of Messidor, the classifier achieved high performance on the other half of Messidor (A(z)=0.881) and on e-ophtha (A(z)=0.761). We observed, in a subset of 273 manually segmented images from e-ophtha, that all eight types of diabetic retinopathy lesions are detected.},
	number = {6},
	journal = {Medical image analysis},
	author = {Quellec, Gwénolé and Lamard, Mathieu and Abràmoff, Michael D and Decencière, Etienne and Lay, Bruno and Erginay, Ali and Cochener, Béatrice and Cazuguel, Guy},
	month = aug,
	year = {2012},
	pmid = {22850462},
	pages = {1228--1240},
}

@misc{noauthor_oasis_nodate,
	title = {{OASIS}},
	url = {http://www.abstractsonline.com/Plan/ViewAbstract.aspx?mID=2866&sKey=619919f9-4a75-49df-89bc-2c4b705eaf3f&cKey=4da8dd6c-43f3-4829-b974-a9e410145242&mKey=%7BF0FCE029-9BF8-4E7C-B48E-9FF7711D4A0E%7D},
	urldate = {2012-10-12},
	file = {OASIS:/home/edecenciere/Zotero/storage/WRAJ6H7Z/ViewAbstract.html:text/html},
}

@misc{noauthor_oasis_nodate-1,
	title = {{OASIS}},
	url = {http://www.abstractsonline.com/Plan/ViewAbstract.aspx?mID=2866&sKey=619919f9-4a75-49df-89bc-2c4b705eaf3f&cKey=4da8dd6c-43f3-4829-b974-a9e410145242&mKey=%7BF0FCE029-9BF8-4E7C-B48E-9FF7711D4A0E%7D},
	urldate = {2012-10-12},
	file = {OASIS:/home/edecenciere/Zotero/storage/W7M5BARG/ViewAbstract.html:text/html},
}

@article{akita_computer_1982,
	title = {A computer method of understanding ocular fundus images},
	volume = {15},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/003132038290022X},
	doi = {10.1016/0031-3203(82)90022-X},
	abstract = {We have studied some fundamental problems towards the understanding of color ocular fundus images which are used in the mass diagnosis of adult diseases such as hypertension and diabetes. These problems are: the extraction of blood vessels from the retinal background; the recognition of arteries and veins; the detection and analysis of peculiar regions such as hemorrhages, exudates, optic discs and arterio-venous crossings. We propose a computer method for each of these problems and show some experimental results.},
	number = {6},
	urldate = {2012-10-05},
	journal = {Pattern Recognition},
	author = {Akita, Koichiro and Kuga, Hideki},
	year = {1982},
	keywords = {Pattern recognition, Feature extraction, Chromatic analysis, Description of vessel networks, Hemorrhages, Ocular fundus images, Optic discs, Relaxation labeling},
	pages = {431--443},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/ZTNSCT9A/003132038290022X.html:text/html},
}

@inproceedings{lefevre_knowledge_2007,
	address = {Berlin, Heidelberg},
	series = {{CAIP}'07},
	title = {Knowledge from markers in watershed segmentation},
	isbn = {978-3-540-74271-5},
	url = {http://dl.acm.org/citation.cfm?id=1770904.1770984},
	abstract = {Due to its broad impact in many image analysis applications, the problem of image segmentation has been widely studied. However, there still does not exist any automatic segmentation procedure able to deal accurately with any kind of image. Thus semi-automatic segmentation methods may be seen as an appropriate alternative to solve the segmentation problem. Among these methods, the marker-based watershed has been successfully involved in various domains. In this algorithm, the user may locate the markers, which are used only as the initial starting positions of the regions to be segmented. We propose to base the segmentation process also on the contents of the markers through a supervised pixel classification, thus resulting in a knowledge-based watershed segmentation where the knowledge is built from the markers. Our contribution has been evaluated through some comparative tests with some state-of-the-art methods on the well-known Berkeley Segmentation Dataset.},
	urldate = {2012-10-01},
	booktitle = {Proceedings of the 12th international conference on {Computer} analysis of images and patterns},
	publisher = {Springer-Verlag},
	author = {Lefèvre, Sébastien},
	year = {2007},
	keywords = {colour segmentation, marker-based watershed, supervised classification},
	pages = {579--586},
}

@inproceedings{lefevre_knowledge_2007-1,
	address = {Berlin, Heidelberg},
	series = {{CAIP}'07},
	title = {Knowledge from markers in watershed segmentation},
	isbn = {978-3-540-74271-5},
	url = {http://dl.acm.org/citation.cfm?id=1770904.1770984},
	abstract = {Due to its broad impact in many image analysis applications, the problem of image segmentation has been widely studied. However, there still does not exist any automatic segmentation procedure able to deal accurately with any kind of image. Thus semi-automatic segmentation methods may be seen as an appropriate alternative to solve the segmentation problem. Among these methods, the marker-based watershed has been successfully involved in various domains. In this algorithm, the user may locate the markers, which are used only as the initial starting positions of the regions to be segmented. We propose to base the segmentation process also on the contents of the markers through a supervised pixel classification, thus resulting in a knowledge-based watershed segmentation where the knowledge is built from the markers. Our contribution has been evaluated through some comparative tests with some state-of-the-art methods on the well-known Berkeley Segmentation Dataset.},
	urldate = {2012-10-01},
	booktitle = {Proceedings of the 12th international conference on {Computer} analysis of images and patterns},
	publisher = {Springer-Verlag},
	author = {Lefèvre, Sébastien},
	year = {2007},
	keywords = {colour segmentation, marker-based watershed, supervised classification},
	pages = {579--586},
}

@inproceedings{baldeweck_vivo_2012,
	title = {In vivo multiphoton microscopy associated to {3D} image processing for human skin characterization},
	url = {http://adsabs.harvard.edu/abs/2012SPIE.8226E..54B},
	doi = {10.1117/12.907410},
	urldate = {2012-06-05},
	booktitle = {Proc. {SPIE} 8226},
	author = {Baldeweck, T. and Tancrede-Bohin, E. and Dokladal, P. and Koudoro, S. and Morard, V. and Meyer, F. and Decenciere, E. and Pena, A.-M.},
	year = {2012},
	file = {NASA ADS\: In vivo multiphoton microscopy associated to 3D image processing for human skin characterization:/home/edecenciere/Zotero/storage/4ZNIC8WU/2012SPIE.8226E..html:text/html},
}

@article{ait_el_madani_vivo_2012,
	title = {In vivo multiphoton imaging of human skin: assessment of topical corticosteroid-induced epidermis atrophy and depigmentation},
	volume = {17},
	issn = {10833668},
	shorttitle = {In vivo multiphoton imaging of human skin},
	url = {http://spie.org/x648.html?product_id=955064},
	doi = {10.1117/1.JBO.17.2.026009},
	number = {2},
	urldate = {2012-06-05},
	journal = {Journal of Biomedical Optics},
	author = {Ait El Madani, Hassan and Tancrede-Bohin, Emmanuelle and Bensussan, Armand and Colonna, Anne and Dupuy, Alain and Bagot, Martine and Pena, Ana-Maria},
	year = {2012},
	file = {In vivo multiphoton imaging of human skin\: assessment of topical corticosteroid-induced epidermis atrophy and depigmentation | Publications\: SPIE:/home/edecenciere/Zotero/storage/B7DVIFR9/x648.html:text/html},
}

@incollection{cox_appropriate_1999,
	title = {Appropriate image processing for confocal microscopy},
	volume = {2},
	booktitle = {Focus on multidimensional microscopy},
	publisher = {World Scientific},
	author = {Cox, Guy and Sheppard, Colin},
	year = {1999},
}

@incollection{grady_weights_2008,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Weights and {Topology}: {A} {Study} of the {Effects} of {Graph} {Construction} on {3D} {Image} {Segmentation}},
	volume = {5241},
	isbn = {978-3-540-85987-1},
	shorttitle = {Weights and {Topology}},
	url = {http://www.springerlink.com/content/n3l5364573601515/abstract/},
	abstract = {Graph-based algorithms have become increasingly popular for medical image segmentation. The fundamental process for each of these algorithms is to use the image content to generate a set of weights for the graph and then set conditions for an optimal partition of the graph with respect to these weights. To date, the heuristics used for generating the weighted graphs from image intensities have largely been ignored, while the primary focus of attention has been on the details of providing the partitioning conditions. In this paper we empirically study the effects of graph connectivity and weighting function on the quality of the segmentation results. To control for algorithm-specific effects, we employ both the Graph Cuts and Random Walker algorithms in our experiments.},
	urldate = {2012-07-06},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2008},
	publisher = {Springer Berlin / Heidelberg},
	author = {Grady, Leo and Jolly, Marie-Pierre},
	editor = {Metaxas, Dimitris and Axel, Leon and Fichtinger, Gabor and Székely, Gábor},
	year = {2008},
	keywords = {Computer Science},
	pages = {153--161},
	file = {SpringerLink Snapshot:/home/edecenciere/Zotero/storage/3PCVR3EA/abstract.html:text/html},
}

@inproceedings{metaxas_weights_2008,
	title = {Weights and {Topology}: {A} {Study} of the {Effects} of {Graph} {Construction} on {3D} {Image} {Segmentation}},
	volume = {5241},
	isbn = {978-3-540-85987-1 978-3-540-85988-8},
	shorttitle = {Weights and {Topology}},
	url = {http://dblp.uni-trier.de/rec/bibtex/conf/miccai/GradyJ08},
	urldate = {2011-10-28},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2008},
	publisher = {Springer},
	author = {Grady, Leo and Jolly, Marie-Pierre},
	editor = {Metaxas, Dimitris and Axel, Leon and Fichtinger, Gabor and Székely, Gábor},
	year = {2008},
	pages = {153--161},
}

@article{li_lazy_2004,
	title = {Lazy snapping},
	volume = {23},
	issn = {0730-0301},
	url = {http://doi.acm.org/10.1145/1015706.1015719},
	doi = {10.1145/1015706.1015719},
	abstract = {In this paper, we present Lazy Snapping, an interactive image cutout tool. Lazy Snapping separates coarse and fine scale processing, making object specification and detailed adjustment easy. Moreover, Lazy Snapping provides instant visual feedback, snapping the cutout contour to the true object boundary efficiently despite the presence of ambiguous or low contrast edges. Instant feedback is made possible by a novel image segmentation algorithm which combines graph cut with pre-computed over-segmentation. A set of intuitive user interface (UI) tools is designed and implemented to provide flexible control and editing for the users. Usability studies indicate that Lazy Snapping provides a better user experience and produces better segmentation results than the state-of-the-art interactive image cutout tool, Magnetic Lasso in Adobe Photoshop.},
	number = {3},
	urldate = {2012-06-05},
	journal = {ACM Trans. Graph.},
	author = {Li, Yin and Sun, Jian and Tang, Chi-Keung and Shum, Heung-Yeung},
	month = aug,
	year = {2004},
	keywords = {Graph cut, Image Cutout, Interactive Image Segmentation, User Interface},
	pages = {303--308},
}

@inproceedings{grady_weights_2008-1,
	address = {New York, USA},
	title = {Weights and {Topology}: {A} {Study} of the {Effects} of {Graph} {Construction} on {3D} {Image} {Segmentation}},
	volume = {1},
	booktitle = {Proc. of {MICCAI}},
	author = {Grady, L. and Jolly, M.-P.},
	year = {2008},
	pages = {153--161},
}

@article{stawiaski_region_2008,
	title = {Region merging via graph cuts},
	volume = {27},
	number = {1},
	journal = {Image Analysis and Stereology},
	author = {Stawiaski, J. and Decencière, E.},
	year = {2008},
	pages = {39--46},
}

@article{sugata_evaluation_2011,
	title = {Evaluation of photoaging in facial skin by multiphoton laser scanning microscopy.},
	volume = {17},
	doi = {10.1111/j.1600-0846.2010.00475.x},
	number = {1},
	journal = {Skin Research and Technology},
	author = {Sugata, K. and Avaro, O. and Sano, T. and Takema, Y.},
	year = {2011},
	pages = {1--3},
}

@article{koehler_keratinocyte_2011,
	title = {Keratinocyte morphology of human skin evaluated by in vivo multiphoton laser tomography},
	volume = {17},
	issn = {1600-0846},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1600-0846.2011.00522.x/abstract},
	doi = {10.1111/j.1600-0846.2011.00522.x},
	abstract = {Background:  Multiphoton tomography (MPT) is a novel non-invasive imaging method in dermatology allowing the depiction of the epidermis with sub-cellular resolution. Here, we present a descriptive characterization of unaffected human epidermis, morphometric data on human keratinocytes and some epidermal parameters in vivo and a morphological characterization of keratinocyte changes in actinic keratoses.},
	language = {en},
	number = {4},
	urldate = {2011-11-04},
	journal = {Skin Research and Technology},
	author = {Koehler, M. J. and Zimmermann, S. and Springer, S. and Elsner, P. and König, K. and Kaatz, M.},
	year = {2011},
	keywords = {skin, epidermis, actinic keratosis, keratinocyte, laser scanning microscopy, multiphoton tomography},
	pages = {479--486},
}

@phdthesis{stawiaski_mathematical_2008,
	title = {Mathematical morphology and graphs: application to interactive medical image segmentation},
	school = {Ecole des Mines de Paris, Paris},
	author = {Stawiaski, Jean},
	year = {2008},
}

@article{timar_interdigitation_2000,
	title = {Interdigitation index - a parameter for differentiating between young and older skin specimens},
	volume = {6},
	issn = {1600-0846},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/11428937},
	abstract = {BACKGROUND/AIMS: Quantitative morphometry developed rapidly during the last decade due to advances is computers and software. We wish to establish a simple baseline for the morphometric differences due to intrinsic ageing between young and old cohorts: the interdigitation index. It is an expression of the shape of the border between the epidermis and dermis. METHODS: We used volar forearm biopsies of women, since the volar forearm is usually not photodamaged. The biopsies were fixed in buffered formalin, embedded in paraffin and sectioned. Separate sections were stained by hematoxylin-eosin, by orcein and by dimethyl-methylene blue. We had seven female volunteers in each group; the young cohort had a mean age of 26.6 years, the older cohort 50.9 years. We chose a cohort that was just about postmenopausal, since in the future we wish to evaluate the effect of externally-applied agents on postmenopausal female skin and the earlier it is applied the better its chance of being effective. RESULTS: We found no difference between the young and older cohort with regard to epidermal thickness. We found a decrease of glycosaminoglycen (GAG) as measured by dimethyl-methylene blue staining. The results of the elastic staining by orcein, although in line with the reports in the literature, are not useful for evaluating the intrinsic ageing process, at least not by the simple percentage of area stained procedure. We introduced a new parameter: the interdigitation index. It is a simple measurement of the interdigitation in the epidermal-dermal junction, known to be diminished by age. This index was diminished by about 20\% between the young and older cohort. CONCLUSIONS: Quantitative morphometry using simple epidermal and dermal measurements on biopsies of the volar forearm of women is suitable for following intrinsic ageing of the skin and offers a simple objective method for following the ageing process of the skin.},
	number = {1},
	urldate = {2011-11-04},
	journal = {Skin Research and Technology},
	author = {Timár, F. and Soós, Gy and Szende, B. and Horváth, A.},
	year = {2000},
	pages = {17--20},
}

@article{dimitrow_sensitivity_2009,
	title = {Sensitivity and specificity of multiphoton laser tomography for in vivo and ex vivo diagnosis of malignant melanoma.},
	volume = {129},
	doi = {10.1038/jid.2008.439},
	number = {7},
	journal = {The Journal of investigative dermatology},
	author = {Dimitrow, Enrico and Ziemer, Mirjana and Koehler, Martin Johannes and Norgauer, Johannes and König, Karsten and Elsner, Peter and Kaatz, Martin},
	year = {2009},
	pages = {1752--8},
}

@inproceedings{freedman_energy_2005,
	title = {Energy minimization via graph cuts: settling what is possible},
	volume = {2},
	booktitle = {Conference on computer vision and pattern recognition ({CVPR})},
	author = {Freedman, D. and Drineas, P.},
	year = {2005},
	pages = {939--946},
}

@misc{noauthor_dblp_nodate,
	title = {{DBLP} {Record} 'conf/miccai/{GradyJ08}'},
	url = {http://dblp.uni-trier.de/rec/bibtex/conf/miccai/GradyJ08},
	urldate = {2011-10-28},
	file = {DBLP Record 'conf/miccai/GradyJ08':/home/edecenciere/Zotero/storage/VFSKE2MU/GradyJ08.html:text/html},
}

@inproceedings{veksler_superpixels_nodate,
	title = {Superpixels and {Supervoxels} in an {Energy} {Optimization} {Framework}},
	booktitle = {European {Conference} on {Computer} {Vision} ({ECCV})},
	author = {Veksler, O. and Boykov, Y. and Mehrani, P.},
}

@inproceedings{fulkerson_class_2009,
	title = {Class {Segmentation} and {Object} {Localization} with {Superpixel} {Neighborhoods}},
	booktitle = {Proceedings of the {International} conference on computer vision},
	author = {Fulkerson, Brian},
	year = {2009},
}

@misc{noauthor_brian_nodate,
	title = {Brian {Fulkerson}},
	url = {http://vision.ucla.edu/~brian/},
	urldate = {2011-06-07},
	file = {Brian Fulkerson:/home/edecenciere/Zotero/storage/U84USP78/~brian.html:text/html},
}

@misc{matheron_surpotentes_1982,
	title = {Surpotentes et sous-potentes},
	publisher = {Ecole des Mines de Paris},
	author = {Matheron, Georges},
	year = {1982},
}

@misc{matheron_surpotentes_1982-1,
	title = {Surpotentes et sous-potentes},
	publisher = {Ecole des Mines de Paris},
	author = {Matheron, Georges},
	year = {1982},
}

@misc{matheron_les_1982,
	title = {Les applications idempotentes},
	publisher = {Ecole des Mines de Paris},
	author = {Matheron, Georges},
	year = {1982},
}

@article{serra_overview_1992,
	title = {An overview of morphological filtering},
	volume = {11},
	issn = {0278-081X},
	url = {http://www.springerlink.com/content/x647881642722087/},
	doi = {10.1007/BF01189221},
	number = {1},
	urldate = {2011-05-09},
	journal = {Circuits Systems and Signal Processing},
	author = {Serra, Jean and Vincent, Luc},
	month = mar,
	year = {1992},
	pages = {47--108},
	file = {SpringerLink - Circuits, Systems, and Signal Processing, Volume 11, Number 1:/home/edecenciere/Zotero/storage/7I8CDGF6/x647881642722087.html:text/html},
}

@misc{maisonneuve_ordinaux_1982,
	title = {Ordinaux transfinis et sur (ou sous) potentes},
	author = {Maisonneuve, Francis},
	year = {1982},
	note = {Int. Rep. CGMM},
}

@misc{maisonneuve_sur_1982,
	title = {Sur le partage des eaux},
	author = {Maisonneuve, Francis},
	year = {1982},
	note = {Int. Rep CGMM},
}

@article{rudra_3d_2011,
	title = {{3D} {Graph} cut with new edge weights for cerebral white matter segmentation},
	volume = {32},
	issn = {0167-8655},
	url = {http://www.sciencedirect.com/science/article/B6V15-51T82MM-1/2/995b42a6916d1eec0af5dfd9f10e7f1c},
	doi = {10.1016/j.patrec.2010.12.013},
	abstract = {{\textless}p{\textgreater}{\textless}br/{\textgreater}Accurate and efficient automatic or semi-automatic brain image segmentation methods are of great interest to both scientific and clinical researchers of the human central neural system. Cerebral white matter segmentation in brain Magnetic Resonance Imaging (MRI) data becomes a challenging problem due to a combination of several factors like low contrast, presence of noise and imaging artifacts, partial volume effects, intrinsic tissue variation due to neurodevelopment and neuropathologies, and the highly convoluted geometry of the cortex. In this paper, we propose a new set of edge weights for the traditional graph cut algorithm (Boykov and Jolly, 2001) to correctly segment the cerebral white matter from T1-weighted MRI sequence. In this algorithm, the edge weights of Boykov and Jolly (2001) are modified by comparing the probabilities of an individual voxel and its neighboring voxels to belong to different segmentation classes. A shape prior in form of a series of ellipses is used next to model the contours of the human skull in various 2D slices in the sequence. This shape constraint is imposed to prune the original graph constructed from the input to form a subgraph consisting of voxels within the skull contours. Our graph cut algorithm with new set of edge weights is applied to the above subgraph, thereby increasing the segmentation accuracy as well as decreasing the computation time. Average segmentation errors for the proposed algorithm, the graph cut algorithm (Boykov and Jolly, 2001), and the Expectation Maximization Segmentation (EMS) algorithm Van Leemput et al., 2001 in terms of Dice coefficients are found to be (3.72 ± 1.12)\%, (14.88 ± 1.69)\%, and (11.95 ± 5.2)\%, respectively.{\textless}/p{\textgreater}},
	number = {7},
	urldate = {2011-04-28},
	journal = {Pattern Recognition Letters},
	author = {Rudra, Ashish K. and Sen, Mainak and Chowdhury, Ananda S. and Elnakib, Ahmed and El-Baz, Ayman},
	month = may,
	year = {2011},
	keywords = {Graph cut, Cerebral white matter segmentation, Edge weights, Shape prior, Subgraph},
	pages = {941--947},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/28Z47MM3/Rudra et al. - 2011 - 3D Graph cut with new edge weights for cerebral wh:},
}

@article{el-zehiry_combinatorial_2011,
	title = {Combinatorial {Optimization} of the piecewise constant {Mumford}-{Shah} functional with application to scalar/vector valued and volumetric image segmentation},
	volume = {29},
	issn = {0262-8856},
	url = {http://www.sciencedirect.com/science/article/B6V09-518TDNV-1/2/7be828b3899f403dfc838330cdbcb1f0},
	doi = {10.1016/j.imavis.2010.09.002},
	abstract = {{\textless}p{\textgreater}{\textless}br/{\textgreater}Front propagation models represent an important category of image segmentation techniques in the current literature. These models are normally formulated in a continuous level sets framework and optimized using gradient descent methods. Such formulations result in very slow algorithms that get easily stuck in local solutions and are highly sensitive to initialization.{\textless}br/{\textgreater}In this paper, we reformulate one of the most influential front propagation models, the Chan-Vese model, in the discrete domain. The graph representability and submodularity of the discrete energy function is established and then max-flow/min-cut approach is applied to perform the optimization of the discrete energy function. Our results show that this formulation is much more robust than the level sets formulation. Our approach is not sensitive to initialization and provides much faster solutions than level sets. The results also depict that our segmentation approach is robust to topology changes, noise and ill-defined edges, i.e., it preserves all the advantages associated with level sets methods.{\textless}/p{\textgreater}},
	number = {6},
	urldate = {2011-04-28},
	journal = {Image and Vision Computing},
	author = {El-Zehiry, Noha and Sahoo, Prasanna and Elmaghraby, Adel},
	month = may,
	year = {2011},
	keywords = {Image segmentation, Active contours, Graph cuts},
	pages = {365--381},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/3QGB22UP/El-Zehiry et al. - 2011 - Combinatorial Optimization of the piecewise consta:},
}

@incollection{mehnert_folding_2000,
	series = {Computational {Imaging} and {Vision}},
	title = {Folding {Induced} {Self}-{Dual} {Filters}},
	volume = {18},
	isbn = {978-0-306-47025-7},
	url = {http://dx.doi.org/10.1007/0-306-47025-X_12},
	abstract = {In this paper we present a method for constructing self-dual grey-scale image operators from arbitrary morphological operators defined on what we call fold-space. We call this class of self-dual operators folding induced self-dual filters (FISFs). We show examples of their application to noise filtering.},
	booktitle = {Mathematical {Morphology} and its {Applications} to {Image} and {Signal} {Processing}},
	publisher = {Springer US},
	author = {Mehnert, Andrew and Jackway, Paul},
	editor = {Goutsias, John and Vincent, Luc and Bloomberg, Dan S},
	year = {2000},
	note = {10.1007/0-306-47025-X\_12},
	pages = {99--108},
}

@article{rosenfeld_digital_1979,
	title = {Digital topology},
	volume = {86},
	journal = {Amer. Math. Monthly},
	author = {Rosenfeld, A.},
	year = {1979},
	pages = {621--630},
}

@phdthesis{monga_segmentation_1988,
	title = {Segmentation d'images par croissance hiérarchique de régions},
	school = {Université de Paris XI},
	author = {Monga, O.},
	year = {1988},
}

@book{soille_morphological_1999,
	title = {Morphological image analysis},
	publisher = {Springer-Verlag},
	author = {Soille, P.},
	year = {1999},
}

@phdthesis{faucon_segmentation_2007,
	title = {Segmentation morphologique et topologique de cubes sismiques},
	school = {Ecole des Mines de Paris, Paris},
	author = {Faucon, Timothée},
	year = {2007},
}

@article{lee_motion-compensated_1995,
	title = {Motion-compensated prediction using modal-based deformable block matching},
	volume = {6},
	number = {1},
	journal = {Journal of Visual Communication and Image Representation},
	author = {Lee, Ouseb and Wang, Tao},
	month = mar,
	year = {1995},
	pages = {26--34},
}

@book{matheron_krigeage_1969,
	title = {Le krigeage universel (cahiers du {CMM}, fascicule 1)},
	publisher = {Ecole des Mines, Paris},
	author = {Matheron, G.},
	year = {1969},
}

@phdthesis{friedlander_traitement_1989,
	title = {Le traitement morphologique d'images en cardiologie nucléaire},
	school = {Ecole des Mines de Paris, Paris},
	author = {Friedlander, F.},
	month = dec,
	year = {1989},
}

@inproceedings{richardson_restoration_1995,
	title = {Restoration of historic film for digital compression : {A} case study},
	volume = {2},
	booktitle = {Proceedings of {ICIP}-95},
	publisher = {IEEE Computer Society Press},
	author = {Richardson, P. and Suter, D.},
	month = may,
	year = {1995},
	pages = {49--52},
}

@article{khalimsky_computer_1990,
	title = {Computer graphics and connected topologies on finite ordered sets},
	volume = {36},
	journal = {Topology and its applications},
	author = {Khalimsky, D. and Kopperman, R. and Meyer, P. R},
	year = {1990},
	pages = {1--17},
}

@inproceedings{cichosz_segmentation_1997,
	title = {Segmentation morphologique multi-échelle en vue du codage},
	booktitle = {Coresa 97},
	author = {Cichosz, Jacek and Meyer, Fernand},
	year = {1997},
}

@inproceedings{stawiaski_interactive_2008,
	address = {New York, USA},
	title = {Interactive liver tumor segmentation using watershed and graph cuts},
	booktitle = {Segmentation in the clinic : {A} grand {Challenge} {II} ({MICCAI} 2008 workshop)},
	author = {Stawiaski, Jean and Decencière, Etienne},
	year = {2008},
}

@techreport{decenciere_completer_1998,
	title = {A {COMPLETER}},
	institution = {MOMUSYS},
	author = {Decencière, Etienne},
	month = nov,
	year = {1998},
}

@article{caciu_numerical_nodate,
	title = {Numerical analysis of the consequences of rugosity modifications in {3D} hydrodynamic contacts},
	journal = {STLE Tribology Transactions (accepted Feb. 2008)},
	author = {Caciu, Costin A and Decencière, Etienne and Jeulin, Dominique},
}

@article{caciu_parametric_nodate,
	title = {Parametric optimisation of periodic textured surfaces for friction reduction in combustion engines},
	journal = {STLE Tribology Transactions (accepted Feb. 2008)},
	author = {Caciu, Costin A and Decencière, Etienne and Jeulin, Dominique},
}

@article{caciu_numerical_2005,
	title = {Numerical analysis of a {3D} hydrodynamic contact},
	volume = {51},
	number = {12},
	journal = {International Journal for numerical methods in fluids},
	author = {Caciu, Costin A and Decencière, Etienne},
	year = {2005},
	pages = {1355--1377},
}

@phdthesis{lerallut_modelisation_2006,
	title = {Modélisation et {Interprétation} d'{Images} à l'{Aide} de {Graphes}},
	school = {Ecole des Mines de Paris, Paris},
	author = {Lerallut, Romain},
	year = {2006},
}

@techreport{decenciere_topological_2004,
	type = {Rapport {Pocket} {Multimedia}},
	title = {Topological sampling of binary images},
	number = {N 01/05/MM},
	institution = {Ecole des Mines de Paris, Centre de Morphologie Mathématique},
	author = {Decencière, Etienne and Bilodeau, Michel},
	month = dec,
	year = {2004},
}

@article{levoy_efficient_1990,
	title = {Efficient {Ray} {Tracing} of {Volume} {Data}},
	volume = {9},
	number = {3},
	journal = {ACM Transactions on Graphics},
	author = {Levoy, Marc},
	month = jul,
	year = {1990},
	pages = {245--261},
}

@inproceedings{kunt_second-generation_1985,
	title = {Second-generation image coding techniques},
	volume = {73},
	booktitle = {Proceedings of the {IEEE}},
	author = {Kunt, M. and Ikonomopoulos, A. and Kocher, M.},
	year = {1985},
	pages = {549--574},
}

@article{sacerdotti_mathematical_2000,
	title = {Mathematical {Modelling} of three-dimensional surface topography in autobody manufacture - {The} {State} of the {Art}},
	volume = {214},
	journal = {Proceedings of the Institution of Mechanical Engineers, PartB},
	author = {Sacerdotti, F. and Griffiths, B. J and Benati, F. and Butler, C.},
	year = {2000},
	pages = {811--819},
}

@techreport{muralikrishnan_valley_2000,
	type = {Status report},
	title = {Valley suppression algorithms},
	url = {http://www.coe.uncc.edu/ bmuralik/academic/docs/valley-dec-2000.pdf},
	number = {N-05/95/MM},
	institution = {Center for Precision Metrology, UNC Charlote},
	author = {Muralikrishnan, B. and Raja, J.},
	year = {2000},
}

@article{mainsah_effects_1994,
	title = {The effects of quantization on {3D} topography characterization},
	number = {5},
	journal = {Meas. Sci. Technol.},
	author = {Mainsah, E. and Stout, K. J and Sullivan, P. J},
	year = {1994},
	pages = {172--181},
}

@article{dong_reference_1995,
	title = {Reference planes for the assessment of surface roughness in three dimensions},
	volume = {35},
	number = {2},
	journal = {International Journal of Machine Tools and Manufacture},
	author = {Dong, W. P and Mainsah, E. and Stout, K. J},
	year = {1995},
	pages = {263--271},
}

@article{stout_surface_1984,
	title = {Surface topography of cylinder bores - the relationship between manufacture, characterization and function},
	volume = {95},
	journal = {Wear},
	author = {Stout, K. J},
	year = {1984},
	pages = {111--125},
}

@article{stout_characterization_1982,
	title = {The characterization of internal combustion engine bores},
	volume = {83},
	journal = {Wear},
	author = {Stout, K. J},
	year = {1982},
	pages = {311--326},
}

@book{bowden_friction_1950,
	title = {The friction and lubrication of solids, part {I}},
	publisher = {Clarendon, Oxford},
	author = {Bowden, F. P and Tabor, D.},
	year = {1950},
}

@article{belongie_shape_2002,
	title = {Shape matching and object recognition using shape contexts},
	volume = {24},
	number = {24},
	journal = {i3epami},
	author = {Belongie, Serge and Malik, Jitendra and Puzicha, Jan},
	month = apr,
	year = {2002},
	pages = {509--522},
}

@book{matheron_random_1975,
	title = {Random sets and integral geometry},
	publisher = {Wiley, New York},
	author = {Matheron, G.},
	year = {1975},
}

@article{yokoi_topological_1973,
	title = {Topological properties in digital binary pictures},
	volume = {4},
	journal = {Systems Comput. Controls},
	author = {Yokoi, S. and Toriwaki, J. and Fukumura, T.},
	year = {1973},
	pages = {32--40},
}

@article{lantuejoul_geodesic_1984,
	title = {Geodesic methods in quantitative image analysis},
	volume = {17},
	number = {2},
	journal = {Pattern Recognition},
	author = {Lantuéjoul, Christian and Maisonneuve, F.},
	year = {1984},
	pages = {177--187},
}

@inproceedings{stawiaski_region_2007,
	address = {Saint Etienne, France},
	title = {Region merging via graph-cuts},
	booktitle = {The 12th {International} {Congress} for {Stereology} ({ICS} {XII})},
	author = {Stawiaski, Jean and Decencière, Etienne},
	year = {2007},
}

@article{edmonds_theoretical_1972,
	title = {Theoretical improvements in algorithmic efficiency for network flow problems},
	volume = {19},
	number = {2},
	journal = {J. ACM},
	author = {Edmonds, J. and Karp, R. M},
	year = {1972},
	pages = {248--264},
}

@book{henry_sismique_1997,
	title = {Sismique réflexion : principes et développements},
	publisher = {Technip},
	author = {Henry, G.},
	year = {1997},
}

@article{tholath_three-dimensional_1999,
	title = {Three-dimensional filtering of engineering surfaces using envelope system},
	volume = {23},
	journal = {Precision engineering},
	author = {Tholath, J. and Radhakrishnan, V.},
	year = {1999},
	pages = {221--228},
}

@article{von_weingraber_suitability_1957,
	title = {Suitability of the envelope line as a reference standard for measuring roughness},
	volume = {11},
	journal = {Microtecnic},
	author = {von Weingraber, H.},
	year = {1957},
	pages = {6--17},
}

@article{boulanger_motifs_1992,
	title = {The motifs method: an interesting complement to {ISO} parameters for some functional problems},
	volume = {32},
	number = {1/2},
	journal = {International Journal of Machine Tools and Manufacture},
	author = {Boulanger, J.},
	year = {1992},
	pages = {203--209},
}

@book{bowden_friction_1964,
	title = {The friction and lubrication of solids, part {II}},
	publisher = {Clarendon, Oxford},
	author = {Bowden, F. P and Tabor, D.},
	year = {1964},
}

@book{bartlett_face_2001,
	title = {Face image analysis by unsupervised learning},
	publisher = {Kluwer academic publishers},
	author = {Bartlett, Marian Stewart},
	year = {2001},
}

@article{setos_fox_1996,
	title = {The {Fox} {Movietone} news preservation project: an introduction},
	volume = {105},
	number = {9},
	journal = {SMPTE Journal},
	author = {Setos, A. G},
	year = {1996},
	pages = {532--536},
}

@article{sikora_low_1995,
	title = {Low complexity shape-adaptive {DCT} for coding of arbitrarily shaped image segments},
	volume = {7},
	journal = {Signal Processing : Image Communication},
	author = {Sikora, T.},
	year = {1995},
	pages = {381--395},
}

@article{schunck_image_1986,
	title = {The image flow constraint equation},
	volume = {35},
	number = {1},
	journal = {Computer Vision, Graphics, and Image Processing},
	author = {Schunck, B. G},
	year = {1986},
	pages = {20--46},
}

@techreport{matheron_schema_1968,
	title = {Schéma booléen séquentiel de partition aléatoire},
	number = {N-83},
	institution = {Centre de Morphologie Mathématique, Ecole des Mines de Paris},
	author = {Matheron, G.},
	year = {1968},
}

@incollection{matheron_splines_1981,
	title = {Splines and kriging : their formal equivalence},
	booktitle = {Down-to-earht statistics : solutions looking for geological problems},
	publisher = {Syracuse university. Geology contributions},
	author = {Matheron, G.},
	editor = {Merrian, D. F},
	year = {1981},
	pages = {77--95},
}

@phdthesis{pardas_segmentacion_1994,
	title = {Segmentación morfológica de secuencias de imágenes: aplicación a la codificación},
	school = {Universitat Politècnica de Catalunya},
	author = {Pardàs, M.},
	month = dec,
	year = {1994},
}

@phdthesis{aubert_proprietes_1999,
	title = {Propriétés optiques des surfaces rugueuses aléatoires},
	school = {Ecole Nationale Supérieure des Mines de Paris},
	author = {Aubert, A.},
	year = {1999},
}

@phdthesis{casas_pla_image_1996,
	title = {Image compression based on perceptual coding techniques},
	school = {Universitat Politècnica de Catalunya},
	author = {Casas Pla, J. R},
	month = mar,
	year = {1996},
}

@misc{center_for_history_and_new_media_guide_nodate,
	title = {Guide rapide pour débuter},
	url = {http://zotero.org/support/quick_start_guide},
	author = {{Center for History and New Media}},
}

@inproceedings{beucher_watershed_1994,
	address = {Fontainebleau, France},
	title = {Watershed, hierarchical segmentation and waterfall algorithm},
	booktitle = {Mathematical {Morphology} and its applications to signal processing ({Proceedings} {ISMM}'94)},
	publisher = {Kluwer Academic Publishers},
	author = {Beucher, Serge},
	editor = {Serra, Jean and Soille, Pierre},
	month = sep,
	year = {1994},
	pages = {69--76},
}

@article{geman_non_1992,
	title = {A non linear filter for film restoration and other problems in image processing},
	volume = {54},
	issn = {1049-9652},
	number = {4},
	journal = {Computer Vision, Graphics, and Image Processing: Graphical Models and Image Processing},
	author = {Geman, S. and McClure, D. E and Geman, D.},
	month = jul,
	year = {1992},
	pages = {281--289},
}

@phdthesis{van_roosmalen_restoration_1999,
	title = {Restoration of archived film and video},
	school = {Delft University of Technology},
	author = {van Roosmalen, P. M.B},
	month = oct,
	year = {1999},
}

@article{conan_geostatistical_1992,
	title = {Geostatistical and morphological methods applied to three-dimensional microscopy},
	volume = {166},
	number = {2},
	journal = {Journal of Microscopy},
	author = {Conan, V. and Gesbert, S. and Howard, V. and Jeulin, Dominique and Meyer, Fernand},
	month = may,
	year = {1992},
	pages = {169--184},
}

@book{birkhoff_lattice_1940,
	title = {Lattice theory},
	publisher = {American Mathematical Society},
	author = {Birkhoff, Garrett},
	year = {1940},
}

@article{decenciere_restoration_1996,
	title = {Restoration of old motion pictures},
	volume = {7},
	issn = {1154–2799},
	number = {5/6},
	journal = {Microscopy, Microanalysis, Microstructures},
	author = {Decencière, Etienne},
	month = dec,
	year = {1996},
	pages = {311--316},
}

@inproceedings{morris_replacement_1994,
	address = {Adelaide, Australia},
	title = {Replacement noise in image sequences - detection and interpolation by motion field segmentation},
	booktitle = {Proceedings of {ICASSP}'94},
	author = {Morris, R. D and Fitzgerald, W. J},
	month = apr,
	year = {1994},
}

@article{cafforio_methods_1976,
	title = {Methods for measuring small displacements of television images},
	volume = {22},
	number = {5},
	journal = {IEEE Trans. Inform. Theory},
	author = {Cafforio, C. and Rocca, F.},
	year = {1976},
	pages = {573--579},
}

@article{rutovitz_pattern_1966,
	title = {Pattern recognition},
	volume = {129},
	journal = {J. Royal Statist. Soc.},
	author = {Rutovitz, D.},
	year = {1966},
	pages = {504--530},
}

@article{zhu_region_1996,
	title = {Region competition: unifying snakes, region growing, and {Bayes}/{MDL} for multiband image segmentation},
	volume = {18},
	number = {9},
	journal = {i3epami},
	author = {Zhu, Song Chun and Yuille, Alan},
	year = {1996},
	pages = {884--900},
}

@article{kolmogorov_what_2004,
	title = {What {Energy} {Functions} {Can} {Be} {Minimized} via {Graph} {Cuts} ?},
	volume = {26},
	number = {2},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Kolmogorov, V. and Zabih, R.},
	year = {2004},
	pages = {147--159},
}

@article{storey_electronic_1985,
	title = {Electronic detection and concealment of film dirt},
	journal = {SMPTE Journal},
	author = {Storey, R.},
	month = jun,
	year = {1985},
	pages = {642--647},
}

@book{matheron_theorie_1970,
	title = {La théorie des variables régionalisées et ses applications},
	publisher = {Ecole des Mines, Paris},
	author = {Matheron, G.},
	year = {1970},
}

@inproceedings{florencio_critical_1994,
	title = {Critical morphological sampling and its applications to image coding},
	booktitle = {Mathematical {Morphology} and its {Applications} to {Image} {Processing} ({Proceedings} {ISMM}'94)},
	author = {Florêncio, D.A.F. and Schafer, R.W.},
	month = sep,
	year = {1994},
	pages = {109--116},
}

@article{besserer_detection_2008,
	title = {Detection and correction of under/overexposed optical soundtracks by coupling image and audio signal processing},
	volume = {2008},
	journal = {EURASIP Journal on Advances in Signal Processing},
	author = {Besserer, Bernard and Taquet, Jonathan and Hassa{\textbackslash}},
	year = {2008},
}

@article{dong_determination_1996,
	title = {Determination of appropriate sampling conditions for three-dimensional microtopography measurement},
	volume = {36},
	number = {12},
	journal = {International Journal of Machine Tools and Manufacture},
	author = {Dong, W. P and Mainsah, E. and Stout, K. J},
	year = {1996},
	pages = {1347--1362},
}

@article{sadjadi_perspective_1990,
	title = {Perspective on techniques for enhancing speckled imagery},
	volume = {29},
	number = {1},
	journal = {Optical Engineering},
	author = {Sadjadi, F. A},
	year = {1990},
	pages = {25--30},
}

@article{vincent_watersheds_1991,
	title = {Watersheds in digital spaces: {An} efficient algorithm based on immersion simulations},
	volume = {13},
	number = {6},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Vincent, Luc and Soille, Pierre},
	year = {1991},
	pages = {583--598},
}

@phdthesis{laveau_mouvement_2005,
	title = {Mouvement et vidéo : estimation, compression, et filtrage morphologique},
	school = {Ecole des Mines de Paris, Paris},
	author = {Laveau, Nicolas},
	year = {2005},
}

@article{ocallaghan_combined_2005,
	title = {Combined {Morphological}-{Spectral} {Unsupervised} {Image} {Segmentation}},
	volume = {14},
	journal = {IEEE Transactions on Image Processing},
	author = {O'Callaghan, Robert J and Bull, David R},
	year = {2005},
	pages = {49--62},
}

@inproceedings{tom_iterative_1996,
	title = {An iterative algorithm for improving the resolution of video sequences},
	volume = {2727},
	booktitle = {Proc. {SPIE}: {Visual} communications and image processing},
	author = {Tom, B. C and Katsaggelos, A. K},
	month = mar,
	year = {1996},
	pages = {1430--1438},
}

@phdthesis{marcotegui_segmentation_1996,
	title = {Segmentation de séquences d'images en vue du codage},
	school = {Ecole Nationale Supérieure des Mines de Paris},
	author = {Marcotegui, Beatriz},
	year = {1996},
}

@article{serra_connectivity_1998,
	title = {Connectivity on complete lattices},
	volume = {9},
	number = {3},
	journal = {Journal of Mathematical Imaging and Vision},
	author = {Serra, Jean},
	month = nov,
	year = {1998},
	pages = {231­--251},
}

@inproceedings{faucon_application_2006,
	address = {Szeged, Hungary},
	title = {Application of surface topological segmentation to seismic imaging},
	booktitle = {Discrete {Geometry} for {Computer} {Imagery} ({DGCI} 2006)},
	author = {Faucon, T. and Decencière, Etienne and Magneron, C.},
	month = oct,
	year = {2006},
	pages = {506--517},
}

@article{perona_scale_1990,
	title = {Scale space and edge detection using anisotropic diffusion},
	volume = {12},
	number = {7},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Perona, P. and Malik, J.},
	year = {1990},
	pages = {629--639},
}

@inproceedings{abreu_simple_1996,
	address = {Atlanta (GA), USA},
	title = {A simple algorithm for restoration of images corrupted by streaks},
	volume = {2},
	booktitle = {1996 {IEEE} {International} {Symposium} on {Circuits} and {Systems} ({ISCAS}-96)},
	publisher = {IEEE Computer Society Press},
	author = {Abreu, E. and Mitra, S. K},
	year = {1996},
	pages = {730--733},
}

@inproceedings{zanoguera_segmentation_2000,
	address = {Palo Alto, California},
	title = {A segmentation pyramid for the interactive segmentation of 3-{D} images and video sequences},
	booktitle = {Mathematical {Morphology} and its {Applications} to {Image} {Processing}, {Proc}. {ISMM}'00},
	publisher = {Kluwer Ac. Publ., Nld},
	author = {Zanoguera, Francisca and Marcotegui, Beatriz and Meyer, Fernand},
	month = jun,
	year = {2000},
	pages = {263--272},
}

@phdthesis{lantuejoul_squelettisation_1978,
	title = {La squelettisation et son application aux mesures topologiques de mosaïques polycristallines},
	school = {Ecole des Mines de Paris, Paris},
	author = {Lantuéjoul, Christian},
	year = {1978},
}

@inproceedings{tylsky_fdg_2006,
	address = {San Diego (CA), USA},
	title = {{FDG} {PET} images segmentation using morphological watershed: a phantom study},
	booktitle = {{IEEE} {Nuclear} {Science} {Symposium} and {Medical} {Imaging} {Conference}},
	author = {Tylsky, P. and Bonniaud, G. and Decencière, Etienne and Stawiaski, J. and Lefkopoulos, D. and Ricard, M.},
	month = oct,
	year = {2006},
}

@article{boykov_graph_2006,
	title = {Graph cuts and efficient {N}-{D} segmentation},
	volume = {70},
	number = {2},
	journal = {International Journal of Computer Vision},
	author = {Boykov, Y. and Funka-Lea, G.},
	year = {2006},
	pages = {109--131},
}

@article{thomas_trends_1998,
	title = {Trends is surface roughness},
	volume = {38},
	number = {5-6},
	journal = {International Journal of Machine Tools and Manufacture},
	author = {Thomas, T. R},
	year = {1998},
	pages = {405--411},
}

@inproceedings{van_roosmalen_noise_1996,
	address = {Lausanne, Switzerland},
	title = {Noise reduction for image sequences using an oriented pyramid thresholding technique},
	volume = {1},
	booktitle = {Proceedings of {ICIP}-96},
	publisher = {IEEE Computer Society Press},
	author = {van Roosmalen, P. and Westen, S. J.P and Lagendijk, R. L and Biemond, J.},
	month = sep,
	year = {1996},
	pages = {375--378},
}

@article{joyeux_reconstruction_2001,
	title = {Reconstruction of degraded image sequences. {Application} to film restoration},
	volume = {19},
	journal = {Image and Vision Computing},
	author = {Joyeux, L. and Boukir, S. and Besserer, B. and Buisson, O.},
	year = {2001},
	pages = {503--516},
}

@inproceedings{tuzikov_extraction_1992,
	address = {The Hague},
	title = {Extraction of grid lines on stamped metal pieces using mathematical morphology},
	volume = {1},
	booktitle = {Proc. 11th {IAPR} {International} {Conference} on {Pattern} {Recognition}, {Conference} {A}: {Computer} {Vision} and {Applications}},
	author = {Tuzikov, A. and Soille, Pierre and Jeulin, Dominique and Bruneel, H. and Vermeulen, M.},
	month = sep,
	year = {1992},
	pages = {425--428},
}

@article{borgefors_shape_2001,
	title = {Shape and topology preserving multi-valued image pyramids for multi-resolution skeletonization},
	volume = {22},
	journal = {Pattern Recognition Letters},
	author = {Borgefors, G. and Ramella, G. and Sanniti di Baja, G.},
	year = {2001},
	pages = {741--751},
}

@inproceedings{salembier_practical_1996,
	address = {Atlanta (GA), USA},
	title = {Practical extensions of connected operators},
	booktitle = {Mathematical {Morphology} and its applications to signal processing ({Proceedings} {ISMM}'96)},
	publisher = {Kluwer Academic Publishers},
	author = {Salembier, Philippe},
	editor = {Maragos, P. and Schafer, R. W and Butt, M. A},
	month = may,
	year = {1996},
	pages = {97--110},
}

@article{salembier_antiextensive_1998,
	title = {Antiextensive connected operators for image and sequence processing},
	volume = {7},
	number = {4},
	journal = {IEEE Transactions on Image Processing},
	author = {Salembier, Philippe and Oliveras, A. and Garrido, Luis},
	month = apr,
	year = {1998},
	pages = {555--570},
}

@book{serra_image_1988,
	title = {Image {Analysis} and {Mathematical} {Morphology} - {Volume} {II} : {Theoretical} {Advances}},
	publisher = {Academic Press, London},
	editor = {Serra, Jean},
	year = {1988},
}

@article{dinic_algorithm_1970,
	title = {Algorithm for solution of a problem of maximum flow in networks with power estimation},
	volume = {11},
	journal = {Sov. MathK Dokl},
	author = {Dinic, E. A},
	year = {1970},
	pages = {1277--1280},
}

@techreport{piquee_application_1985,
	type = {Rapport de stage d'option de troisieme année},
	title = {Application de la morphologie mathématique à l'amélioration des alignements dans les images sismiques},
	number = {S-181},
	institution = {Ecole des Mines de Paris, Centre de Morphologie Mathématique},
	author = {Piquée, Vincent},
	year = {1985},
}

@inproceedings{kokaram_line_1997,
	address = {Munich, Germany},
	title = {Line registration of jittered video},
	booktitle = {Proceedings of {ICASSP}'97},
	author = {Kokaram, A. C and Rayner, P. and van Roosmalen, P. and Biemond, J.},
	month = apr,
	year = {1997},
}

@inproceedings{li_lazy_2004-1,
	title = {Lazy snapping},
	volume = {23},
	booktitle = {{SIGGRAPH} 2004 {Proceedings}},
	author = {Li, Y. and Sun, J. and Tang, C. and Shum, H.},
	year = {2004},
	pages = {303--308},
}

@article{van_vliet_non_1989,
	title = {A non linear {Laplace} operator as edge detector in noisy images},
	volume = {45},
	number = {2},
	journal = {Computer Vision, Graphics, and Image Processing},
	author = {van Vliet, L. J and Young, I. T and Beckers, G. L},
	month = feb,
	year = {1989},
	pages = {167--195},
}

@phdthesis{meyer_cytologie_1979,
	title = {Cytologie quantitative et morphologie mathématique},
	school = {Ecole des Mines de Paris, Paris},
	author = {Meyer, Fernand},
	year = {1979},
}

@article{boykov_fast_2001,
	title = {Fast {Approximate} {Energy} {Minimization} via {Graph} {Cuts}},
	volume = {23},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Boykov, Y. and Veksler, O. and Zabih, R.},
	year = {2001},
	pages = {1222--1239},
}

@article{hunt_prospects_1994,
	title = {Prospects for image restoration},
	volume = {5},
	number = {1},
	journal = {International Journal of Modern Physics},
	author = {Hunt, B. R},
	year = {1994},
	pages = {151--178},
}

@phdthesis{joyeux_reconstruction_2000,
	title = {Reconstruction de séquences d'images haute résolution. {Application} à la restauration de films cinématographiques},
	school = {Université de la Rochelle},
	author = {Joyeux, L.},
	month = jan,
	year = {2000},
}

@inproceedings{faucon_morphological_2005,
	address = {Paris, France},
	title = {Morphological segmentation applied to {3D} seismic data},
	booktitle = {Mathematical morphology: 40 years on ({Proceedings} of {ISMM}'2005)},
	author = {Faucon, T. and Decencière, Etienne and Magneron, C.},
	editor = {Ronse, C. and Najman, L. and Decencière, Etienne},
	month = apr,
	year = {2005},
	pages = {475--484},
}

@book{despas_guide_1995,
	title = {Guide de la conservation des films},
	publisher = {Commission Supérieure Technique de l'Image et du Son (CST), Paris},
	author = {Despas, B. and Fournier, J. L},
	year = {1995},
}

@article{jeulin_morphological_1989,
	title = {Morphological modelling of images by sequential random functions},
	volume = {16},
	journal = {Signal Processing},
	author = {Jeulin, Dominique},
	year = {1989},
	pages = {403--431},
}

@article{malandain_topological_1993,
	title = {Topological segmentation of discrete surfaces},
	volume = {10},
	number = {2},
	journal = {International Journal of Computer Vision},
	author = {Malandain, G. and Bertrand, G. and Ayache, N.},
	year = {1993},
	pages = {183--197},
}

@inproceedings{serra_sampling_1994,
	title = {A sampling approach based on equicontinuity},
	booktitle = {Mathematical {Morphology} and its {Applications} to {Image} {Processing} ({Proceedings} {ISMM}'94)},
	author = {Serra, Jean},
	editor = {Serra, Jean and Soille, Pierre},
	month = sep,
	year = {1994},
	pages = {117--124},
}

@inproceedings{decenciere_detection_1997,
	address = {Barcelona, Spain},
	title = {Detection of local defects in old motion pictures},
	booktitle = {{VII} {National} {Symposium} on {Pattern} {Recognition} and {Image} {Analysis}},
	author = {Decencière, Etienne and Serra, Jean},
	month = apr,
	year = {1997},
	pages = {145--150},
}

@inproceedings{witkin_scale-space_1983,
	title = {Scale-space filtering},
	booktitle = {Proceedings of the 7th {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	author = {Witkin, A. P},
	year = {1983},
	pages = {1019--1022},
}

@inproceedings{roosmalen_noise_1998,
	address = {Island of Rhodes, Greece},
	title = {Noise reduction of image sequences as preprocessing for mpeg2 encoding},
	booktitle = {European {Conference} on {Signal} {Processing} ({EUSIPCO} '98)},
	author = {Roosmalen, P. M.B and Kokaram, A. C and Biemond, J.},
	month = sep,
	year = {1998},
}

@inproceedings{zanoguera_tool-box_1999,
	address = {Kobe, Japan},
	title = {A tool-box for interactive image segmentation based on nested partions},
	booktitle = {{IEEE} {International} {Conference} on {Image} {Processing}},
	author = {Zanoguera, Francisca and Marcotegui, Beatriz and Meyer, Fernand},
	month = oct,
	year = {1999},
}

@article{falcao_image_2004,
	title = {The image foresting transform: theory, algorithm and applications},
	volume = {26},
	number = {1},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Falcao, A. X and Stolfi, J. and Lotufo, R. A},
	month = jan,
	year = {2004},
	pages = {19--29},
}

@inproceedings{marcotegui_morphological_1994,
	address = {Fontainebleau, France},
	title = {Morphological segmentation of image sequences},
	booktitle = {Mathematical {Morphology} and its applications to signal processing ({Proceedings} {ISMM}'94)},
	publisher = {Kluwer Academic Publishers},
	author = {Marcotegui, Beatriz and Meyer, Fernand},
	editor = {Serra, Jean and Soille, P.},
	month = sep,
	year = {1994},
	pages = {101--108},
}

@inproceedings{vincent_friction_2007,
	address = {Philadelphia, USA},
	title = {Friction analysis in laser surface textured lubricated contacts},
	booktitle = {{STLE} {Annual} {Meeting}},
	author = {Vincent, C. and Caciu, Costin A and Monteil, G. and Decencière, Etienne and Jeulin, Dominique},
	year = {2007},
}

@article{black_estimating_1996,
	title = {Estimating optical flow in segmented images using variable-order parametric models with local deformations},
	volume = {18},
	number = {10},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Black, M. J and Jepson, A. D},
	year = {1996},
	pages = {972--986},
}

@inproceedings{boykov_computing_2003,
	address = {Nice, France},
	title = {Computing {Geodesics} and {Minimal} {Surfaces} via {Graph} {Cuts}},
	volume = {1},
	booktitle = {International {Conference} on {Computer} {Vision}},
	author = {Boykov, Y. and Kolmogorov, V.},
	year = {2003},
	pages = {26--33},
}

@article{levoy_display_1988,
	title = {Display of surfaces from volume data},
	volume = {8},
	number = {5},
	journal = {IEEE Computer Graphics and Applications},
	author = {Levoy, Marc},
	month = may,
	year = {1988},
	pages = {29--37},
}

@article{migliotari_multistage_1995,
	title = {Multistage motion estimation for image interpolation},
	volume = {7},
	journal = {Signal Processing: Image Communication},
	author = {Migliotari, P. and Tubaro, S.},
	year = {1995},
	pages = {187--199},
}

@article{vincent_morphological_1993,
	title = {Morphological gray scale reconstruction in image analysis: {Applications} and efficient algorithms},
	volume = {2},
	number = {2},
	journal = {IEEE Transactions on Image Processing},
	author = {Vincent, Luc},
	month = apr,
	year = {1993},
	pages = {176--201},
}

@article{decenciere_content-dependent_2001,
	title = {Content-dependent image sampling using mathematical morphology: application to texture mapping},
	volume = {16},
	number = {6},
	journal = {Signal Processing: Image Communication},
	author = {Decencière, Etienne and Marcotegui, Beatriz and Meyer, Fernand},
	month = feb,
	year = {2001},
	pages = {567--584},
}

@article{komodakis_approximate_2007,
	title = {Approximate labelling via graph cuts based on linear programming},
	volume = {29},
	number = {8},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Komodakis, Nikos},
	month = aug,
	year = {2007},
	pages = {1436--1453},
}

@article{dudon_triangular_1997,
	title = {Triangular active mesh for motion estimation},
	volume = {10},
	number = {1-3},
	journal = {Signal Processing: Image Communication},
	author = {Dudon, M. and Avaro, O. and Roux, C.},
	month = jul,
	year = {1997},
	pages = {21--41},
}

@article{dong_comprehensive_1993,
	title = {Comprehensive study of parameters for characterizing three-dimensional surface topography. {II}: {Statistical} properties of parameter variation},
	volume = {167},
	journal = {Wear},
	author = {Dong, W. P and Sullivan, P. J and Stout, K. J},
	year = {1993},
	pages = {9--21},
}

@inproceedings{lyon_real-time_1998,
	address = {Montreux, Switzerland},
	title = {Real-time archive restoration},
	booktitle = {Proceedings of the {IAB} seminar on television archives preservation and creative use},
	author = {Lyon, D.},
	month = apr,
	year = {1998},
}

@book{kokaram_motion_1998,
	title = {Motion picture restoration},
	publisher = {Springer-Verlag},
	author = {Kokaram, A. C},
	year = {1998},
}

@inproceedings{bierling_displacement_1988,
	title = {Displacement estimation by hierarchical block matching},
	volume = {1001},
	booktitle = {Proc. {SPIE}: {Visual} communications and image processing},
	author = {Bierling, M.},
	year = {1988},
	pages = {942--951},
}

@article{lerallut_image_2007,
	title = {Image filtering using morphological amoebas},
	volume = {25},
	number = {4},
	journal = {Image and Vision Computing},
	author = {Lerallut, Romain and Decencière, Etienne and Meyer, Fernand},
	month = apr,
	year = {2007},
	pages = {395--404},
}

@article{miller_deformable_1996,
	title = {Deformable templates using large deformation kinematics},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Miller, M. I and Christense, G. E and Rabitt, R. D},
	year = {1996},
}

@article{gu_semiautomatic_1998,
	title = {Semiautomatic {Segmentation} and {Tracking} of {Semantic} {Video} {Objects}},
	volume = {8},
	number = {5},
	journal = {IEEE Trans. on Circuits and Systems for Video Technology},
	author = {Gu, C. and Lee, L. C},
	month = sep,
	year = {1998},
	pages = {572--584},
}

@article{boykov_experimental_2004,
	title = {An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision},
	volume = {26},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Boykov, Y. and Kolmogorov, V.},
	year = {2004},
	pages = {1124--1137},
}

@book{thomas_rough_1999,
	title = {Rough {Surfaces}, second edition},
	publisher = {Imperial College Press},
	author = {Thomas, T.R.},
	year = {1999},
}

@article{heijmans_morphological_1991,
	title = {Morphological sampling},
	volume = {54},
	journal = {Computer Vision, Graphics, and Image Processing: Image Understanding},
	author = {Heijmans, H.J.A.M. and Toet, A.},
	month = nov,
	year = {1991},
	pages = {384--400},
}

@inproceedings{naranjo_flicker_2000,
	title = {Flicker reduction in old films},
	booktitle = {Proc. of the 2000 {International} {Conference} on {Image} {Processing} ({ICIP}-2000)},
	author = {Naranjo, V. and Albiol, A.},
	month = sep,
	year = {2000},
}

@inproceedings{chong_new_1997,
	address = {Munich, Germany},
	title = {A new spatio-temporal {MRF} model for the detection of missing data in image sequences},
	booktitle = {Proceedings of {ICASSP}'97},
	author = {Chong, M. N and Liu, P. and Goh, W. B and Krishnan, D.},
	month = apr,
	year = {1997},
}

@article{jeulin_multivariate_1992,
	title = {Multivariate random image models},
	number = {11},
	journal = {Acta Stereologica},
	author = {Jeulin, Dominique},
	year = {1992},
	pages = {59--66},
}

@article{dong_comprehensive_1992,
	title = {Comprehensive study of parameters for characterizing three-dimensional surface topography. {I}: {Some} inherent properties of parameter variation},
	volume = {159},
	journal = {Wear},
	author = {Dong, W. P and Sullivan, P. J and Stout, K. J},
	year = {1992},
	pages = {161--171},
}

@inproceedings{kokaram_removal_1994,
	address = {Edinburgh, United Kingdom},
	title = {Removal of replacement noise in motion picture sequences using {3D} auto-regressive modelling},
	volume = {3},
	booktitle = {Signal {Processing} {VII}: {Theories} and {Application} (proceedings of {EUSIPCO}-94)},
	author = {Kokaram, A. C and Rayner, P.},
	month = sep,
	year = {1994},
}

@article{zhang_application_1995,
	title = {The application of mean field theory to image motion estimation},
	volume = {4},
	number = {1},
	journal = {IEEE Transactions on Image Processing},
	author = {Zhang, J. and Hanauer, G. G},
	month = jan,
	year = {1995},
	pages = {19--33},
}

@book{matheron_estimating_1989,
	title = {Estimating and choosing},
	publisher = {Springer Verlag, Berlin},
	author = {Matheron, G.},
	year = {1989},
}

@article{mortensen_interactive_1998,
	title = {Interactive {Segmentation} with {Intelligent} scissors},
	volume = {60},
	number = {5},
	journal = {Graphical Models and Image Processing},
	author = {Mortensen, E. N and Barrett, W. A},
	month = sep,
	year = {1998},
	pages = {349--384},
}

@inproceedings{lerallut_image_2005,
	address = {Paris, France},
	title = {Image filtering using morphological amoebas},
	booktitle = {Mathematical morphology: 40 years on ({Proceedings} of {ISMM}'2005)},
	author = {Lerallut, Romain and Decencière, Etienne and Meyer, Fernand},
	editor = {Ronse, C. and Najman, L. and Decencière, Etienne},
	month = apr,
	year = {2005},
	pages = {13--22},
}

@inproceedings{decenciere_topography_2002,
	address = {Sidney, Australia},
	title = {Topography characterization of engineering surfaces using mathematical morphology},
	booktitle = {Mathematical {Morphology} and its applications to signal processing ({Proceedings} {ISMM}'2002)},
	author = {Decencière, Etienne and Jeulin, Dominique},
	editor = {Talbot, H.},
	month = apr,
	year = {2002},
}

@incollection{kotropoulos_mathematical_2001,
	title = {Mathematical morphology and motion picture restoration},
	booktitle = {Nonlinear model-based image/video processing and analysis},
	publisher = {John Wiley and Sons},
	author = {Decencière, Etienne},
	editor = {Kotropoulos, C. and Pitas, I.},
	year = {2001},
}

@inproceedings{boykov_what_2005,
	address = {Beijing, China},
	title = {What {Metrics} {Can} {Be} {Approximated} by {Geo}-{Cuts}, or {Global} {Optimization} of {Length}/{Area} and {Flux}},
	volume = {1},
	booktitle = {Proceedings of the {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Boykov, Y. and Kolmogorov, V.},
	year = {2005},
	pages = {564--571},
}

@article{heitz_multimodal_1993,
	title = {Multimodal estimation of discontinuous optical flow using {Markov} random fields},
	volume = {15},
	number = {12},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Heitz, F. and Bouthemy, P.},
	year = {1993},
	pages = {1217--1232},
}

@phdthesis{morris_image_1994,
	title = {Image {Sequence} {Restoration} via {Gibbs} distributions},
	school = {Trinity College},
	author = {Morris, Robin D},
	year = {1994},
}

@incollection{beucher_morphological_1993,
	title = {The morphological approach to segmentation: the watershed transformation},
	booktitle = {Mathematical {Morphology} in {Image} {Processing}},
	author = {Beucher, Serge and Meyer, Fernand},
	editor = {Dougherty, E.R.},
	year = {1993},
	pages = {433--481},
}

@article{scott_foundations_1998,
	title = {Foundations of topological characterization of surface texture},
	volume = {38},
	number = {5-6},
	journal = {International Journal of Machine Tools and Manufacture},
	author = {Scott, P.},
	year = {1998},
	pages = {559--566},
}

@inproceedings{tenze_blotches_2000,
	title = {Blotches correction and contrast enhancement for old film pictures},
	booktitle = {Proc. of the 2000 {International} {Conference} on {Image} {Processing} ({ICIP}-2000)},
	author = {Tenze, L. and Ramponi, G. and Carrato, S.},
	month = sep,
	year = {2000},
}

@inproceedings{d_noise_1995,
	address = {Anaheim, CA},
	title = {Noise {Reduction} in {Image} {Sequences} with {Sparse} {Temporal} {Sampling}.},
	url = {ftp://ftp.elec.rma.ac.be/user/dirk/SIP95.ps.gz},
	booktitle = {{IASTED} {Int}. {Conf}. on {Signal} and {Image} {Processing}},
	publisher = {ACTA Press},
	author = {D, Acheroy M. Borghys},
	editor = {Namazi, N. M.},
	month = nov,
	year = {1995},
	keywords = {image sequence, motion compensation, noise reduction, restoration},
	pages = {452--455},
}

@inproceedings{kokaram_joint_1998,
	address = {San Diego, U.S.A},
	title = {Joint noise reduction, motion estimation, missing data reconstruction, and model parameter estimation for degraded motion pictures},
	booktitle = {{SPIE} {Conference} on {Bayesian} {Inference} for {Inverse} {Problems}},
	author = {Kokaram, A. C and Godsill, S.},
	month = jul,
	year = {1998},
}

@article{takahashi_restoration_1991,
	title = {Restoration of images with missing pixels},
	volume = {22},
	number = {2},
	journal = {Systems and Computers in Japan},
	author = {Takahashi, Kenichi and Ishii, Naohiro},
	year = {1991},
	pages = {34--41},
}

@inproceedings{allene_links_2007,
	address = {Rio de Janeiro, Brazil},
	title = {Some links between min-cuts, optimal spanning forests and watersheds},
	booktitle = {Mathematical {Morphology} and its {Applications} to {Signal} and {Image} {Processing} ({Proc}. {ISMM}'07)},
	author = {Allène, C. and Audibert, J. -Y and Couprie, M. and Cousty, J. and Keriven, R.},
	year = {2007},
	pages = {253--264},
}

@phdthesis{decenciere_restauration_1997,
	title = {Restauration automatique de films anciens},
	school = {Ecole Nationale Supérieure des Mines de Paris},
	author = {Decencière, Etienne},
	month = dec,
	year = {1997},
}

@article{karzanov_determining_1974,
	title = {Determining the maximal flow in a network by the method of preflows},
	volume = {15},
	journal = {Sov. Math. Dokl.},
	author = {Karzanov, A. V},
	year = {1974},
	pages = {434--437},
}

@article{jeulin_synthesis_1981,
	title = {Synthesis of rough surfaces by random morphological models},
	volume = {3},
	number = {1},
	journal = {Stereol. Iugosl. (Proc. 3rd european symposium of stereology)},
	author = {Jeulin, Dominique and Jeulin, P.},
	year = {1981},
	pages = {239--246},
}

@inproceedings{decenciere_downsampling_2005,
	address = {Paris, France},
	title = {Downsampling of binary images using adpative crossing numbers},
	booktitle = {Mathematical morphology: 40 years on ({Proceedings} {ISMM}'2005)},
	author = {Decencière, Etienne and Bilodeau, M.},
	editor = {Ronse, C. and Najman, L. and Decencière, Etienne},
	month = apr,
	year = {2005},
	pages = {279--288},
}

@article{kokaram_detection_1995,
	title = {Detection of missing data in image sequences},
	volume = {4},
	number = {11},
	journal = {IEEE Transactions on Image Processing},
	author = {Kokaram, A. C and Morris, R. D and Fitzgerald, W. J and Rayner, P. J.W},
	year = {1995},
	pages = {1496--1508},
}

@article{zhang_parameter_1997,
	title = {Parameter estimation techniques : a tutorial with application to conic fitting},
	volume = {15},
	number = {1},
	journal = {International Journal of Image and Vision Computing},
	author = {Zhang, Z.},
	month = jan,
	year = {1997},
	pages = {59--76},
}

@incollection{reed_image_2005,
	title = {Image sequence restoration : a wider perspective},
	booktitle = {Digital image sequence processing, compression, and analysis},
	publisher = {CRC Press},
	author = {Kokaram, Anil},
	editor = {Reed, Todd R},
	year = {2005},
	pages = {177--213},
}

@inproceedings{meyer_morphological_1999,
	address = {Antalya, Turkey},
	title = {Morphological multiscale and interactive segmentation},
	booktitle = {{IEEE}-{EURASIP} {Workshop} on {Nonlinear} {Signal} and {Image} {Processing}},
	author = {Meyer, Fernand},
	month = jun,
	year = {1999},
}

@article{falc_ao_user-steered_1998,
	title = {User-{Steered} {Image} {Segmentation} {Paradigms}: {Live} {Wire} and {Live} {Lane}},
	volume = {60},
	number = {4},
	journal = {Graphical Models and Image Processing},
	author = {Falc{\textbackslash} ao, A. X and Udupa, J. K and Samarasekera, S. and Sharma, S. and Hirsch, B. E and Lotufo, R. A},
	month = jul,
	year = {1998},
	pages = {233--260},
}

@inproceedings{beucher_road_1990,
	title = {Road segmentation by watershed algorithms},
	booktitle = {{PROMETHEUS} {Workshop}, {Sophia} {Antipolis}, {France}},
	author = {Beucher, Serge},
	month = apr,
	year = {1990},
}

@article{meyer_morphological_1990,
	title = {Morphological {Segmentation}},
	volume = {1},
	number = {1},
	journal = {Journal of Visual Communication and Image Representation},
	author = {Meyer, Fernand and Beucher, Serge},
	month = sep,
	year = {1990},
	pages = {21--46},
}

@inproceedings{decenciere_automatic_1998,
	address = {Glasgow, UK},
	title = {An automatic system for restoring image sequences},
	booktitle = {Noblesse workshop on non-linear model based image analysis},
	publisher = {Springer},
	author = {Decencière, Etienne},
	editor = {Marshall, Stephen and Harvey, N. and Shah, D.},
	month = jul,
	year = {1998},
	pages = {77--82},
}

@inproceedings{lombaert_multilevel_2005,
	title = {A {Multilevel} {Banded} {Graph} {Cuts} {Method} for {Fast} {Image} {Segmentation}},
	booktitle = {Proceedings of the {Tenth} {IEEE} {International} {Conference} on {Computer} {Vision}, {ICCV}},
	author = {Lombaert, H. and Sun, Y. and Grady, L. and Xu, C.},
	year = {2005},
}

@phdthesis{boehm_contribution_2004,
	title = {Contribution à l'amélioration du rendu volumique de données médicales {3D}},
	school = {Ecole des Mines de Paris, Paris},
	author = {Boehm, Mathilde},
	year = {2004},
}

@techreport{bergen_temporal_1996,
	type = {Race {R2053} {Deliverable}},
	title = {Temporal aspects in video compression},
	number = {R2053/UPC/GPS/DS/R/015/b1},
	institution = {Morpheco Consortium},
	author = {Bergen, Lothar and Gu, C. and Meyer, Fernand and Salembier, Philippe},
	month = jan,
	year = {1996},
}

@inproceedings{meyer_minimal_1994,
	address = {Fontainebleau, France},
	title = {Minimal spanning forests for morphological segmentation},
	booktitle = {Mathematical {Morphology} and its applications to signal processing ({Proceedings} {ISMM}'94)},
	publisher = {Kluwer Academic Publishers},
	author = {Meyer, Fernand},
	editor = {Serra, Jean and Soille, P.},
	month = sep,
	year = {1994},
	pages = {13--14},
}

@phdthesis{klein_conception_1977,
	title = {Conception et réalisation d'une unité logique pour l'analyse quantitative d'images},
	school = {Université de Nancy, France},
	author = {Klein, Jean-Claude},
	year = {1977},
}

@book{grimmett_percolation_1999,
	title = {Percolation, second edition},
	publisher = {Springer},
	author = {Grimmett, Geoffrey},
	year = {1999},
}

@article{morris_stochastic_1994,
	title = {Stochastic and deterministic methods in motion picture restoration},
	volume = {45},
	journal = {Journal of Communications},
	author = {Morris, R. D and Fitzgerald, W. J},
	month = aug,
	year = {1994},
	pages = {17--21},
}

@phdthesis{enficiaud_algorithmes_2007,
	title = {Algorithmes multidimensionnels et multispectraux en morphologie mathématique : approche par méta-programmation},
	school = {Ecole des Mines de Paris, Paris},
	author = {Enficiaud, Raffi},
	year = {2007},
}

@phdthesis{beucher_segmentation_1990,
	title = {Segmentation d'images et morphologie mathématique},
	school = {Ecole des Mines de Paris, Paris},
	author = {Beucher, Serge},
	month = jun,
	year = {1990},
}

@inproceedings{popp_surface_1999,
	title = {Surface characterization with regard to the tribological behaviour of sheet metal in forming processes},
	booktitle = {Proceedings of the {ShetMet}'99},
	author = {Popp, U. and Neudecker, T. and Geiger, M.},
	month = sep,
	year = {1999},
	pages = {303--310},
}

@book{thomas_rough_1982,
	title = {Rough {Surfaces}},
	publisher = {Longman Group UK Limited},
	author = {Thomas, T.R.},
	year = {1982},
}

@inproceedings{saito_image_2000,
	title = {Image processing for restoration of heavily corrupted old film sequences},
	volume = {3},
	booktitle = {Proc. of the 15th {International} {Conference} on {Pattern} {Recognition} ({ICPR})},
	author = {Saito, T. and Komatsu, T. and Ohuchi, T. and Seto, T.},
	month = sep,
	year = {2000},
	pages = {17--20},
}

@inproceedings{meyer_contrast_1977,
	address = {Caen, France},
	title = {Contrast features extraction},
	booktitle = {Quantitative analysis of microstructures in materials science, biology and medicine},
	publisher = {Riederer Verlag},
	author = {Meyer, Fernand},
	editor = {Chermant, J. L},
	year = {1977},
	pages = {374--380},
}

@inproceedings{efstratiadis_model_1990,
	title = {A model based, pel-recursive motion estimation algorithm},
	booktitle = {Proceedings {IEEE} {ICASSP}'90},
	author = {Efstratiadis, S. and Katsagellos, A.},
	year = {1990},
	pages = {1973--1976},
}

@inproceedings{caciu_stochastic_2005,
	address = {Paris, France},
	title = {Stochastic shape optimisation},
	booktitle = {Mathematical morphology: 40 years on ({Proceedings} of {ISMM}'2005)},
	author = {Caciu, Costin A and Decencière, Etienne and Jeulin, Dominique},
	editor = {Ronse, C. and Najman, L. and Decencière, Etienne},
	month = apr,
	year = {2005},
	pages = {333--342},
}

@inproceedings{vlachos_improving_1996,
	title = {Improving the efficiency of {MPEG}-2 coding by means of film unsteadiness correction},
	volume = {2952},
	booktitle = {Proc. {SPIE}: {Digital} {Compression} {Technologies} and {Systems} for {Video} {Communications}},
	author = {Vlachos, T.},
	month = oct,
	year = {1996},
	pages = {534--542},
}

@article{borgefors_multiscale_1999,
	title = {On the multiscale representation of {2D} and {3D} shapes},
	volume = {61},
	journal = {Graphical Models and Image Processing},
	author = {Borgefors, G. and Ramella, G. and Sanniti di Baja, G. and Svensson, S.},
	year = {1999},
	pages = {44--62},
}

@inproceedings{marcotegui_video_1999,
	address = {Kobe, Japan},
	title = {A {Video} {Object} {Generator} {Tool} {Allowing} {Friendly} {User} {Interaction}},
	booktitle = {{IEEE} {International} {Conference} on {Image} {Processing} ({ICIP}'99)},
	author = {Marcotegui, Beatriz and Correia, P. and Marqués, F. and Mech, R. and Rosa, R. and Wollborn, M. and Zanoguera, Francisca},
	month = oct,
	year = {1999},
}

@inproceedings{meyer_algorithme_1991,
	address = {Lyon, France},
	title = {Un algorithme optimal pour la ligne de partage des eaux},
	volume = {2},
	booktitle = {8ème congrès de reconnaissance des formes et intelligence artificielle},
	author = {Meyer, Fernand},
	month = nov,
	year = {1991},
	pages = {847--857},
}

@article{kleihorst_noise_1995,
	title = {Noise reduction of image sequences using motion compensation and signal decomposition},
	volume = {4},
	number = {3},
	journal = {IEEE Transactions on Image Processing},
	author = {Kleihorst, R. P and Lagendijk, R. L and Biemond, J.},
	year = {1995},
	pages = {274--284},
}

@inproceedings{armstrong_reconstructing_1998,
	address = {Rhodes, Greece},
	title = {Reconstructing missing regions in colour images using multichannel median models},
	booktitle = {European {Conference} on {Signal} {Processing} ({EUSIPCO} '98)},
	author = {Armstrong, S. and Kokaram, A. C and Rayner, P. J.W},
	month = sep,
	year = {1998},
}

@inproceedings{lerallut_noise_2005,
	address = {Genoa, Italy},
	title = {Noise reduction in {3D} images using morphological amoebas},
	booktitle = {Proceedings of {IEEE} {International} {Conference} on {Image} {Processing}},
	author = {Lerallut, Romain and Boehm, Mathilde and Decencière, Etienne and Meyer, Fernand},
	year = {2005},
}

@inproceedings{brun_restoration_2007,
	address = {Texas, USA},
	title = {Restoration of variable area soundtracks},
	booktitle = {Proc. of the 2007 {International} {Conference} on {Image} {Processing} ({ICIP}-2007)},
	author = {Brun, Emmanuel and Hassaïne, Abdelâali and Besserer, Bernard and Decenciére, Etienne},
	month = sep,
	year = {2007},
}

@article{rosen_wear_1996,
	title = {Wear of cylinder bore microtopography},
	volume = {198},
	journal = {Wear},
	author = {Rosén, B. -G and Ohlsson, R. and Thomas, T. R},
	month = apr,
	year = {1996},
	pages = {271--279},
}

@article{dong_comprehensive_1994,
	title = {Comprehensive study of parameters for characterizing three-dimensional surface topography. {III}: {Parameters} for characterising amplitude and some functional properties},
	volume = {178},
	journal = {Wear},
	author = {Dong, W. P and Sullivan, P. J and Stout, K. J},
	year = {1994},
	pages = {29--43},
}

@book{matheron_elements_1967,
	title = {Éléments pour une théorie des milieux poreux},
	publisher = {Masson, Paris},
	author = {Matheron, G.},
	year = {1967},
}

@book{matheron_les_1965,
	title = {Les variables régionalisées et leur estimation},
	publisher = {Masson, Paris},
	author = {Matheron, G.},
	year = {1965},
}

@inproceedings{cichosz_morphological_1997,
	address = {Louvain-la-Neuve (Belgium)},
	title = {Morphological multiscale image segmentation},
	booktitle = {Workshop on {Image} {Analysis} for {Multimedia} {Interactive} {Services} ({WIAMIS}'97)},
	author = {Cichosz, Jacek and Meyer, Fernand},
	month = jun,
	year = {1997},
	pages = {161--166},
}

@inproceedings{kokaram_system_1996,
	address = {Cambridge, UK},
	title = {A system for reconstruction of missing data in image sequences using sampled {3D} {AR} models and {MRF} motion priors},
	booktitle = {Computer {Vision} - {ECCV}'96},
	author = {Kokaram, A. C and Godsill, J.G.},
	editor = {Buxton, F. and Cipolla, R.},
	month = apr,
	year = {1996},
}

@article{ozkan_adaptive_1993,
	title = {Adaptive motion-compensated filtering of noisy image sequences},
	volume = {3},
	number = {4},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	author = {Ozkan, M. K and Sezan, M. I and Tekalp, A. M},
	year = {1993},
	pages = {277--290},
}

@article{hotter_detection_1996,
	title = {Detection and description of moving objects by stochastic modelling and analysis of complex scenes},
	volume = {8},
	journal = {Signal Processing: Image Communication},
	author = {Hötter, M. and Mester, R. and Müller, F.},
	year = {1996},
	pages = {281--293},
}

@inproceedings{pardas_connectivity_1992,
	address = {San Diego, USA},
	title = {Connectivity filters for image sequences},
	volume = {1769},
	booktitle = {Proc. {SPIE}: {Image} {Algebra} and {Morphological} {Image} {Processing} {III}},
	author = {Pardàs, M. and Serra, Jean and Torrés, L.},
	month = jul,
	year = {1992},
	pages = {318--329},
}

@inproceedings{decenciere_motion_1996,
	address = {Atlanta (GA), USA},
	title = {Motion picture restoration using morphological tools},
	booktitle = {Mathematical {Morphology} and its applications to signal processing ({Proceedings} {ISMM}'96)},
	publisher = {Kluwer Academic Publishers},
	author = {Decencière, Etienne},
	editor = {Maragos, P. and Schafer, R. W and Butt, M. A},
	month = may,
	year = {1996},
	pages = {361--368},
}

@phdthesis{barre_contribution_1997,
	title = {Contribution de l'analyse d'images à la caractérisation morphologique des surfaces industrielles},
	school = {Université Jean Monnet},
	author = {Barré, F.},
	month = sep,
	year = {1997},
}

@inproceedings{borgefors_multiresolution_1996,
	address = {Lyon, France},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Multiresolution representation of shape in binary images},
	volume = {1176},
	isbn = {3-540-62005-2},
	booktitle = {Discrete {Geometry} for {Computer} {Imagery}, ({Proceedings} {DCGI}'96)},
	publisher = {Springer},
	author = {Borgefors, G. and Ramella, G. and Sanniti di Baja, G.},
	editor = {Miguet, Serge and Montanvert, Annick and Ubéda, Stéphane},
	month = nov,
	year = {1996},
	pages = {51--58},
}

@phdthesis{gratin_representation_1993,
	title = {De la {Représentation} des {Images} au {Traitement} {Morphologique} d'{Images} {Tridimensionnelles}},
	school = {Ecole des Mines de Paris, Paris},
	author = {Gratin, Christophe},
	year = {1993},
}

@inproceedings{decenciere_content_2000,
	address = {Palo Alto, CA, United States},
	title = {Content dependent image sampling using mathematical morphology},
	booktitle = {Mathematical {Morphology} and its applications to signal processing ({Proceedings} {ISMM}'2000)},
	publisher = {Kluwer Academic Publishers},
	author = {Decencière, Etienne and Marcotegui, Beatriz and Meyer, Fernand},
	editor = {Goutsias, J. and Vincent, L. and Bloomberg, D. S},
	month = jun,
	year = {2000},
	pages = {263--272},
}

@inproceedings{vlachos_motion_1996,
	address = {Lausanne, Switzerland},
	title = {Motion estimation for the correction of twins-lens telecine flicker},
	volume = {1},
	booktitle = {Proceedings of {ICIP}-96},
	publisher = {IEEE Computer Society Press},
	author = {Vlachos, T. and Thomas, G.},
	month = sep,
	year = {1996},
	pages = {109--112},
}

@article{geman_stochastic_1984,
	title = {Stochastic relaxation, {Gibbs} distributions, and the {Bayesian} restoration of images},
	volume = {6},
	issn = {0162-8828},
	number = {6},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Geman, S. and Geman, D.},
	month = nov,
	year = {1984},
	pages = {721--741},
}

@inproceedings{armstrong_interpolation_1997,
	address = {Mackinak Island, Boston, U.S.A},
	title = {Interpolation of {Missing} {Data} using {MIN}-{MAX} {Predictors}.},
	booktitle = {{EEE} {Conference} on {Non} {Linear} {Signal} {Processing}},
	author = {Armstrong, S. and Kokaram, A. C and Rayner, P. J.W},
	month = sep,
	year = {1997},
}

@article{pardas_3d_1994,
	title = {{3D} morphological segmentation and motion estimation for image sequences},
	volume = {38},
	journal = {Signal Processing},
	author = {Pardàs, M. and Salembier, Philippe},
	year = {1994},
	pages = {31--43},
}

@book{chauvet_aide-memoire_1993,
	title = {Aide-mémoire de géostatistique linéaire},
	publisher = {Ecole des Mines de Paris},
	author = {Chauvet, P.},
	year = {1993},
}

@phdthesis{vincent_algorithmes_1990,
	title = {Algorithmes morphologiques à base de files d'attente et de lacets. {Extension} aux graphes},
	school = {Ecole des Mines de Paris, Paris},
	author = {Vincent, L.},
	month = may,
	year = {1990},
}

@inproceedings{ohuchi_robust_2000,
	title = {A robust method of image flicker correction for heavily-corrupted old film sequences},
	booktitle = {Proc. of the 2000 {International} {Conference} on {Image} {Processing} ({ICIP}-2000)},
	author = {Ohuchi, T. and Seto, T. and Komatsu, T. and Saito, T.},
	month = sep,
	year = {2000},
}

@inproceedings{kokaram_detection_1996,
	address = {Trieste, Italy},
	title = {Detection and removal of line scratches in degraded motion picture sequences},
	booktitle = {Proceedings of {EUSIPCO}'96},
	author = {Kokaram, A. C},
	month = sep,
	year = {1996},
}

@inproceedings{dudon_triangle-based_1995,
	address = {Haldiki, Greece},
	title = {Triangle-based motion estimation and temporal interpolation},
	booktitle = {{IEEE} workshop on nonlinear signal and image processing ({NSIP}'95)},
	author = {Dudon, M. and Avaro, O. and Roux, C.},
	month = jun,
	year = {1995},
	pages = {242--245},
}

@article{kong_digital_1989,
	title = {Digital topology: introduction and survey},
	volume = {48},
	journal = {Computer Vision, Graphics, and Image Processing},
	author = {Kong, T. Y and Rosenfeld, A.},
	year = {1989},
	pages = {357--393},
}

@article{roerdink_watershed_2000,
	title = {The {Watershed} {Transform}: {Definitions}, {Algorithms} and {Parallelization} {Strategies}},
	volume = {41},
	journal = {Fundamenta Informaticae},
	author = {Roerdink, J. B.T.M and Meijster, A.},
	year = {2000},
	pages = {187--228},
}

@article{grimaud_new_1992,
	title = {New measure of contrast : dynamics},
	journal = {Image Algebra and Morphological Processing III, San Diego CA, Proc. SPIE},
	author = {Grimaud, M.},
	year = {1992},
}

@book{schmitt_morphologie_1993,
	title = {Morphologie mathématique},
	publisher = {Masson, Paris},
	author = {Schmitt, Michel and Mattioli, Juliette},
	year = {1993},
}

@article{salembier_segmentation-based_1997,
	title = {Segmentation-based video coding system allowing the manipulation of objects},
	volume = {7},
	number = {1},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	author = {Salembier, Philippe and Marqués, F. and Pardàs, M. and Morros, R. and Corset, I. and Jeannin, S. and Bouchard, L. and Meyer, Fernand and Marcotegui, B.},
	month = feb,
	year = {1997},
	pages = {60--74},
}

@inproceedings{kokaram_joint_1997,
	address = {Florence, Italy},
	title = {Joint detection, interpolation, motion and parameter estimation for image sequences with missing data},
	booktitle = {International {Conference} on {Image} {Applications} and {Processing}},
	author = {Kokaram, A. C and Godsill, S.},
	year = {1997},
}

@inproceedings{angulo_stochastic_2007,
	address = {Rio de Janeiro, Brazil},
	title = {Stochastic watershed segmentation},
	booktitle = {Mathematical {Morphology} and its {Applications} to {Signal} and {Image} {Processing} ({Proc}. {ISMM}'07)},
	author = {Angulo, Jesus and Jeulin, Dominique},
	year = {2007},
}

@techreport{corset_technical_1995,
	title = {Technical description of {SESAME} ({SEgmentation}-based coding {System} {Allowing} {Manipulation} of {objEcts})},
	institution = {ISO/IEC JTC1/SC29/WG11. MPEG 95 / 408},
	author = {Corset, I. and Bouchard, L. and Jeannin, S. and Salembier, Philippe and Marques, F. and Pardàs, M. and Morros, R. and Meyer, Fernand and Marcotegui, B.},
	month = nov,
	year = {1995},
}

@inproceedings{staeves_topography_1997,
	address = {Gifu, Japan},
	title = {Topography of sheet metal and its relationship to the tribological behaviour during the forming process},
	booktitle = {International conference on tribology in manufacturing processes ({ICTMP}'97)},
	author = {Staeves, J. and Schmoeckel, D.},
	year = {1997},
}

@inproceedings{yeh_perceptual_1998,
	title = {A {Perceptual} {Distortion} {Measure} for {Edge}-like {Artifacts} in {Image} {Sequences}},
	booktitle = {Conference on {Human} {Vision}, {Visual} {Processing} and {Digital} {Display} {III}},
	publisher = {SPIE},
	author = {Yeh, E. M. and Kokaram, A. C. and Kingsbury, N. G.},
	month = jan,
	year = {1998},
}

@book{chauvet_processing_1993,
	title = {Processing data with a spatial support : {Geostatistics} and its methods},
	publisher = {Ecole des Mines de Paris},
	author = {Chauvet, P.},
	year = {1993},
}

@inproceedings{serra_connected_1993,
	address = {San Diego, USA},
	title = {Connected operators and pyramids},
	volume = {2030},
	booktitle = {Proc. {SPIE}: {Non} linear algebra and morphological image processing},
	author = {Serra, Jean and Salembier, Philippe},
	month = jul,
	year = {1993},
	pages = {65--76},
}

@inproceedings{decenciere_application_1998,
	title = {Application de la morphologie mathématique au mipmapping},
	booktitle = {{CORESA}'98},
	author = {Decencière, Etienne and Marcotegui, Beatriz and Meyer, Fernand},
	month = jun,
	year = {1998},
}

@article{wu_optimal_1993,
	title = {An optimal graph theoretic approach to data clustering : theory and its applications to image segmentation},
	volume = {15},
	number = {11},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Wu, Z. and Leahy, R.},
	month = nov,
	year = {1993},
	pages = {1101--1113},
}

@inproceedings{lacroute_fast_1994,
	title = {Fast volume rendering using a shear-warp factorization of the viewing tranformation},
	booktitle = {{SIGGRAPH} 1994 {Proceedings}},
	author = {Lacroute, Philippe and Levoy, Marc},
	year = {1994},
	pages = {451--457},
}

@article{van_roosmalen_correction_1999,
	title = {Correction of intensity flicker in old film sequences},
	volume = {9},
	number = {7},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	author = {van Roosmalen, P. M.B and Lagendijk, R. L and Biemond, J.},
	year = {1999},
	pages = {1013--1019},
}

@inproceedings{vincent_morphological_1992,
	address = {Driebergen, The Netherlands},
	title = {Morphological area opening and closing for gray scale images},
	booktitle = {Proceedings of {NATO}: {Shape} in picture workshop},
	author = {Vincent, L.},
	month = sep,
	year = {1992},
}

@inproceedings{stawiaski_spatio_2008,
	address = {London, United Kingdom},
	title = {Spatio temporal segmentation for radiotherapy planning},
	booktitle = {Proceedings of {ECMI} 2008},
	author = {Stawiaski, Jean and Decencière, Etienne},
	year = {2008},
}

@techreport{ahuja_fast_1987,
	type = {Tech. rep.},
	title = {A fast and simple algorithm for the maximum flow problem},
	number = {1905–87},
	institution = {Massachusetts Institute of Technology},
	author = {Ahuja, R. K and Orlin, J. B},
	year = {1987},
}

@inproceedings{kokaram_reconstruction_1997,
	address = {Florence, Italy},
	title = {Reconstruction of severely degraded image sequences},
	booktitle = {International {Conference} on {Image} {Applications} and {Processing}},
	author = {Kokaram, A. C},
	year = {1997},
}

@article{meyer_overview_2001,
	title = {An {Overview} of {Morphological} {Segmentation}},
	volume = {15},
	number = {7},
	journal = {International Journal of Pattern Recognition and Artificial Intelligence},
	author = {Meyer, Fernand},
	year = {2001},
	pages = {1089--1118},
}

@inproceedings{marcotegui_segmentation_1996-1,
	address = {Atlanta (GA), USA},
	title = {Segmentation algorithm by multicriteria region merging},
	booktitle = {Mathematical {Morphology} and its applications to signal processing ({Proceedings} {ISMM}'96)},
	publisher = {Kluwer Academic Publishers},
	author = {Marcotegui, Beatriz},
	editor = {Maragos, P. and Schafer, R. W and Butt, M. A},
	month = may,
	year = {1996},
	pages = {313--320},
}

@article{salembier_region-based_1999,
	title = {Region-based representations of image and video : segmentation tools for multimedia services},
	volume = {9},
	number = {8},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	author = {Salembier, Philippe and Marqués, F.},
	month = dec,
	year = {1999},
}

@inproceedings{schmoeckel_function-oriented_1997,
	title = {Function-oriented {3D} filtering for tribological assessment of sheet metal surfaces in deep-drawing},
	booktitle = {7th international conference on metrology and properties of engineering surfaces},
	author = {Schmoeckel, D. and Staeves, J.},
	year = {1997},
	pages = {438--444},
}

@book{foresti_multimedia_2000,
	title = {multimedia video-based surveillance systems},
	publisher = {Kluwer academic publishers},
	editor = {Foresti, Gian Luca and Mähönen, Petri and Regazzoni, Carlo S},
	year = {2000},
}

@article{dubois_noise_1984,
	title = {Noise reduction in image sequences using motion compensated temporal filtering},
	volume = {32},
	number = {7},
	journal = {IEEE Transactions on Communications},
	author = {Dubois, E. and Sabri, S.},
	year = {1984},
	pages = {826--831},
}

@article{tian_motion_1996,
	title = {Motion estimation and segmentation},
	volume = {9},
	journal = {Machine Vision and Applications},
	author = {Tian, T. Y and Shah, M.},
	year = {1996},
	pages = {32--42},
}

@article{albiol_morphological_1997,
	title = {Morphological image enlargements},
	volume = {8},
	number = {4},
	journal = {Journal of Visual Communication and Image Representation},
	author = {Albiol, A. and Serra, Jean},
	month = dec,
	year = {1997},
	pages = {367--383},
}

@article{salembier_flat_1995,
	title = {Flat zones filtering, connected operators and filters by reconstruction},
	volume = {3},
	number = {8},
	journal = {IEEE Transactions on Image Processing},
	author = {Salembier, Philippe and Serra, Jean},
	month = aug,
	year = {1995},
	pages = {1153--1160},
}

@phdthesis{van_droogenbroeck_traitement_1994,
	title = {Traitement d'images numériques au moyen d'algorithmes utilisant la morphologie mathématique et la notion d'objet : application au codage},
	school = {Ecole des Mines de Paris, Paris},
	author = {Van Droogenbroeck, Marc},
	month = may,
	year = {1994},
}

@article{karczewicz_video_1997,
	title = {Video coding using motion compensation with polynomial motion vector fields},
	volume = {10},
	number = {1-3},
	journal = {Signal Processing: Image Communication},
	author = {Karczewicz, M. and Nieweglowski, J. and Haavisto, P.},
	month = jul,
	year = {1997},
	pages = {63--91},
}

@article{wang_representing_1994,
	title = {Representing moving images with layers},
	volume = {3},
	number = {5},
	journal = {IEEE Transactions on Image Processing},
	author = {Wang, John Y. A and Adelson, Edward H},
	month = sep,
	year = {1994},
}

@article{greig_exact_1989,
	title = {Exact maximum a posteriori estimation for binary images},
	volume = {51},
	number = {2},
	journal = {Journal of the Royal Statistical Society, Series B},
	author = {Greig, D. and Porteous, B. and Seheult, A.},
	year = {1989},
	pages = {271--279},
}

@inproceedings{morris_stochastic_1994-1,
	address = {Budapest, Hungary},
	title = {Stochastic and deterministic methods in motion picture restoration},
	booktitle = {Proceedings of international workshop in image processing},
	author = {Morris, R. D and Fitzgerald, W. J},
	month = jun,
	year = {1994},
}

@article{nicolas_motion_1995,
	title = {Motion and illumination variation estimation using a hierarchy of models: application to image sequence coding},
	volume = {6},
	number = {4},
	journal = {Journal of Visual Communication and Image Representation},
	author = {Nicolas, H. and Labit, C.},
	year = {1995},
	pages = {303--316},
}

@book{matheron_les_1980,
	title = {Les fonctions aléatoires intrinsèques d'ordre k},
	publisher = {Ecole des Mines de Paris},
	author = {Matheron, G. and Delfiner, P.},
	year = {1980},
}

@article{lantuejoul_use_1981,
	title = {On the use of the geodesic metric in image analysis},
	volume = {121},
	journal = {Journal of Microscopy},
	author = {Lantuéjoul, Christian and Beucher, Serge},
	year = {1981},
	pages = {39--49},
}

@article{decenciere_adaptive_2007,
	title = {Adaptive crossing numbers and their application to binary downsampling},
	volume = {26},
	number = {2},
	journal = {Image Analysis and Stereology},
	author = {Decencière, Etienne and Bilodeau, Michel},
	month = jun,
	year = {2007},
	pages = {73--81},
}

@inproceedings{khriji_rational_1999,
	address = {Kobe, Japan},
	title = {Rational {Spatial} {Interpolators} for {Old} {Movie} {Restoration}},
	booktitle = {1999 {IEEE} {International} {Conference} on {Image} {Processing}},
	author = {Khriji, L. and Gabbouj, M. and Ramponi, G. and Decencière, Etienne},
	month = oct,
	year = {1999},
}

@phdthesis{andre_segmentation_2002,
	title = {Segmentation {3D} d'images radiologiques : applications à la volumétrie d'organes et de lésions},
	school = {Université Paris XI Orsay},
	author = {André, G.},
	month = nov,
	year = {2002},
}

@article{arce_multistage_1991,
	title = {Multistage order statistics filters for image sequence processing},
	volume = {39},
	number = {5},
	journal = {IEEE Transactions on Acoustics, Speech and Signal Processing},
	author = {Arce, G. R},
	year = {1991},
	pages = {1146--1163},
}

@article{jain_displacement_1981,
	title = {Displacement measurement and its application in interframe image coding},
	volume = {29},
	number = {12},
	journal = {IEEE Transactions on Communications},
	author = {Jain, J. R and Jain, A. K},
	year = {1981},
	pages = {1799--1808},
}

@inproceedings{khriji_old_1999,
	address = {Paphos, Cyprus},
	title = {Old movie restoration using rational spatial interpolators},
	booktitle = {The 6th {IEEE} {International} {Conference} on {Electronics}, {Circuits} and {Systems}},
	author = {Khriji, L. and Gabbouj, M. and Ramponi, G. and Decencière, Etienne},
	month = sep,
	year = {1999},
}

@inproceedings{vincent_mathematical_1988,
	address = {Cambridge, MA},
	title = {Mathematical morphology on graphs},
	booktitle = {Proc. {SPIE}'s visual communications and image processing 88},
	author = {Vincent, Luc},
	month = nov,
	year = {1988},
	pages = {95--105},
}

@incollection{vichik_self-dual_2007,
	address = {Rio de Janeiro, Brazil},
	title = {Self-dual morphology on tree semilattices and applications},
	booktitle = {Proceedings of the 8th {International} {Symposium} on {Mathematical} {Morphology}},
	author = {Vichik, A. and Keshet, Renato and Malah, David},
	year = {2007},
}

@article{heijmans_inf-semilattice_2002,
	title = {Inf-{Semilattice} {Approach} to {Self}-{Dual} {Morphology}},
	journal = {Journal of Mathematical Imaging and Vision},
	author = {Heijmans, Henk J.A.M. and Keshet, Renato},
	year = {2002},
	pages = {55--80},
}

@article{heijmans_self-dual_1996,
	title = {Self-dual morphological operators and filters},
	volume = {6},
	issn = {0924-9907},
	url = {http://dx.doi.org/10.1007/BF00127373},
	abstract = {The median operator is a nonlinear image transformation celebrated for its noise cleaning capacities. It treats the foreground and background of an image identically, i.e., it is self-dual. Unfortunately, the median operator has one major drawback: it is not idempotent. Even worse, subsequent iterations of a given image may lead to oscillations. This paper describes a general method for the construction of morphological operators which are self-dual. This construction is based upon the concept of a switch operator. Subsequently, the paper treats a class of operators, the so-called activity-extensive operators, which have the intriguing property that every sequence of iterates of a given image is pointwise monotone and therefore convergent. The underlying concept is that of the activity ordering. Every increasing, self-dual operator can be modified in such a way that it becomes activity-extensive. The sequence of iterates of this modification converges to a self-dual morphological filter.},
	journal = {Journal of Mathematical Imaging and Vision},
	author = {Heijmans, Henk J. A. M},
	year = {1996},
	note = {10.1007/BF00127373},
	pages = {15--36},
}

@article{heijmans_self-dual_1996-1,
	title = {Self-dual morphological operators and filters},
	volume = {6},
	issn = {0924-9907},
	url = {http://dx.doi.org/10.1007/BF00127373},
	abstract = {The median operator is a nonlinear image transformation celebrated for its noise cleaning capacities. It treats the foreground and background of an image identically, i.e., it is self-dual. Unfortunately, the median operator has one major drawback: it is not idempotent. Even worse, subsequent iterations of a given image may lead to oscillations. This paper describes a general method for the construction of morphological operators which are self-dual. This construction is based upon the concept of a switch operator. Subsequently, the paper treats a class of operators, the so-called activity-extensive operators, which have the intriguing property that every sequence of iterates of a given image is pointwise monotone and therefore convergent. The underlying concept is that of the activity ordering. Every increasing, self-dual operator can be modified in such a way that it becomes activity-extensive. The sequence of iterates of this modification converges to a self-dual morphological filter.},
	journal = {Journal of Mathematical Imaging and Vision},
	author = {Heijmans, Henk J. A. M},
	year = {1996},
	note = {10.1007/BF00127373},
	pages = {15--36},
}

@incollection{matheron_filters_1988,
	title = {Filters and lattices},
	volume = {2},
	booktitle = {Image analysis and mathematical morphology - {Volume} 2: theoretical advances},
	publisher = {Academic Press},
	author = {Matheron, Georges},
	editor = {Serra, Jean},
	year = {1988},
	pages = {115--140},
}

@article{matheron_intrinsic_1973,
	title = {The intrinsic random functions, and their applications},
	volume = {5},
	journal = {Advances in Applied Probability},
	author = {Matheron, Georges},
	year = {1973},
	pages = {439--468},
}

@book{matheron_traite_1963,
	title = {Traité de géostatistique appliquée, tome {II}},
	publisher = {Editions Techniques, Paris},
	author = {Matheron, Georges},
	year = {1963},
}

@inproceedings{acton_locally_1999,
	address = {Kobe, Japan},
	title = {Locally monotonic models for image and video processing},
	url = {http://ieeexplore.ieee.org/xpl/downloadCitations},
	doi = {10.1109/ICIP.1999.822932},
	urldate = {2011-04-11},
	booktitle = {Proceedings 1999 {International} {Conference} on {Image} {Processing} ({Cat}. {99CH36348})},
	author = {Acton, S.T. and Restrepo, A.},
	year = {1999},
	pages = {429--433},
	file = {:/home/edecenciere/Zotero/storage/ZKVTE9TD/downloadCitations.html:text/html},
}

@inproceedings{bosworth_morphological_1999,
	address = {Kobe, Japan},
	title = {The morphological lomo filter for multiscale image processing},
	url = {http://ieeexplore.ieee.org/xpl/downloadCitations},
	doi = {10.1109/ICIP.1999.819569},
	urldate = {2011-04-11},
	booktitle = {Proceedings 1999 {International} {Conference} on {Image} {Processing} ({Cat}. {99CH36348})},
	author = {Bosworth, J. and Acton, S.T.},
	year = {1999},
	pages = {157--161},
	file = {:/home/edecenciere/Zotero/storage/5HR49XX9/downloadCitations.html:text/html},
}

@article{bosworth_morphological_2003,
	title = {Morphological scale-space in image processing},
	volume = {13},
	issn = {1051-2004},
	url = {http://www.sciencedirect.com/science/article/B6WDJ-47GXWMM-2/2/f220edd9d1d9263e9f9c0103a6b94cb1},
	doi = {10.1016/S1051-2004(02)00033-7},
	abstract = {{\textless}p{\textgreater}{\textless}br/{\textgreater}The purpose of this paper is twofold. First, we provide an extensive review of the state-of-the-art in scale-space generation techniques for image processing, including linear methods, diffusion-based methods, and emphasizing morphological methods. Then, we introduce a new morphological approach to scale-space, called the lomo scale-space. The technique introduces a novel two-dimensional generalization of the concept of locally monotonic (lomo) signals. The lomo scale-space is a sequence of locally monotonic image representations where the scale is specified by the spatial extent or degree of local monotonicity. The morphological process used to generate the lomo scale-space retains many desirable properties of other morphological methods, such as edge localization and smoothing of extrema. In contrast to previous morphological scale-space methods, the filters employed here are self-dual, and thus do not induce a gray-level bias into the scaled signal representations. The scale-space methods reviewed and introduced in this paper are applicable to several multiscale image processing tasks such as segmentation, object-based image compression, content-based retrieval, and video tracking.{\textless}/p{\textgreater}},
	number = {2},
	urldate = {2011-04-11},
	journal = {Digital Signal Processing},
	author = {Bosworth, Joseph H. and Acton, Scott T.},
	month = apr,
	year = {2003},
	keywords = {Morphology, Non-linear filters, Scale-space},
	pages = {338--367},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/75CNJKMI/Bosworth et Acton - 2003 - Morphological scale-space in image processing:},
}

@inproceedings{schulze_linear_1993,
	address = {Los Alamitos, CA, USA},
	title = {Linear combinations of morphological operators: the midrange, pseudomedian, and {LOCO} filters},
	volume = {5},
	isbn = {0-7803-0946-4},
	shorttitle = {Linear combinations of morphological operators},
	doi = {http://doi.ieeecomputersociety.org/10.1109/ICASSP.1993.319746},
	abstract = {It is shown how linear combinations of morphological operators can be formed to alleviate the bias introduced by the individual morphological operators. Since every morphological operator has a complementary operator that is equally and oppositely biased, the authors propose averaging the complementary operators to alleviate the bias. Of the three filters formed by averaging the standard morphological operators, two are the previously defined midrange filter, and pseudomedian filter, while one is a new filter, called the LOCO filter. Under most conditions, the LOCO filter is the best of these at reducing impulses and noise., Linear combinations of morphological operators allow the shape control of the morphological filters (exerted by the selection of a structuring element) without introducing bias. For example, the LOCO filter with a square structuring element preserves 90 degrees corners in an image while reducing noise almost as well as the square-shaped medium filter, which rounds off such corners.},
	booktitle = {Acoustics, {Speech}, and {Signal} {Processing}, {IEEE} {International} {Conference} on},
	publisher = {IEEE Computer Society},
	author = {Schulze, M.A. and Pearce, J.A.},
	year = {1993},
	pages = {57--60vol.5},
	file = {Linear combinations of morphological operators\: the midrange, pseudomedian, and LOCO filters:/home/edecenciere/Zotero/storage/FGUKB72W/ICASSP.1993.html:text/html},
}

@inproceedings{schulze_properties_1991,
	address = {San Jose, CA, USA},
	title = {Some properties of the two-dimensional pseudomedian filter},
	url = {http://link.aip.org/link/?PSI/1451/48/1&Agg=doi},
	doi = {10.1117/12.44315},
	urldate = {2011-04-11},
	booktitle = {Proceedings of {SPIE}},
	author = {Schulze, Mark A. and Pearce, John A.},
	year = {1991},
	pages = {48--57},
}

@misc{pratt_pseudomedian_1985,
	title = {Pseudomedian filter},
	url = {http://adsabs.harvard.edu/abs/1985SPIE..534...34P},
	urldate = {2011-04-11},
	author = {Pratt, W. K and Cooper, T. J and Kabir, I.},
	month = jan,
	year = {1985},
	file = {NASA ADS\: Pseudomedian filter:/home/edecenciere/Zotero/storage/IZTCVGMD/1985SPIE..534...html:text/html},
}

@article{restrepo_adaptive_1988,
	title = {Adaptive trimmed mean filters for image restoration},
	volume = {36},
	issn = {00963518},
	url = {http://ieeexplore.ieee.org/xpl/downloadCitations},
	doi = {10.1109/29.1660},
	number = {8},
	urldate = {2011-04-11},
	journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
	author = {Restrepo, A. and Bovik, A.C.},
	month = aug,
	year = {1988},
	pages = {1326--1337},
	file = {:/home/edecenciere/Zotero/storage/G37TR9XB/downloadCitations.html:text/html},
}

@book{david_order_1981,
	address = {New York},
	title = {Order statistics, 2nd edition},
	publisher = {Wiley},
	author = {David, H.A.},
	year = {1981},
}

@article{ray_inclusion_2005,
	title = {Inclusion filters: a class of self-dual connected operators},
	volume = {14},
	issn = {1057-7149},
	shorttitle = {Inclusion filters},
	url = {http://ieeexplore.ieee.org/xpl/downloadCitations},
	doi = {10.1109/TIP.2005.857251},
	number = {11},
	urldate = {2011-04-08},
	journal = {IEEE Transactions on Image Processing},
	author = {Ray, N. and Acton, S.T.},
	month = nov,
	year = {2005},
	pages = {1736--1746},
	file = {:/home/edecenciere/Zotero/storage/JB4I4BVZ/downloadCitations.html:text/html},
}

@article{ray_inclusion_2005-1,
	title = {Inclusion filters: a class of self-dual connected operators},
	volume = {14},
	issn = {1057-7149},
	shorttitle = {Inclusion filters},
	url = {http://ieeexplore.ieee.org/xpl/downloadCitations},
	doi = {10.1109/TIP.2005.857251},
	number = {11},
	urldate = {2011-04-08},
	journal = {IEEE Transactions on Image Processing},
	author = {Ray, N. and Acton, S.T.},
	month = nov,
	year = {2005},
	pages = {1736--1746},
	file = {:/home/edecenciere/Zotero/storage/PARPU4Q2/downloadCitations.html:text/html},
}

@article{pascal_monsasse_fast_2000,
	title = {Fast computation of a contrast-invariant image representation},
	volume = {9},
	number = {5},
	journal = {IEEE Transactions on Image Processing},
	author = {{Pascal Monsasse} and {Frédéric Guichard}},
	month = may,
	year = {2000},
	pages = {860--872},
}

@inproceedings{depommier_motion_1992,
	address = {San Francisco, USA},
	title = {Motion estimation with detection of occlusion areas},
	booktitle = {Proceedings of {ICASSP}'92},
	author = {Depommier, R. and Dubois, E.},
	month = apr,
	year = {1992},
	pages = {269--273},
}

@inproceedings{decenciere_segmentation-based_1998,
	address = {Amsterdam, The Netherlands},
	title = {Segmentation-based motion compensation},
	booktitle = {Mathematical {Morphology} and its applications to signal processing ({Proceedings} {ISMM}'98)},
	publisher = {Kluwer Academic Publishers},
	author = {Decencière, Etienne},
	editor = {Heijmans, H. J.A.M and Roerding, J. B.T.M},
	month = jun,
	year = {1998},
}

@inproceedings{kolmogorov_what_2002,
	title = {What {Energy} {Functions} {Can} {Be} {Minimized} via {Graph} {Cuts} ?},
	booktitle = {{ECCV}},
	author = {Kolmogorov, V. and Zabih, R.},
	year = {2002},
}

@article{dong_comprehensive_1994-1,
	title = {Comprehensive study of parameters for characterizing three-dimensional surface topography. {IV}: {Parameters} for characterising spatial and hybrid properties},
	volume = {178},
	journal = {Wear},
	author = {Dong, W. P and Sullivan, P. J and Stout, K. J},
	year = {1994},
	pages = {45--60},
}

@inproceedings{chenot_new_1998,
	address = {Montreux, Switzerland},
	title = {New tools for digital restoration of television archives},
	booktitle = {Proceedings of the {IAB} seminar on television archives preservation and creative use},
	author = {Chenot, J. H},
	month = apr,
	year = {1998},
}

@inproceedings{armstrong_bayesian_1998,
	address = {San Diego, U.S.A.},
	title = {Bayesian framework for reconstructing color image data},
	booktitle = {{SPIE} {Conference} on {Bayesian} {Inference} for {Inverse} {Problems}},
	author = {Armstrong, S. and Kokaram, A. C and Rayner, P. J.W},
	month = jul,
	year = {1998},
}

@article{buisson_motion_2003,
	title = {Motion compensated film restoration},
	volume = {13},
	number = {4},
	journal = {Machine vision and applications},
	author = {Buisson, O. and Boukir, S. and Besserer, B.},
	year = {2003},
	pages = {201--212},
}

@book{ford_flows_1962,
	title = {Flows in networks},
	publisher = {Princeton University Press},
	author = {Ford, L. R and Fulkerson, D. R},
	year = {1962},
}

@incollection{hilditch_linear_1969,
	title = {Linear skeletons from square cupboards},
	booktitle = {Machine {Intelligence}, {Vol}. 4},
	publisher = {Edinburgh Univ. Press},
	author = {Hilditch, C. J},
	editor = {Meltzer, B. and Michie, D.},
	year = {1969},
	pages = {403--420},
}

@book{press_numerical_1988,
	title = {Numerical {Recipes} in {C}},
	publisher = {Cambridge University Press},
	author = {Press, W.H. and Flannery, B.P. and Teukolsky, S.A. and Vetterling, W.T.},
	year = {1988},
}

@inproceedings{goh_bi-directional_1996,
	title = {Bi-directional {3D} auto-regressive model approach to motion picture restoration},
	booktitle = {{IEEE} {International} conference on acoustics, speech and signal processing},
	publisher = {IEEE},
	author = {Goh, W. B and Chong, M. N and Kalra, S. and Krishnan, D.},
	month = may,
	year = {1996},
	pages = {2277--2280},
}

@inproceedings{marichal_motion_1996,
	address = {Melbourne, Australia},
	title = {Motion reconstruction with wireframe structures},
	booktitle = {Picture coding symposium},
	author = {Marichal, X. and Macq, B.},
	month = mar,
	year = {1996},
}

@inproceedings{cousty_watershed_2007,
	address = {Rio de Janeiro, Brazil},
	title = {Watershed cuts},
	booktitle = {Mathematical {Morphology} and its {Applications} to {Signal} and {Image} {Processing} ({Proc}. {ISMM}'07)},
	author = {Cousty, J. and Bertrand, G. and Najman, L. and Couprie, M.},
	year = {2007},
	pages = {301--312},
}

@article{levoy_volume_1990,
	title = {Volume {Rendering} by {Adaptative} {Refinement}},
	volume = {6},
	number = {1},
	journal = {The Visual Computer},
	author = {Levoy, Marc},
	month = jul,
	year = {1990},
	pages = {2--7},
}

@article{pfestorf_3d-surface_1998,
	title = {{3D}-surface parameters and their application on deterministic textured methal sheets},
	volume = {38},
	number = {5-6},
	journal = {International Journal of Machine Tools and Manufacture},
	author = {Pfestorf, M. and Engel, U. and Geiger, M.},
	year = {1998},
	pages = {607--614},
}

@article{archard_surface_1974,
	title = {Surface topography and tribology},
	number = {7},
	journal = {Tribology International},
	author = {Archard, J. F},
	year = {1974},
	pages = {213--220},
}

@article{chen_fast_2001,
	title = {Fast block-matching algorithm based on the winner-update strategy},
	volume = {10},
	number = {8},
	journal = {IEEE Transactions on Image Processing},
	author = {Chen, Yong-Shen and Hung, Yi-Ping and Fuh, Chiou-Shann},
	month = aug,
	year = {2001},
	pages = {1212--1222},
}

@inproceedings{salembier_very_1996,
	address = {Lausanne, Switzerland},
	title = {Very low bit rate video coding using active triangular mesh},
	booktitle = {{IEEE} {International} {Conference} on {Acoustics}, {Speech} \& {Signal} {Processing}, {ICASSP}'96},
	author = {Salembier, Philippe and Ayuso, X.},
	month = sep,
	year = {1996},
}

@book{serra_image_1982,
	title = {Image {Analysis} and {Mathematical} {Morphology} - {Volume} {I}},
	publisher = {Academic Press},
	author = {Serra, Jean},
	year = {1982},
}

@article{decenciere_applications_1998,
	title = {Applications of kriging to image sequence coding},
	volume = {13},
	number = {3},
	journal = {Signal Processing: Image Communication},
	author = {Decencière, Etienne and de Fouquet, Chantal and Meyer, Fernand},
	month = dec,
	year = {1998},
	pages = {227--249},
}

@article{haralick_digital_1989,
	title = {The digital morphological sampling theorem},
	volume = {37},
	journal = {IEEE Transactions on Acoustics, Speech and Signal Processing},
	author = {Haralick, R.M. and Zhuang, X. and Lin, C. and Lee, J.S.J.},
	month = dec,
	year = {1989},
	pages = {2067--2090},
}

@inproceedings{boykov_interactive_2001,
	address = {Vancouver, Canada},
	title = {Interactive {Graph} {Cuts} for {Optimal} {Boundary} and {Region} {Segmentation} of {Objects} in {N}-{D} {Images}},
	booktitle = {International {Conference} on {Computer} {Vision}},
	author = {Boykov, Y. and Jolly, M. P},
	year = {2001},
	pages = {105--112},
}

@article{diehl_object-oriented_1991,
	title = {Object-oriented motion estimation and segmentation in image sequences},
	volume = {3},
	journal = {Signal Processing: Image Communication},
	author = {Diehl, N.},
	year = {1991},
	pages = {23--56},
}

@inproceedings{haralick_multi-resolution_1987,
	title = {Multi-resolution morphology},
	booktitle = {{IEEE} {First} {International} {Conference} on {Computer} {Vision}},
	author = {Haralick, R.M. and Lin, C. and Lee, J.S.J. and Zhuang, X.},
	year = {1987},
	pages = {516--520},
}

@article{hamarneh_watershed_2007,
	title = {Watershed segmentation using prior shape and appearance knowledge},
	volume = {In Press},
	journal = {Image and Vision Computing},
	author = {Hamarneh, Ghassan and Li, Xiaoxing},
	year = {2007},
}

@phdthesis{gu_multivalued_1995,
	title = {Multivalued morphology and segmentation based coding},
	school = {EPFL, Lausanne, Switzerland},
	author = {Gu, C.},
	year = {1995},
}

@inproceedings{pinel_restauration_1989,
	title = {La restauration des films},
	booktitle = {Histoire du cinéma: nouvelles approches ({Colloque} de {Cerisy})},
	publisher = {Publications de la Sorbonne},
	author = {Pinel, V.},
	editor = {Aumont, J. and Gaudreault, A. and Marie, M.},
	month = aug,
	year = {1989},
}

@article{falc_ao_ultra-fast_2000,
	title = {An ultra-fast user-steered image segmentation paradigm: live wire on the fly},
	volume = {19},
	number = {1},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Falc{\textbackslash} ao, Alexandre X and Udupa, Jayaram K and Miyazawa, Flávio K},
	month = jan,
	year = {2000},
	pages = {55--62},
}

@inproceedings{vincent_grayscale_1993,
	address = {Barcelona, Spain},
	title = {Grayscale area openings and closings, their efficient implementation and applications},
	booktitle = {Mathematical {Morphology} and its applications to signal processing ({Proceedings} {ISMM}'93)},
	publisher = {UPC Publications Office},
	author = {Vincent, Luc},
	editor = {Serra, Jean and Salembier, Philippe},
	month = may,
	year = {1993},
	pages = {22--27},
}

@inproceedings{besserer_optical_2008,
	address = {Bern, Switzerland},
	title = {Optical soundtrack restoration: the image processing approach},
	booktitle = {Archiving 2008},
	author = {Besserer, Bernard and Hassaïne, Abdelâali and Decenciére, Etienne},
	month = jun,
	year = {2008},
}

@inproceedings{velasco-forero_mathematical_2021,
	title = {Mathematical morphology meets {Deep} {Learning}},
	booktitle = {13th {European} {Congress} for {Stereology} and {Image} {Analysis} ({ECSIA})},
	author = {Velasco-Forero, Santiago and Blusseau, Samy and Sangalli, Mateus},
	year = {2021},
	file = {Full Text:/home/edecenciere/Zotero/storage/RQ7Q33D3/Velasco-Forero et al. - 2021 - Mathematical morphology meets Deep Learning.pdf:application/pdf},
}

@inproceedings{armstrong_restoring_1998,
	address = {Glasgow, UK},
	title = {Restoring video images taken from scratched 2-inch tape},
	booktitle = {Noblesse workshop on non-linear model based image analysis},
	publisher = {Springer},
	author = {Armstrong, S. and Kokaram, A. C and Rayner, P. J.W},
	editor = {Marshall, S. and Harvey, N. and Shah, D.},
	month = jul,
	year = {1998},
}

@incollection{huang_image_1981,
	title = {Image sequence enhancement},
	booktitle = {Image sequence analysis},
	publisher = {Springer-Verlag},
	author = {Huang, T. S and Hsu, Y. P},
	editor = {Huang, T.S.},
	year = {1981},
	pages = {289--309},
}

@phdthesis{jeulin_morphologie_1979,
	title = {Morphologie mathématique et propriétés physiques des agglomérés de minerai de fer et de coke métallurgique},
	school = {Ecole des Mines de Paris, Paris},
	author = {Jeulin, Dominique},
	year = {1979},
}

@article{salembier_hierarchical_1994,
	title = {Hierarchical morphological segmentation for image sequence coding},
	volume = {3},
	number = {5},
	journal = {IEEE Transactions on Image Processing},
	author = {Salembier, Philippe and Pardàs, M.},
	month = sep,
	year = {1994},
	pages = {639--651},
}

@article{decenciere_application_1997,
	title = {Application of the morphological geodesic reconstruction to image sequence analysis},
	volume = {144},
	number = {6},
	journal = {IEE Proceedings: vision, image and signal processing},
	author = {Decencière, Etienne and Marshall, Stephen and Serra, Jean},
	month = dec,
	year = {1997},
}

@inproceedings{godsill_restoration_1997,
	address = {Leeds, UK},
	title = {Restoration of image sequences using a causal spatio-temporal model},
	booktitle = {Proceedings of the 17th {Leeds} annual statistics research workshop ({The} art and science of {Bayesian} image analysis)},
	author = {Godsill, S. and Kokaram, A. C},
	month = jul,
	year = {1997},
}

@inproceedings{audigier_watershed_2007,
	address = {Rio de Janeiro, Brazil},
	title = {Watershed by image foresting transform, tie-zone, and theoretical relationships with other watershed definitions},
	booktitle = {Mathematical {Morphology} and its {Applications} to {Signal} and {Image} {Processing} ({Proc}. {ISMM}'07)},
	author = {Audigier, R. and Lotufo, R. A},
	year = {2007},
	pages = {277--288},
}

@book{bilodeau_space_2005,
	title = {Space, structure, and randomness},
	publisher = {Springer},
	editor = {Bilodeau, Michel and Meyer, Fernand and Schmitt, Michel},
	year = {2005},
}

@article{decenciere_morphological_2001,
	title = {Morphological decomposition of the surface of an internal combustion engine cylinder in view of characterizing wear},
	volume = {249},
	journal = {Wear},
	author = {Decencière, Etienne and Jeulin, Dominique},
	year = {2001},
	pages = {482--488},
}

@article{sannareddy_characterization_1998,
	title = {Characterization of surface texture generated by multi-process manufacture},
	volume = {38},
	number = {5-6},
	journal = {International Journal of Machine Tools and Manufacture},
	author = {Sannareddy, H. and Raja, J. and Chen, K.},
	year = {1998},
	pages = {529--536},
}

@book{haering_visual_2001,
	title = {Visual {Event} detection},
	publisher = {Kluwer Academic Publishers},
	author = {Haering, Niels and da Vitoria Lobo, Niels},
	year = {2001},
}

@inproceedings{friend_film/digital/film_1994,
	title = {Film/digital/film},
	booktitle = {{AMIA} {Conference}},
	author = {Friend, M.},
	month = oct,
	year = {1994},
}

@techreport{decenciere_contract_1999,
	type = {Technical report},
	title = {Contract {CT1008} between {ARMINES} and {KODAK} {INDUSTRIE}. {Final} report},
	number = {N-24/99/MM},
	institution = {Ecole des Mines de Paris, Paris},
	author = {Decencière, Etienne and Beucher, Serge},
	month = may,
	year = {1999},
}

@article{konrad_bayesian_1992,
	title = {Bayesian estimation of motion vector fields},
	volume = {14},
	number = {9},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Konrad, J. and Dubois, E.},
	year = {1992},
	pages = {910--927},
}

@article{horn_determining_1981,
	title = {Determining optical flow},
	volume = {17},
	journal = {Artificial Intelligence},
	author = {Horn, B. K.P and Schunck, B. G},
	year = {1981},
	pages = {185--203},
}

@inproceedings{laveau_structuring_2005,
	address = {Paris, France},
	title = {Structuring {Elements} following the {Optical} {Flow}},
	booktitle = {Mathematical morphology: 40 years on ({Proceedings} of {ISMM}'2005)},
	author = {Laveau, N. and Bernard, C.},
	editor = {Ronse, C. and Najman, L. and Decencière, Etienne},
	month = apr,
	year = {2005},
	pages = {43--52},
}

@inproceedings{godsill_joint_1996,
	address = {Trieste, Italy},
	title = {Joint interpolation, motion and parameter estimation for image sequences with missing data},
	booktitle = {Signal {Processing} {VIII}: {Theories} and {Application} (proceedings of {EUSIPCO}-96)},
	author = {Godsill, S. J and Kokaram, A. C},
	month = sep,
	year = {1996},
}

@article{ghanbari_motion_1995,
	title = {Motion compensation for very low bit-rate video},
	volume = {7},
	number = {4-6},
	journal = {Signal Processing : Image Communication},
	author = {Ghanbari, M. and de Faria, S. and Goh, I. N and Tan, K. T},
	month = nov,
	year = {1995},
	pages = {567--580},
}

@techreport{bouchard_texture_1995,
	type = {Race {R2053} {Deliverable}},
	title = {From {Texture} to {Feature}},
	number = {R2053/UPC/GPS/DS/R/014/b1},
	institution = {Morpheco Consortium},
	author = {Bouchard, L. and Decencière, Etienne and Salembier, Philippe},
	month = nov,
	year = {1995},
}

@book{marr_vision:_1982,
	title = {Vision: a computational investigation into the human representation and processing of visual information},
	publisher = {W. H. Freeman, San Francisco},
	author = {Marr, David},
	year = {1982},
	keywords = {artificial intelligence, vision},
}

@article{gilge_coding_1989,
	title = {Coding of arbitrarily shaped image segments based on a generalized orthogonal transform},
	volume = {1},
	number = {2},
	journal = {Signal Processing : Image Communication},
	author = {Gilge, M. and Engelhardt, T. and Mehlan, R.},
	month = oct,
	year = {1989},
	pages = {153--180},
}

@article{montanvert_hierarchical_1991,
	title = {Hierarchical image analysis using irregular tessellations},
	volume = {13},
	number = {4},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Montanvert, A. and Meer, P. and Rosenfeld, A.},
	month = apr,
	year = {1991},
	pages = {307--316},
}

@techreport{casas_feature-based_1996,
	type = {Race {R2053} {Deliverable}},
	title = {Feature-based coding algorithm},
	number = {R2053/UPC/GPS/DS/R/016/b1},
	institution = {Morpheco Consortium},
	author = {Casas, J. R and Decencière, Etienne and Salembier, Philippe},
	month = jan,
	year = {1996},
}

@article{kweon_extracting_1994,
	title = {Extracting topographic terrain features from elevation maps},
	volume = {59},
	number = {2},
	journal = {Computer Vision, Graphics, and Image Processing: Image Understanding},
	author = {Kweon, I. S and Kanade, T.},
	year = {1994},
	pages = {171--182},
}

@inproceedings{van_roosmalen_fast_1999,
	address = {Phoenix, Arizona, United States of America},
	title = {Fast high quality interpolation of missing data in image sequences using a controlled pasting scheme},
	booktitle = {{IEEE} {International} {Conference} on {Acoustics}, {Speech} \& {Signal} {Processing}, {ICASSP}'99},
	author = {van Roosmalen, P. M.B and Kokaram, A. C and Biemond, J.},
	month = mar,
	year = {1999},
	pages = {3105--3108},
}

@article{beaulieu_hierarchy_1989,
	title = {Hierarchy in picture segmentation : a stepwise optimization approach.},
	volume = {11},
	number = {2},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Beaulieu, J. -M and Goldberg, M.},
	month = feb,
	year = {1989},
}

@article{kokaram_interpolation_1995,
	title = {Interpolation of missing data in image sequences},
	volume = {4},
	number = {11},
	journal = {IEEE Transactions on Image Processing},
	author = {Kokaram, A. C and Morris, R. D and Fitzgerald, W. J and Rayner, P. J. W.},
	year = {1995},
	pages = {1508--1519},
}

@article{haralick_image_1985,
	title = {Image {Segmentation} {Techniques}},
	volume = {29},
	number = {1},
	journal = {Computer Vision, Graphics, and Image Processing},
	author = {Haralick, R.M. and Shapiro, L.G.},
	month = jan,
	year = {1985},
	pages = {100--132},
}

@incollection{serra_anamorphoses_1993,
	title = {Anamorphoses and function lattices (multivalued morphology)},
	booktitle = {Mathematical {Morphology} in {Image} {Processing}},
	author = {Serra, Jean},
	editor = {Dougherty, E. R},
	year = {1993},
	pages = {483--523},
}

@inproceedings{stawiaski_computing_2007,
	address = {Brazil},
	title = {Computing {Approximate} {Geodesics} and {Minimal} {Surfaces} using {Watershed} and {Graph}-{Cuts}},
	booktitle = {International {Symposium} on {Mathematical} {Morphology} ({ISMM}'2007)},
	author = {Stawiaski, Jean and Decencière, Etienne and Bidault, Francois},
	year = {2007},
}

@article{vincent_graphs_1989,
	title = {Graphs and mathematical morphology},
	volume = {16},
	number = {4},
	journal = {Signal Processing},
	author = {Vincent, Luc},
	month = apr,
	year = {1989},
	pages = {365--388},
}

@inproceedings{seto_selective_2000,
	title = {Selective sharpness enhancement of heavily-corrupted old film sequences},
	booktitle = {Proc. of the 2000 {International} {Conference} on {Image} {Processing} ({ICIP}-2000)},
	author = {Seto, T. and Ohuchi, T. and Komatsu, T. and Saito, T.},
	month = sep,
	year = {2000},
}

@article{sternberg_grayscale_1986,
	title = {Grayscale morphology},
	volume = {35},
	journal = {Computer Vision, Graphics, and Image Processing},
	author = {Sternberg, S. R},
	year = {1986},
	pages = {333--355},
}

@inproceedings{stawiaski_combining_2007,
	address = {Brisbane, Australia},
	title = {Combining {Morphological} and {Graph} {Based} {Methods} for {Multi}-{Label} {Segmentation}},
	booktitle = {Interaction in medical image analysis and visualization ({MICCAI} workshop)},
	author = {Stawiaski, Jean and Sangild Sorensen, Thomas and Bidault, Francois and Decencière, Etienne},
	year = {2007},
}

@article{nieweglowski_temporal_1995,
	title = {Temporal image sequence prediction using motion field interpolation},
	volume = {7},
	number = {4-6},
	journal = {Signal Processing : Image Communication},
	author = {Nieweglowski, J. and Haavisto, P.},
	month = nov,
	year = {1995},
	pages = {333--353},
}

@inproceedings{salembier_multiscale_1992,
	address = {Boston, USA},
	title = {Multiscale image segmentation},
	volume = {1818},
	booktitle = {Proc. {SPIE}: {Visual} communications and image processing},
	author = {Salembier, Philippe and Serra, Jean},
	month = nov,
	year = {1992},
	pages = {620--631},
}

@inproceedings{malburg_characterization_1993,
	title = {Characterization of surface texture generated by plateau honing process},
	volume = {42},
	booktitle = {Annals of the {CIRP}},
	author = {Malburg, M. C and Raja, J. and Whitehouse, D. J},
	year = {1993},
	pages = {637--639},
}

@article{kong_theory_1985,
	title = {A theory of binary digital pictures},
	volume = {32},
	journal = {Computer Vision, Graphics, and Image Processing},
	author = {Kong, T. Y and Roscoe, A. W},
	year = {1985},
	pages = {221--243},
}

@techreport{soille_geodesic_1994,
	title = {Geodesic transformations in mathematical morphology},
	number = {N-24/94/MM},
	institution = {Centre de Morphologie Mathématique, Ecole des Mines de Paris},
	author = {Soille, Pierre},
	month = jan,
	year = {1994},
}

@article{monteil_reduction_1998,
	title = {Réduction du frottement au contact segment piston chemise : contribution à l'amélioration du rendement des moteurs},
	volume = {719},
	journal = {Revue de la Société des Ingénieurs},
	author = {Monteil, G. and Lebeaud, C.},
	year = {1998},
}

@book{despas_restauration_1997,
	title = {La restauration numérique des films cinématographiques},
	publisher = {Commission Supérieure Technique de l'Image et du Son (CST), Paris},
	author = {Despas, B. and Helt, F.},
	year = {1997},
}

@article{yatziv_fast_2006,
	title = {Fast image and video colorization using chrominance blending},
	volume = {15},
	number = {5},
	journal = {IEEE Transactions on Image Processing},
	author = {Yatziv, Liron and Sapiro, Guillermo},
	month = may,
	year = {2006},
	pages = {1120--1129},
}

@phdthesis{zanoguera_segmentation_2001,
	title = {Segmentation interactive d'images fixes et séquences vidéo basée sur des hiérarchies de partitions},
	school = {Ecole des Mines de Paris, Paris},
	author = {Zanoguera, Francisca},
	year = {2001},
}

@inproceedings{boomgaard_quadratic_1996,
	address = {Atlanta (GA), USA},
	title = {Quadratic structuring functions in mathematical morphology},
	booktitle = {Mathematical {Morphology} and its applications to signal processing ({Proceedings} {ISMM}'96)},
	publisher = {Kluwer Academic Publishers},
	author = {Boomgaard, R. v. d and Makram-Ebeid, S. and Schavemaker, J.},
	editor = {Maragos, P. and Schafer, R. W and Butt, M. A},
	month = may,
	year = {1996},
	pages = {147--154},
}

@phdthesis{caciu_analyse_2006,
	title = {Analyse et optimisation des surfaces des chemises de moteurs thermiques},
	school = {Ecole des Mines de Paris, Paris},
	author = {Caciu, Costin A},
	month = may,
	year = {2006},
}

@inproceedings{kalra_new_1997,
	address = {Munich, Germany},
	title = {A new auto-regressive ({AR}) model-based algorithm for motion picture restoration},
	booktitle = {Proceedings of {ICASSP}'97},
	author = {Kalra, S. and Chong, M. N and Krishan, D.},
	month = apr,
	year = {1997},
}

@inproceedings{kokaram_joint_1997-1,
	address = {Santa Barbara, California},
	title = {Joint {Detection}, {Interpolation}, {Motion} and {Parameter} {Estimation} for {Image} {Sequences} with {Missing} {Data}},
	booktitle = {{EEE} {International} {Conference} on {Image} {Processing}},
	author = {Kokaram, A. C and Godsill, S.},
	month = oct,
	year = {1997},
}

@techreport{decenciere_echantillonnage_1995,
	type = {Technical report},
	title = {Echantillonnage morphologique et réduction d'images},
	number = {N-05/95/MM},
	institution = {Ecole des Mines de Paris, Paris},
	author = {Decencière, Etienne},
	month = mar,
	year = {1995},
}

@inproceedings{van_roosmalen_improved_1998,
	address = {Leuven, Belgium},
	title = {Improved blotch detection by postprocessing},
	booktitle = {Proceedings of {IEEE} {Benelux} {Signal} {Processing} {Chapter}},
	author = {van Roosmalen, P. M.B},
	month = mar,
	year = {1998},
}

@phdthesis{kokaram_motion_1993,
	title = {Motion picture restoration},
	school = {Cambridge University},
	author = {Kokaram, A. C},
	month = may,
	year = {1993},
}

@inproceedings{boykov_markov_1998,
	title = {Markov random fields with efficient approximations},
	booktitle = {{IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Boykov, Y. and Veksler, O. and Zabih, R.},
	year = {1998},
}

@inproceedings{chenot_restoration_1998,
	address = {Amsterdam, The Netherlands},
	title = {Restoration of archived television programmes for digital broadcasting},
	booktitle = {{IBC}'98 {IEE} {Conference}},
	author = {Chenot, J. H and Drewery, J. O and Lyon, D.},
	month = sep,
	year = {1998},
	pages = {26--31},
}

@article{simonyan_very_2014,
	title = {Very deep convolutional networks for large-scale image recognition},
	url = {http://arxiv.org/abs/1409.1556},
	urldate = {2017-01-09},
	journal = {arXiv preprint arXiv:1409.1556},
	author = {Simonyan, Karen and Zisserman, Andrew},
	year = {2014},
	file = {[PDF] arxiv.org:/home/edecenciere/Zotero/storage/DIXNC3WH/Simonyan et Zisserman - 2014 - Very deep convolutional networks for large-scale i.pdf:application/pdf;Snapshot:/home/edecenciere/Zotero/storage/9GFJC2W9/1409.html:text/html},
}

@inproceedings{ciresan_mitosis_2013,
	title = {Mitosis {Detection} in {Breast} {Cancer} {Histology} {Images} with {Deep} {Neural} {Networks}},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-40763-5_51},
	doi = {10.1007/978-3-642-40763-5_51},
	abstract = {We use deep max-pooling convolutional neural networks to detect mitosis in breast histology images. The networks are trained to classify each pixel in the images, using as context a patch centered on the pixel. Simple postprocessing is then applied to the network output. Our approach won the ICPR 2012 mitosis detection competition, outperforming other contestants by a significant margin.},
	language = {en},
	urldate = {2017-01-06},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2013},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Cireşan, Dan C. and Giusti, Alessandro and Gambardella, Luca M. and Schmidhuber, Jürgen},
	month = sep,
	year = {2013},
	pages = {411--418},
}

@article{russakovsky_imagenet_2015-1,
	title = {{ImageNet} {Large} {Scale} {Visual} {Recognition} {Challenge}},
	volume = {115},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/article/10.1007/s11263-015-0816-y},
	doi = {10.1007/s11263-015-0816-y},
	abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5 years of the challenge, and propose future directions and improvements.},
	language = {en},
	number = {3},
	urldate = {2017-01-04},
	journal = {International Journal of Computer Vision},
	author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
	month = dec,
	year = {2015},
	pages = {211--252},
	file = {Full Text PDF:/home/edecenciere/Zotero/storage/9VTZAS4P/Russakovsky et al. - 2015 - ImageNet Large Scale Visual Recognition Challenge.pdf:application/pdf;Snapshot:/home/edecenciere/Zotero/storage/257S63FB/s11263-015-0816-y.html:text/html},
}

@article{springenberg_striving_2014,
	title = {Striving for {Simplicity}: {The} {All} {Convolutional} {Net}},
	shorttitle = {Striving for {Simplicity}},
	url = {http://arxiv.org/abs/1412.6806},
	abstract = {Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding -- and building on other recent work for finding simple network structures -- we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the "deconvolution approach" for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches.},
	urldate = {2017-01-04},
	journal = {arXiv:1412.6806 [cs]},
	author = {Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.6806},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing, Computer Science - Learning},
	file = {arXiv\:1412.6806 PDF:/home/edecenciere/Zotero/storage/VH4DBCBX/Springenberg et al. - 2014 - Striving for Simplicity The All Convolutional Net.pdf:application/pdf;arXiv.org Snapshot:/home/edecenciere/Zotero/storage/55TPIAX6/1412.html:text/html},
}

@inproceedings{ranzato_unsupervised_2007,
	title = {Unsupervised {Learning} of {Invariant} {Feature} {Hierarchies} with {Applications} to {Object} {Recognition}},
	doi = {10.1109/CVPR.2007.383157},
	abstract = {We present an unsupervised method for learning a hierarchy of sparse feature detectors that are invariant to small shifts and distortions. The resulting feature extractor consists of multiple convolution filters, followed by a feature-pooling layer that computes the max of each filter output within adjacent windows, and a point-wise sigmoid non-linearity. A second level of larger and more invariant features is obtained by training the same algorithm on patches of features from the first level. Training a supervised classifier on these features yields 0.64\% error on MNIST, and 54\% average recognition rate on Caltech 101 with 30 training samples per category. While the resulting architecture is similar to convolutional networks, the layer-wise unsupervised training procedure alleviates the over-parameterization problems that plague purely supervised learning procedures, and yields good performance with very few labeled training samples.},
	booktitle = {2007 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Ranzato, M. and Huang, F. J. and Boureau, Y. L. and LeCun, Y.},
	month = jun,
	year = {2007},
	keywords = {Detectors, object detection, Computer architecture, computer vision, Feature extraction, unsupervised learning, object recognition, Supervised learning, convolution, feature extractor, feature-pooling layer, Gabor filters, invariant feature hierarchy, multiple convolution filters},
	pages = {1--8},
	file = {IEEE Xplore Full Text PDF:/home/edecenciere/Zotero/storage/P7E93BIJ/Ranzato et al. - 2007 - Unsupervised Learning of Invariant Feature Hierarc.pdf:application/pdf;IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/6D6ZH387/4270182.html:text/html},
}

@article{lecun_backpropagation_1989,
	title = {Backpropagation {Applied} to {Handwritten} {Zip} {Code} {Recognition}},
	volume = {1},
	issn = {0899-7667},
	url = {http://www.mitpressjournals.org/doi/10.1162/neco.1989.1.4.541},
	doi = {10.1162/neco.1989.1.4.541},
	abstract = {The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.},
	number = {4},
	urldate = {2017-01-04},
	journal = {Neural Computation},
	author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
	month = dec,
	year = {1989},
	pages = {541--551},
}

@article{fukushima_neocognitron:_1980,
	title = {Neocognitron: {A} self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position},
	volume = {36},
	issn = {0340-1200, 1432-0770},
	shorttitle = {Neocognitron},
	url = {http://link.springer.com/article/10.1007/BF00344251},
	doi = {10.1007/BF00344251},
	abstract = {A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by “learning without a teacher”, and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname “neocognitron”. After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consits of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of “S-cells”, which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of “C-cells” similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any “teacher” during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cell of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern.},
	language = {en},
	number = {4},
	urldate = {2017-01-04},
	journal = {Biological Cybernetics},
	author = {Fukushima, Kunihiko},
	month = apr,
	year = {1980},
	pages = {193--202},
}

@inproceedings{ciresan_committee_2011,
	title = {A committee of neural networks for traffic sign classification},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6033458},
	urldate = {2017-01-03},
	booktitle = {Neural {Networks} ({IJCNN}), {The} 2011 {International} {Joint} {Conference} on},
	publisher = {IEEE},
	author = {Cireşan, Dan and Meier, Ueli and Masci, Jonathan and Schmidhuber, Jürgen},
	year = {2011},
	pages = {1918--1921},
}

@article{huertas-company_catalog_2015,
	title = {A {Catalog} of {Visual}-like {Morphologies} in the 5 {CANDELS} {Fields} {Using} {Deep} {Learning}},
	volume = {221},
	issn = {0067-0049},
	url = {http://stacks.iop.org/0067-0049/221/i=1/a=8},
	doi = {10.1088/0067-0049/221/1/8},
	abstract = {We present a catalog of visual-like H-band morphologies of ∼50.000 galaxies ( H f 160 w {\textless} 24.5) in the 5 CANDELS fields (GOODS-N, GOODS-S, UDS, EGS, and COSMOS). Morphologies are estimated using Convolutional Neural Networks (ConvNets). The median redshift of the sample is \#\#IMG\#\# [http://ej.iop.org/images/0067-0049/221/1/8/apjs520039ieqn1.gif] \${\textbackslash}langle z{\textbackslash}rangle {\textbackslash}sim 1.25.\$ The algorithm is trained on GOODS-S, for which visual classifications are publicly available, and then applied to the other 4 fields. Following the CANDELS main morphology classification scheme, our model retrieves for each galaxy the probabilities of having a spheroid or a disk, presenting an irregularity, being compact or a point source, and being unclassifiable. ConvNets are able to predict the fractions of votes given to a galaxy image with zero bias and ∼10\% scatter. The fraction of mis-classifications is less than 1\%. Our classification scheme represents a major improvement with respect to Concentration-Asymmetry-Smoothness-based methods, which hit a 20\%–30\% contamination limit at high z . The catalog is released with the present paper via the Rainbow database ( http://rainbowx.fis.ucm.es/Rainbow\_navigator\_public/ [http://rainbowx.fis.ucm.es/Rainbow\_navigator\_public/] ).},
	language = {en},
	number = {1},
	urldate = {2016-12-01},
	journal = {The Astrophysical Journal Supplement Series},
	author = {Huertas-Company, M. and Gravet, R. and Cabrera-Vives, G. and Pérez-González, P. G. and Kartaltepe, J. S. and Barro, G. and {M. Bernardi} and Mei, S. and Shankar, F. and Dimauro, P. and Bell, E. F. and Kocevski, D. and Koo, D. C. and Faber, S. M. and Mcintosh, D. H.},
	year = {2015},
	pages = {8},
	file = {IOP Full Text PDF:/home/edecenciere/Zotero/storage/EMZ4ISRK/Huertas-Company et al. - 2015 - A Catalog of Visual-like Morphologies in the 5 CAN.pdf:application/pdf},
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	url = {http://www.nature.com/nature/journal/v521/n7553/abs/nature14539.html},
	number = {7553},
	urldate = {2016-11-29},
	journal = {Nature},
	author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	year = {2015},
	pages = {436--444},
	file = {[PDF] bioinfo.org.cn:/home/edecenciere/Zotero/storage/6T76ZMTC/LeCun et al. - 2015 - Deep learning.pdf:application/pdf;Snapshot:/home/edecenciere/Zotero/storage/6J8S9WER/nature14539.html:text/html},
}

@article{tancrede-bohin_non-invasive_2015,
	title = {Non-invasive short-term assessment of retinoids effects on human skin in vivo using multiphoton microscopy},
	volume = {29},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/jdv.12650/full},
	number = {4},
	urldate = {2016-11-29},
	journal = {Journal of the European Academy of Dermatology and Venereology},
	author = {Tancrède-Bohin, Emmanuelle and Baldeweck, Thérese and Decencière, Etienne and Brizion, Sébastien and Victorin, S. and Parent, N. and Faugere, J. and Souverain, L. and Bagot, M. and Pena, A.-M.},
	year = {2015},
	pages = {673--681},
	file = {Snapshot:/home/edecenciere/Zotero/storage/D3552A9G/full.html:text/html},
}

@article{turaga_convolutional_2009,
	title = {Convolutional {Networks} {Can} {Learn} to {Generate} {Affinity} {Graphs} for {Image} {Segmentation}},
	volume = {22},
	issn = {0899-7667},
	url = {http://dx.doi.org/10.1162/neco.2009.10-08-881},
	doi = {10.1162/neco.2009.10-08-881},
	abstract = {Many image segmentation algorithms first generate an affinity graph and then partition it. We present a machine learning approach to computing an affinity graph using a convolutional network (CN) trained using ground truth provided by human experts. The CN affinity graph can be paired with any standard partitioning algorithm and improves segmentation accuracy significantly compared to standard hand-designed affinity functions.},
	number = {2},
	urldate = {2016-11-29},
	journal = {Neural Computation},
	author = {Turaga, Srinivas C. and Murray, Joseph F. and Jain, Viren and Roth, Fabian and Helmstaedter, Moritz and Briggman, Kevin and Denk, Winfried and Seung, H. Sebastian},
	month = nov,
	year = {2009},
	pages = {511--538},
	file = {Neural Computation Snapshot:/home/edecenciere/Zotero/storage/43GW7HIX/neco.2009.html:text/html},
}

@article{li_fully_2016,
	title = {Fully {Convolutional} {Instance}-aware {Semantic} {Segmentation}},
	url = {http://arxiv.org/abs/1611.07709},
	abstract = {We present the first fully convolutional end-to-end solution for instance-aware semantic segmentation task. It inherits all the merits of FCNs for semantic segmentation and instance mask proposal. It performs instance mask prediction and classification jointly. The underlying convolutional representation is fully shared between the two sub-tasks, as well as between all regions of interest. The proposed network is highly integrated and achieves state-of-the-art performance in both accuracy and efficiency. It wins the COCO 2016 segmentation competition by a large margin. The code would be released at {\textbackslash}url\{https://github.com/daijifeng001/TA-FCN\}.},
	urldate = {2016-11-29},
	journal = {arXiv:1611.07709 [cs]},
	author = {Li, Yi and Qi, Haozhi and Dai, Jifeng and Ji, Xiangyang and Wei, Yichen},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.07709},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1611.07709 PDF:/home/edecenciere/Zotero/storage/EMPAUK9Z/Li et al. - 2016 - Fully Convolutional Instance-aware Semantic Segmen.pdf:application/pdf;arXiv.org Snapshot:/home/edecenciere/Zotero/storage/IH4NWAJC/1611.html:text/html},
}

@article{lin_microsoft_2014,
	title = {Microsoft {COCO}: {Common} {Objects} in {Context}},
	shorttitle = {Microsoft {COCO}},
	url = {http://arxiv.org/abs/1405.0312},
	abstract = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.},
	urldate = {2016-11-29},
	journal = {arXiv:1405.0312 [cs]},
	author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Dollár, Piotr},
	month = may,
	year = {2014},
	note = {arXiv: 1405.0312},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{ning_toward_2005,
	title = {Toward automatic phenotyping of developing embryos from videos},
	volume = {14},
	issn = {1057-7149},
	doi = {10.1109/TIP.2005.852470},
	abstract = {We describe a trainable system for analyzing videos of developing C. elegans embryos. The system automatically detects, segments, and locates cells and nuclei in microscopic images. The system was designed as the central component of a fully automated phenotyping system. The system contains three modules 1) a convolutional network trained to classify each pixel into five categories: cell wall, cytoplasm, nucleus membrane, nucleus, outside medium; 2) an energy-based model, which cleans up the output of the convolutional network by learning local consistency constraints that must be satisfied by label images; 3) a set of elastic models of the embryo at various stages of development that are matched to the label images.},
	number = {9},
	journal = {IEEE Transactions on Image Processing},
	author = {Ning, Feng and Delhomme, D. and LeCun, Y. and Piano, F. and Bottou, L. and Barbano, P. E.},
	month = sep,
	year = {2005},
	keywords = {Image segmentation, Algorithms, Biological system modeling, Animals, Artificial Intelligence, automatic phenotyping, Bioinformatics, biological techniques, Caenorhabditis elegans, cellular biophysics, convolutional network, cytoplasm, Embryo, Embryo, Nonmammalian, embryos, energy-based model, Fetal Development, genetics, Genomics, Image Enhancement, Image Interpretation, Computer-Assisted, microscopic images, Microscopy, Microscopy, Phase-Contrast, Microscopy, Video, Motion pictures, nonlinear filter, nucleus membrane, optical microscopy, Pattern Recognition, Automated, Performance analysis, Phenotype, Reproducibility of Results, Sensitivity and Specificity, Videos},
	pages = {1360--1371},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/ZEBAAHGI/1495508.html:text/html},
}

@article{farabet_learning_2013,
	title = {Learning {Hierarchical} {Features} for {Scene} {Labeling}},
	volume = {35},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2012.231},
	abstract = {Scene labeling consists of labeling each pixel in an image with the category of the object it belongs to. We propose a method that uses a multiscale convolutional network trained from raw pixels to extract dense feature vectors that encode regions of multiple sizes centered on each pixel. The method alleviates the need for engineered features, and produces a powerful representation that captures texture, shape, and contextual information. We report results using multiple postprocessing methods to produce the final labeling. Among those, we propose a technique to automatically retrieve, from a pool of segmentation components, an optimal set of components that best explain the scene; these components are arbitrary, for example, they can be taken from a segmentation tree or from any family of oversegmentations. The system yields record accuracies on the SIFT Flow dataset (33 classes) and the Barcelona dataset (170 classes) and near-record accuracy on Stanford background dataset (eight classes), while being an order of magnitude faster than competing approaches, producing a 320×240 image labeling in less than a second, including feature extraction.},
	number = {8},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Farabet, C. and Couprie, C. and Najman, L. and LeCun, Y.},
	month = aug,
	year = {2013},
	keywords = {deep learning, Image segmentation, image classification, Feature extraction, Labeling, Image edge detection, Context, Accuracy, Barcelona dataset, contextual information capturing, Convolutional networks, dense feature vector extraction, hierarchical feature learning, image labeling, image pixel labeling, image texture, multiple size region encoding, multiscale convolutional network, near-record accuracy, object category, scene labeling, scene parsing, segmentation components, segmentation tree, shape information capturing, shape recognition, SIFT flow dataset, Stanford background dataset, texture information capturing, Transforms, trees (mathematics), Vectors},
	pages = {1915--1929},
}

@book{bazin_skin_2015,
	title = {Skin aging atlas},
	volume = {Volume 4. Indian type},
	publisher = {Med'com},
	author = {Bazin, Roland and Flament, Frédéric and Rubert, Virginie},
	year = {2015},
}

@book{bazin_skin_2012,
	title = {Skin aging atlas},
	volume = {Volume 3. Afro-american type},
	publisher = {Med'com},
	author = {Bazin, Roland and Flament, Frédéric and Giron, F.},
	year = {2012},
}

@book{bazin_skin_2010,
	title = {Skin aging atlas},
	volume = {Volume 2. Asian type},
	publisher = {Med'com},
	author = {Bazin, Roland and Flament, Frédéric},
	year = {2010},
}

@book{bazin_skin_2007,
	title = {Skin aging atlas},
	volume = {Volume 1. Caucasian type},
	publisher = {Med'com},
	author = {Bazin, Roland and Doublet, Eric},
	year = {2007},
}

@article{kreshuk_automated_2014,
	title = {Automated {Detection} of {Synapses} in {Serial} {Section} {Transmission} {Electron} {Microscopy} {Image} {Stacks}},
	volume = {9},
	issn = {1932-6203},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0087351},
	doi = {10.1371/journal.pone.0087351},
	abstract = {We describe a method for fully automated detection of chemical synapses in serial electron microscopy images with highly anisotropic axial and lateral resolution, such as images taken on transmission electron microscopes. Our pipeline starts from classification of the pixels based on 3D pixel features, which is followed by segmentation with an Ising model MRF and another classification step, based on object-level features. Classifiers are learned on sparse user labels; a fully annotated data subvolume is not required for training. The algorithm was validated on a set of 238 synapses in 20 serial 7197×7351 pixel images (4.5×4.5×45 nm resolution) of mouse visual cortex, manually labeled by three independent human annotators and additionally re-verified by an expert neuroscientist. The error rate of the algorithm (12\% false negative, 7\% false positive detections) is better than state-of-the-art, even though, unlike the state-of-the-art method, our algorithm does not require a prior segmentation of the image volume into cells. The software is based on the ilastik learning and segmentation toolkit and the vigra image processing library and is freely available on our website, along with the test data and gold standard annotations (http://www.ilastik.org/synapse-detection/sstem).},
	number = {2},
	urldate = {2016-11-24},
	journal = {PLOS ONE},
	author = {Kreshuk, Anna and Koethe, Ullrich and Pax, Elizabeth and Bock, Davi D. and Hamprecht, Fred A.},
	month = feb,
	year = {2014},
	keywords = {Algorithms, Imaging techniques, Image Processing, Anisotropy, Cell membranes, Connectomics, Neural pathways, Synapses},
	pages = {e87351},
	file = {Snapshot:/home/edecenciere/Zotero/storage/2C33J9GK/article.html:text/html},
}

@inproceedings{le_cun_theoretical_1988,
	title = {A theoretical framework for back-propagation},
	volume = {1},
	url = {https://www.researchgate.net/profile/Yann_Lecun/publication/2360531_A_Theoretical_Framework_for_Back-Propagation/links/0deec519dfa297eac1000000.pdf},
	urldate = {2016-11-24},
	booktitle = {The {Connectionist} {Models} {Summer} {School}},
	author = {Le Cun, Yann and Touresky, D. and Hinton, G. and Sejnowski, T.},
	year = {1988},
	pages = {21--28},
}

@incollection{werbos_applications_1982-1,
	title = {Applications of advances in nonlinear sensitivity analysis},
	url = {http://link.springer.com/chapter/10.1007/BFb0006203},
	abstract = {The following paper summarizes the major properties and applications of a collection of algorithms involving differentiation and optimization at minimum cost. The areas of application include the sensitivity analysis of models, new work in statistical or econometric estimation, optimization, artificial intelligence and neuron modelling. The details, references and derivations can be obtained by requesting „Sensitivity Analysis Methods for Nonlinear Systems“ from Forecast Analysis and Evaluation Team, Quality Assurance, OSS/EIA, Room 7413, Department of Energy, Washington, DC 20461.},
	language = {en},
	urldate = {2016-11-24},
	booktitle = {{SpringerLink}},
	publisher = {Springer Berlin Heidelberg},
	author = {Werbos, Paul J.},
	year = {1982},
	doi = {10.1007/BFb0006203},
	pages = {762--770},
	file = {Snapshot:/home/edecenciere/Zotero/storage/J2ADNPS5/BFb0006203.html:text/html},
}

@article{fukushima_neural_1979,
	title = {Neural {Network} {Model} for a {Mechanism} of {Pattern} {Recognition} {Unaffected} by {Shift} in {Position}- {Neocognitron}},
	volume = {62},
	number = {10},
	journal = {ELECTRON. \& COMMUN. JAPAN},
	author = {Fukushima, Kunihiko},
	year = {1979},
	pages = {11--18},
}

@article{schmidhuber_deep_2015,
	title = {Deep learning in neural networks: {An} overview},
	volume = {61},
	issn = {0893-6080},
	shorttitle = {Deep learning in neural networks},
	url = {http://www.sciencedirect.com/science/article/pii/S0893608014002135},
	doi = {10.1016/j.neunet.2014.09.003},
	abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \&amp; evolutionary computation, and indirect search for short programs encoding deep and large networks.},
	urldate = {2016-11-24},
	journal = {Neural Networks},
	author = {Schmidhuber, Jürgen},
	month = jan,
	year = {2015},
	keywords = {deep learning, unsupervised learning, Supervised learning, evolutionary computation, Reinforcement learning},
	pages = {85--117},
}

@article{havaei_brain_2017,
	title = {Brain tumor segmentation with {Deep} {Neural} {Networks}},
	volume = {35},
	issn = {1361-8415},
	url = {http://www.sciencedirect.com/science/article/pii/S1361841516300330},
	doi = {10.1016/j.media.2016.05.004},
	abstract = {In this paper, we present a fully automatic brain tumor segmentation method based on Deep Neural Networks (DNNs). The proposed networks are tailored to glioblastomas (both low and high grade) pictured in MR images. By their very nature, these tumors can appear anywhere in the brain and have almost any kind of shape, size, and contrast. These reasons motivate our exploration of a machine learning solution that exploits a flexible, high capacity DNN while being extremely efficient. Here, we give a description of different model choices that we’ve found to be necessary for obtaining competitive performance. We explore in particular different architectures based on Convolutional Neural Networks (CNN), i.e. DNNs specifically adapted to image data.

We present a novel CNN architecture which differs from those traditionally used in computer vision. Our CNN exploits both local features as well as more global contextual features simultaneously. Also, different from most traditional uses of CNNs, our networks use a final layer that is a convolutional implementation of a fully connected layer which allows a 40 fold speed up. We also describe a 2-phase training procedure that allows us to tackle difficulties related to the imbalance of tumor labels. Finally, we explore a cascade architecture in which the output of a basic CNN is treated as an additional source of information for a subsequent CNN. Results reported on the 2013 BRATS test data-set reveal that our architecture improves over the currently published state-of-the-art while being over 30 times faster.},
	urldate = {2016-11-24},
	journal = {Medical Image Analysis},
	author = {Havaei, Mohammad and Davy, Axel and Warde-Farley, David and Biard, Antoine and Courville, Aaron and Bengio, Yoshua and Pal, Chris and Jodoin, Pierre-Marc and Larochelle, Hugo},
	month = jan,
	year = {2017},
	keywords = {convolutional neural networks, Brain tumor segmentation, Cascaded convolutional neural networks, deep neural networks},
	pages = {18--31},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/IKASSIQX/S1361841516300330.html:text/html},
}

@article{cootes_trainable_1992,
	series = {{BMVC} 1991},
	title = {Trainable method of parametric shape description},
	volume = {10},
	issn = {0262-8856},
	url = {http://www.sciencedirect.com/science/article/pii/0262885692900444},
	doi = {10.1016/0262-8856(92)90044-4},
	abstract = {We have developed a trainable method of shape representation which can automatically capture the invariant properties of a class of shapes, and provide a compact parametric description of variability. We have applied the method to a family of flexible ribbons (worms), and to heart shapes in echocardiograms. We show that in both cases a natural parameterization of shape results.},
	number = {5},
	urldate = {2016-11-22},
	journal = {Image and Vision Computing},
	author = {Cootes, T. F. and Cooper, D. H. and Taylor, C. J. and Graham, J},
	month = jun,
	year = {1992},
	keywords = {deformable templates, flexible shape models},
	pages = {289--294},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/EAEZT85P/0262885692900444.html:text/html},
}

@article{brejl_object_2000,
	title = {Object localization and border detection criteria design in edge-based image segmentation: automated learning from examples},
	volume = {19},
	issn = {0278-0062},
	shorttitle = {Object localization and border detection criteria design in edge-based image segmentation},
	doi = {10.1109/42.887613},
	abstract = {This paper provides methodology for fully automated model-based image segmentation. All information necessary to perform image segmentation is automatically derived from a training set that is presented in a form of segmentation examples. The training set is used to construct two models representing the objects-shape model and border appearance model. A two-step approach to image segmentation is reported. In the first step, an approximate location of the object of interest is determined. In the second step, accurate border segmentation is performed. The shape-variant Hough transform method was developed that provides robust object localization automatically. It finds objects of arbitrary shape, rotation, or scaling and can handle object variability. The border appearance model was developed to automatically design cost functions that can be used in the segmentation criteria of edge-based segmentation methods. The authors' method was tested in five different segmentation tasks that included 489 objects to be segmented. The final segmentation was compared to manually defined borders with good results [rms errors in pixels: 1.2 (cerebellum), 1.1 (corpus callosum), 1.5 (vertebrae), 1.4 (epicardial), and 1.6 (endocardial) borders]. Two major problems of the state-of-the-art edge-based image segmentation algorithms were addressed: strong dependency on a close-to-target initialization, and necessity for manual redesign of segmentation criteria whenever new segmentation problem is encountered.},
	number = {10},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Brejl, M. and Sonka, M.},
	month = oct,
	year = {2000},
	keywords = {Image segmentation, Algorithms, object detection, Robustness, Image analysis, Humans, Artificial Intelligence, Image Enhancement, Image Processing, Computer-Assisted, medical image processing, Magnetic Resonance Imaging, Edge detection, Image edge detection, Hough transforms, Algorithm design and analysis, Active shape model, automated learning from examples, border appearance model, border detection criteria design, brain, cardiology, cerebellum, Cities and towns, Computer Simulation, corpus callosum, Cost function, Dynamic programming, edge-based image segmentation, endocardial, epicardial, Heart, knowledge representation, learning systems, medical diagnostic imaging, modelling, object localization, shape model, shape-variant Hough transform method, Spine, training set, two-step approach, vertebrae},
	pages = {973--985},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/XKE47USH/887613.html:text/html},
}

@article{kuntimad_perfect_1999,
	title = {Perfect image segmentation using pulse coupled neural networks},
	volume = {10},
	issn = {1045-9227},
	doi = {10.1109/72.761716},
	abstract = {This paper describes a method for segmenting digital images using pulse coupled neural networks (PCNN). The pulse coupled neuron (PCN) model used in PCNN is a modification of the cortical neuron model of Eckhorn et al. (1990). A single layered laterally connected PCNN is capable of perfectly segmenting digital images even when there is a considerable overlap in the intensity ranges of adjacent regions. Conditions for perfect image segmentation are derived. It is also shown that addition of an inhibition receptive field to the neuron model increases the possibility of perfect segmentation. The inhibition input reduces the overlap of intensity ranges of adjacent regions by effectively compressing the intensity range of each region},
	number = {3},
	journal = {IEEE Transactions on Neural Networks},
	author = {Kuntimad, G. and Ranganath, H. S.},
	month = may,
	year = {1999},
	keywords = {Image segmentation, Pixel, neural nets, Image Processing, adjacent regions, Artificial neural networks, Bridges, Brightness, cortical neuron model, Digital images, inhibition receptive field, intensity range overlap, Neural Networks, Neurons, perfect image segmentation, Personal communication networks, pulse coupled neural networks, single-layered laterally connected PCNN},
	pages = {591--598},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/BGTC2E78/761716.html:text/html},
}

@inproceedings{ren_learning_2003,
	title = {Learning a classification model for segmentation},
	doi = {10.1109/ICCV.2003.1238308},
	abstract = {We propose a two-class classification model for grouping. Human segmented natural images are used as positive examples. Negative examples of grouping are constructed by randomly matching human segmentations and images. In a preprocessing stage an image is over-segmented into super-pixels. We define a variety of features derived from the classical Gestalt cues, including contour, texture, brightness and good continuation. Information-theoretic analysis is applied to evaluate the power of these grouping cues. We train a linear classifier to combine these features. To demonstrate the power of the classification model, a simple algorithm is used to randomly search for good segmentations. Results are shown on a wide range of images.},
	booktitle = {Proceedings {Ninth} {IEEE} {International} {Conference} on {Computer} {Vision}},
	author = {Ren, X. and Malik, J.},
	month = oct,
	year = {2003},
	keywords = {Image segmentation, image classification, computer vision, Humans, Image databases, image matching, Computer Science, image texture, Brightness, classification model, Design optimization, Gestalt cues, grouping, human segmented natural image, image range, information analysis, information-theoretic analysis, linear classifier, Logistics, Partitioning algorithms},
	pages = {10--17 vol.1},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/J72CGKEG/1238308.html:text/html},
}

@article{lopez_evaluation_1999,
	title = {Evaluation of {Methods} for {Ridge} and {Valley} {Detection}},
	volume = {21},
	issn = {0162-8828},
	url = {http://dx.doi.org/10.1109/34.761263},
	doi = {10.1109/34.761263},
	abstract = {Ridges and valleys are useful geometric features for image analysis. Different characterizations have been proposed to formalize the intuitive notion of ridge/valley. In this paper, we review their principal characterizations and propose a new one. Subsequently, we evaluate these characterizations with respect to a list of desirable properties and their purpose in the context of representative image analysis tasks.},
	number = {4},
	urldate = {2016-11-21},
	journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
	author = {López, Antonio M. and Lumbreras, Felipe and Serrat, Joan and Villanueva, Juan J.},
	month = apr,
	year = {1999},
	keywords = {comparative analysis., Creases, drainage patterns, separatrices},
	pages = {327--335},
}

@article{haralick_ridges_1983,
	title = {Ridges and valleys on digital images},
	volume = {22},
	issn = {0734-189X},
	url = {http://www.sciencedirect.com/science/article/pii/0734189X83900944},
	doi = {10.1016/0734-189X(83)90094-4},
	abstract = {Ridges and valleys on digital images are found by looking for zero crossings of the first directional derivative taken in a direction which extremizes the second directional derivative. Computation of the required directional derivative is accomplished by fitting a two-variable cubic polynomial to each neighborhood of the image. Results are shown for a face image and an airphoto scene. It indicates that the technique has a good ability to find ridges and valleys.},
	number = {1},
	urldate = {2016-11-21},
	journal = {Computer Vision, Graphics, and Image Processing},
	author = {Haralick, Robert M},
	month = apr,
	year = {1983},
	pages = {28--38},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/XZB5GAD7/0734189X83900944.html:text/html},
}

@incollection{batool_modeling_nodate,
	title = {Modeling and {Detection} of {Wrinkles} in {Aging} {Human} {Faces} {Using} {Marked} {Point} {Processes}},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-33868-7_18},
	abstract = {In this paper we propose a new generative model for wrinkles on aging human faces using Marked Point Processes (MPP). Wrinkles are considered as stochastic spatial arrangements of sequences of line segments, and detected in an image by proper localization of line segments. The intensity gradients are used to detect more probable locations and a prior probability model is used to constrain properties of line segments. Wrinkles are localized by sampling MPP using the Reversible Jump Markov Chain Monte Carlo (RJMCMC) algorithm. We also present an evaluation setup to measure the performance of the proposed model. We present results on a variety of images obtained from the Internet to illustrate the performance of the proposed model.},
	language = {en},
	urldate = {2016-11-21},
	booktitle = {{SpringerLink}},
	publisher = {Springer Berlin Heidelberg},
	author = {Batool, Nazre and Chellappa, Rama},
	doi = {10.1007/978-3-642-33868-7_18},
	pages = {178--188},
	file = {Snapshot:/home/edecenciere/Zotero/storage/4GCPNZPD/978-3-642-33868-7_18.html:text/html},
}

@article{soille_efficient_1994,
	title = {An {Efficient} {Algorithm} for {Drainage} {Network} {Extraction} on {DEMs}},
	volume = {5},
	issn = {1047-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S1047320384710170},
	doi = {10.1006/jvci.1994.1017},
	abstract = {This paper presents a new and efficient algorithm for extracting drainage networks on digital elevation models (DEMs), The algorithm is based on the simulation of a flow of water on the topographic surface, and it requires three steps. First, all irrelevant minima within the DEM are removed to ensure the continuity of streamlines. Second, flow directions are assigned to all pixels, plateaus included. Third, the contributing drainage area of each pixel is determined. Drainage networks are then extracted by thresholding the image for contributing drainage areas above a user-defined value. First-in-first-out queues of pixels ensure a fast implementation of all steps. The algorithm is presented as pseudo c code.},
	number = {2},
	urldate = {2016-11-21},
	journal = {Journal of Visual Communication and Image Representation},
	author = {Soille, Pierre and Gratin, Christophe},
	month = jun,
	year = {1994},
	pages = {181--189},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/KR8333QJ/S1047320384710170.html:text/html},
}

@inproceedings{besl_method_1992,
	title = {Method for registration of 3-{D} shapes},
	volume = {1611},
	url = {http://dx.doi.org/10.1117/12.57955},
	doi = {10.1117/12.57955},
	abstract = {This paper describes a general purpose, representation independent method for the accurate and computationally efficient registration of 3-D shapes including free-form curves and surfaces. The method handles the full six-degrees of freedom and is based on the iterative closest point (ICP) algorithm, which requires only a procedure to find the closest point on a geometric entity to a given point. The ICP algorithm always converges monotonically to the nearest local minimum of a mean-square distance metric, and experience shows that the rate of convergence is rapid during the first few iterations. Therefore, given an adequate set of initial rotations and translations for a particular class of objects with a certain level of 'shape complexity', one can globally minimize the mean-square distance metric over all six degrees of freedom by testing each initial registration. For examples, a given 'model' shape and a sensed 'data' shape that represents a major portion of the model shape can be registered in minutes by testing one initial translation and a relatively small set of rotations to allow for the given level of model complexity. One important application of this method is to register sensed data from unfixtured rigid objects with an ideal geometric model prior to shape inspection. The described method is also useful for deciding fundamental issues such as the congruence (shape equivalence) of different geometric representations as well as for estimating the motion between point sets where the correspondences are not known. Experimental results show the capabilities of the registration algorithm on point sets, curves, and surfaces.},
	urldate = {2016-11-07},
	author = {Besl, Paul J. and McKay, Neil D.},
	year = {1992},
	pages = {586--606},
}

@article{chen_object_1992,
	series = {Range {Image} {Understanding}},
	title = {Object modelling by registration of multiple range images},
	volume = {10},
	issn = {0262-8856},
	url = {http://www.sciencedirect.com/science/article/pii/026288569290066C},
	doi = {10.1016/0262-8856(92)90066-C},
	abstract = {We study the problem of creating a complete model of a physical object. Although this may be possible using intensity images, we here use images which directly provide access to three dimensional information. The first problem that we need to solve is to find the transformation between the different views. Previous approaches either assume this transformation to be known (which is extremely difficult for a complete model), or compute it with feature matching (which is not accurate enough for integration). In this paper, we propose a new approach which works on range data directly and registers successive views with enough overlapping area to get an accurate transformation between views. This is performed by minimizing a functional which does not require point-to-point matches. We give the details of the registration method and modelling procedure and illustrate them on real range images of complex objects.},
	number = {3},
	urldate = {2016-11-07},
	journal = {Image and Vision Computing},
	author = {Chen, Yang and Medioni, Gérard},
	month = apr,
	year = {1992},
	keywords = {3D surface registration, object modelling, range image registration},
	pages = {145--155},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/JEUXGEII/026288569290066C.html:text/html},
}

@article{soille_recursive_1996,
	title = {Recursive implementation of erosions and dilations along discrete lines at arbitrary angles},
	volume = {18},
	issn = {0162-8828},
	doi = {10.1109/34.494646},
	abstract = {Van Herk (1992) has shown that the erosion/dilation operator with a linear structuring element of an arbitrary length can be implemented in only three min/max operations per pixel. In this paper, the algorithm is generalized to erosions and dilations along discrete lines at arbitrary angles. We also address the padding problem; so that the operation can be performed in place without copying the pixels to and from an intermediate buffer. Applications to image filtering and to radial decompositions of discs are presented},
	number = {5},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Soille, P. and Breen, E. J. and Jones, R.},
	month = may,
	year = {1996},
	keywords = {Mathematics, filtering theory, Edge detection, Image Processing, mathematical morphology, Morphology, Australia, discrete lines, Electronic mail, erosion/dilation operator, Filtering algorithms, Gray-scale, image filtering, Information science, line structuring, min/max operations, Minimax techniques, Morphological operations, periodic structuring, radial decompositions, Structural discs},
	pages = {562--567},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/2DTX6F6J/494646.html:text/html},
}

@inproceedings{hernandez_point_2009,
	title = {Point cloud segmentation towards urban ground modeling},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5137562},
	urldate = {2016-11-07},
	booktitle = {Joint {Urban} {Remote} {Sensing} {Event}},
	publisher = {IEEE},
	author = {Hernández, Jorge and Marcotegui, Beatriz},
	year = {2009},
	pages = {1--5},
	file = {Snapshot:/home/edecenciere/Zotero/storage/S83GTGZG/5137562.html:text/html},
}

@inproceedings{alghamdi_automatic_2016,
	address = {Athens},
	title = {Automatic {Optic} {Disc} {Abnormality} {Detection} in {Fundus} {Images}: {A} {Deep} {Learning} {Approach}},
	copyright = {attached},
	shorttitle = {Automatic {Optic} {Disc} {Abnormality} {Detection} in {Fundus} {Images}},
	url = {http://epubs.surrey.ac.uk/812324/},
	abstract = {Optic disc (OD) is a key structure in retinal images. It serves as an indicator to detect various diseases such as glaucoma and changes related to new vessel formation on the OD in diabetic retinopathy (DR) or retinal vein occlusion. OD is also essential to locate structures such as the macula and the main vascular arcade. Most existing methods for OD localization are rule-based, either exploiting the OD appearance proper- ties or the spatial relationship between the OD and the main vascular arcade. The detection of OD abnormalities has been performed through the detection of lesions such as hemorrhaeges or through measuring cup to disc ratio. Thus these methods result in complex and in exible im- age analysis algorithms limiting their applicability to large image sets obtained either in epidemiological studies or in screening for retinal or optic nerve diseases. In this paper, we propose an end-to-end supervised model for OD abnormality detection. The most informative features of the OD are learned directly from retinal images and are adapted to the dataset at hand. Our experimental results validated the effectiveness of this current approach and showed its potential application.},
	language = {en},
	urldate = {2016-10-13},
	booktitle = {Lecture {Notes} in {Computer} {Science}},
	author = {Alghamdi, H. S. and Tang, H. L. and Waheeb, S. A. and Peto, T.},
	year = {2016},
	file = {Snapshot:/home/edecenciere/Zotero/storage/KGN4E8FH/812324.html:text/html},
}

@article{bao_optimized_2012,
	series = {Special {Section}: {Dependable} {System} {Modelling} and {Analysis}},
	title = {An optimized discrete neural network in embedded systems for road recognition},
	volume = {25},
	issn = {0952-1976},
	url = {http://www.sciencedirect.com/science/article/pii/S0952197612000206},
	doi = {10.1016/j.engappai.2012.01.016},
	abstract = {A type of optimized neural networks with limited precision weights (LPWNN) is presented in this paper. Such neural networks, which require less memory for storing the weights and less expensive floating point units in order to perform the computations involved, are better suited for embedded systems implementation than the real weight ones. Based on analyzing the learning capability of LPWNN, Quantize Back-propagation Step-by-Step (QBPSS) algorithm is proposed for such neural networks to overcome the effects of limited precision. Methods of designing and training LPNN are represented, including the quantization of non-linear activation function and the selection of learning rate, network architecture and weights precision. The optimized LPWNN performance has been evaluated by comparing to conventional neural networks with double-precision floating-point weights on road recognition of image for intelligent vehicle in ARM 9 embedded systems, and the results show the optimized LPWNN has 7 times faster than the conventional ones.},
	number = {4},
	urldate = {2016-10-13},
	journal = {Engineering Applications of Artificial Intelligence},
	author = {Bao, Jian and Chen, Yu and Yu, Jinshou},
	month = jun,
	year = {2012},
	keywords = {Pattern recognition, Embedded systems, Limited precision weights, Neural network},
	pages = {775--782},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/6CHBRND3/S0952197612000206.html:text/html},
}

@incollection{yi_new_2008,
	series = {{IFIP} – {The} {International} {Federation} for {Information} {Processing}},
	title = {A {New} {Learning} {Algorithm} for {Neural} {Networks} with {Integer} {Weights} and {Quantized} {Non}-linear {Activation} {Functions}},
	copyright = {©2008 International Federation for Information Processing},
	isbn = {978-0-387-09694-0 978-0-387-09695-7},
	url = {http://link.springer.com/chapter/10.1007/978-0-387-09695-7_42},
	abstract = {The hardware implementation of neural networks is a fascinating area of research with for reaching applications. However, the real weights and non-linear activation function are not suited for hardware implementation. A new learning algorithm, which trains neural networks with integer weights and excludes derivatives from the training process, is presented in this paper. The performance of this procedure was evaluated by comparing to multi-threshold method and continuous discrete learning method on XOR and function approximation problems, and the simulation results show the new learning method outperforms the other two greatly in convergence and generalization.},
	language = {en},
	number = {276},
	urldate = {2016-10-13},
	booktitle = {Artificial {Intelligence} in {Theory} and {Practice} {II}},
	publisher = {Springer US},
	author = {Yi, Prof Yan and Hangping, Zhang and Bin, Zhou},
	editor = {Bramer, Max},
	month = sep,
	year = {2008},
	doi = {10.1007/978-0-387-09695-7_42},
	keywords = {Artificial Intelligence (incl. Robotics), History of Computing, Optics and Electrodynamics, Theory of Computation},
	pages = {427--431},
	file = {Snapshot:/home/edecenciere/Zotero/storage/5QFITUJ6/10.html:text/html},
}

@incollection{zilly_boosting_2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Boosting {Convolutional} {Filters} with {Entropy} {Sampling} for {Optic} {Cup} and {Disc} {Image} {Segmentation} from {Fundus} {Images}},
	copyright = {©2015 Springer International Publishing Switzerland},
	isbn = {978-3-319-24887-5 978-3-319-24888-2},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-24888-2_17},
	abstract = {We propose a novel convolutional neural network (CNN) based method for optic cup and disc segmentation. To reduce computational complexity, an entropy based sampling technique is introduced that gives superior results over uniform sampling. Filters are learned over several layers with the output of previous layers serving as the input to the next layer. A softmax logistic regression classifier is subsequently trained on the output of all learned filters. In several error metrics, the proposed algorithm outperforms existing methods on the public DRISHTI-GS data set.},
	language = {en},
	number = {9352},
	urldate = {2016-09-28},
	booktitle = {Machine {Learning} in {Medical} {Imaging}},
	publisher = {Springer International Publishing},
	author = {Zilly, Julian G. and Buhmann, Joachim M. and Mahapatra, Dwarikanath},
	editor = {Zhou, Luping and Wang, Li and Wang, Qian and Shi, Yinghuan},
	month = oct,
	year = {2015},
	doi = {10.1007/978-3-319-24888-2_17},
	keywords = {Artificial Intelligence (incl. Robotics), Health Informatics, Image Processing and Computer Vision, Pattern recognition, Data Mining and Knowledge Discovery},
	pages = {136--143},
	file = {Snapshot:/home/edecenciere/Zotero/storage/DEHKRC84/978-3-319-24888-2_17.html:text/html},
}

@incollection{ganin_n^4-fields:_2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {N{\textasciicircum}4-{Fields}: {Neural} {Network} {Nearest} {Neighbor} {Fields} for {Image} {Transforms}},
	copyright = {©2015 Springer International Publishing Switzerland},
	isbn = {978-3-319-16807-4 978-3-319-16808-1},
	shorttitle = {N{\textasciicircum}4-{Fields}},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-16808-1_36},
	abstract = {We propose a new architecture for difficult image processing operations, such as natural edge detection or thin object segmentation. The architecture is based on a simple combination of convolutional neural networks with the nearest neighbor search. We focus our attention on the situations when the desired image transformation is too hard for a neural network to learn explicitly. We show that in such situations the use of the nearest neighbor search on top of the network output allows to improve the results considerably and to account for the underfitting effect during the neural network training. The approach is validated on three challenging benchmarks, where the performance of the proposed architecture matches or exceeds the state-of-the-art.},
	language = {en},
	number = {9004},
	urldate = {2016-09-28},
	booktitle = {Computer {Vision} -- {ACCV} 2014},
	publisher = {Springer International Publishing},
	author = {Ganin, Yaroslav and Lempitsky, Victor},
	editor = {Cremers, Daniel and Reid, Ian and Saito, Hideo and Yang, Ming-Hsuan},
	month = nov,
	year = {2014},
	doi = {10.1007/978-3-319-16808-1_36},
	keywords = {Artificial Intelligence (incl. Robotics), Health Informatics, Image Processing and Computer Vision, Pattern recognition, Information Storage and Retrieval, Information Systems Applications (incl. Internet)},
	pages = {536--551},
	file = {Snapshot:/home/edecenciere/Zotero/storage/U7PJD35G/978-3-319-16808-1_36.html:text/html},
}

@article{everingham_pascal_2014,
	title = {The {Pascal} {Visual} {Object} {Classes} {Challenge}: {A} {Retrospective}},
	volume = {111},
	issn = {0920-5691, 1573-1405},
	shorttitle = {The {Pascal} {Visual} {Object} {Classes} {Challenge}},
	url = {http://link.springer.com/article/10.1007/s11263-014-0733-5},
	doi = {10.1007/s11263-014-0733-5},
	abstract = {The Pascal Visual Object Classes (VOC) challenge consists of two components: (i) a publicly available dataset of images together with ground truth annotation and standardised evaluation software; and (ii) an annual competition and workshop. There are five challenges: classification, detection, segmentation, action classification, and person layout. In this paper we provide a review of the challenge from 2008–2012. The paper is intended for two audiences: algorithm designers, researchers who want to see what the state of the art is, as measured by performance on the VOC datasets, along with the limitations and weak points of the current generation of algorithms; and, challenge designers, who want to see what we as organisers have learnt from the process and our recommendations for the organisation of future challenges. To analyse the performance of submitted algorithms on the VOC datasets we introduce a number of novel evaluation methods: a bootstrapping method for determining whether differences in the performance of two algorithms are significant or not; a normalised average precision so that performance can be compared across classes with different proportions of positive instances; a clustering method for visualising the performance across multiple algorithms so that the hard and easy images can be identified; and the use of a joint classifier over the submitted algorithms in order to measure their complementarity and combined performance. We also analyse the community’s progress through time using the methods of Hoiem et al. (Proceedings of European Conference on Computer Vision, 2012) to identify the types of occurring errors. We conclude the paper with an appraisal of the aspects of the challenge that worked well, and those that could be improved in future challenges.},
	language = {en},
	number = {1},
	urldate = {2016-09-27},
	journal = {International Journal of Computer Vision},
	author = {Everingham, Mark and Eslami, S. M. Ali and Gool, Luc Van and Williams, Christopher K. I. and Winn, John and Zisserman, Andrew},
	month = jun,
	year = {2014},
	pages = {98--136},
	file = {Snapshot:/home/edecenciere/Zotero/storage/RX7JR9Z4/s11263-014-0733-5.html:text/html},
}

@article{everingham_pascal_2009,
	title = {The {Pascal} {Visual} {Object} {Classes} ({VOC}) {Challenge}},
	volume = {88},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/article/10.1007/s11263-009-0275-4},
	doi = {10.1007/s11263-009-0275-4},
	abstract = {The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection.This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classification and detection, analyse whether the methods are statistically different, what they are learning from the images (e.g. the object or its context), and what the methods find easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension.},
	language = {en},
	number = {2},
	urldate = {2016-09-27},
	journal = {International Journal of Computer Vision},
	author = {Everingham, Mark and Gool, Luc Van and Williams, Christopher K. I. and Winn, John and Zisserman, Andrew},
	month = sep,
	year = {2009},
	pages = {303--338},
	file = {Snapshot:/home/edecenciere/Zotero/storage/DHATXFW5/s11263-009-0275-4.html:text/html},
}

@incollection{hanbury_how_2008,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {How {Do} {Superpixels} {Affect} {Image} {Segmentation}?},
	copyright = {©2008 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-85919-2 978-3-540-85920-8},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-85920-8_22},
	abstract = {Computationally intensive segmentation algorithms often operate on an image pre-segmented into small regions referred to as “superpixels”. We investigate the effect of the choice of the pre-segmentation algorithm and its parameters on the outcome of the final segmentation. Three pre-segmentation algorithms are compared. To avoid the particularities of sophisticated segmentation algorithms, the final segmentations are built using agglomerative hierarchical clustering. These segmentations are evaluated using 300 images from the Berkeley Segmentation Dataset. This leads to useful insights about the variations in the final segmentation caused by the choice of the pre-segmentation algorithm.},
	language = {en},
	number = {5197},
	urldate = {2016-09-20},
	booktitle = {Progress in {Pattern} {Recognition}, {Image} {Analysis} and {Applications}},
	publisher = {Springer Berlin Heidelberg},
	author = {Hanbury, Allan},
	editor = {Ruiz-Shulcloper, José and Kropatsch, Walter G.},
	month = sep,
	year = {2008},
	doi = {10.1007/978-3-540-85920-8_22},
	keywords = {Image segmentation, Artificial Intelligence (incl. Robotics), Computer Graphics, Image Processing and Computer Vision, Pattern recognition, Biometrics, Computer Imaging, Vision, Pattern Recognition and Graphics, clustering, segmentation evaluation},
	pages = {178--186},
	file = {Snapshot:/home/edecenciere/Zotero/storage/D9W9693D/978-3-540-85920-8_22.html:text/html},
}

@incollection{scherer_evaluation_2010,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Evaluation of {Pooling} {Operations} in {Convolutional} {Architectures} for {Object} {Recognition}},
	copyright = {©2010 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-15824-7 978-3-642-15825-4},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-15825-4_10},
	abstract = {A common practice to gain invariant features in object recognition models is to aggregate multiple low-level features over a small neighborhood. However, the differences between those models makes a comparison of the properties of different aggregation functions hard. Our aim is to gain insight into different functions by directly comparing them on a fixed architecture for several common object recognition tasks. Empirical results show that a maximum pooling operation significantly outperforms subsampling operations. Despite their shift-invariant properties, overlapping pooling windows are no significant improvement over non-overlapping pooling windows. By applying this knowledge, we achieve state-of-the-art error rates of 4.57\% on the NORB normalized-uniform dataset and 5.6\% on the NORB jittered-cluttered dataset.},
	language = {en},
	number = {6354},
	urldate = {2016-09-16},
	booktitle = {Artificial {Neural} {Networks} – {ICANN} 2010},
	publisher = {Springer Berlin Heidelberg},
	author = {Scherer, Dominik and Müller, Andreas and Behnke, Sven},
	editor = {Diamantaras, Konstantinos and Duch, Wlodek and Iliadis, Lazaros S.},
	month = sep,
	year = {2010},
	doi = {10.1007/978-3-642-15825-4_10},
	keywords = {Artificial Intelligence (incl. Robotics), Pattern recognition, Algorithm Analysis and Problem Complexity, Information Systems Applications (incl. Internet), Computation by Abstract Devices, Database Management},
	pages = {92--101},
	file = {Snapshot:/home/edecenciere/Zotero/storage/EK3BMCI6/10.html:text/html},
}

@article{badrinarayanan_segnet:_2015,
	title = {{SegNet}: {A} {Deep} {Convolutional} {Encoder}-{Decoder} {Architecture} for {Image} {Segmentation}},
	shorttitle = {{SegNet}},
	url = {http://arxiv.org/abs/1511.00561},
	abstract = {We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation termed SegNet. This core trainable segmentation engine consists of an encoder network, a corresponding decoder network followed by a pixel-wise classification layer. The architecture of the encoder network is topologically identical to the 13 convolutional layers in the VGG16 network . The role of the decoder network is to map the low resolution encoder feature maps to full input resolution feature maps for pixel-wise classification. The novelty of SegNet lies is in the manner in which the decoder upsamples its lower resolution input feature map(s). Specifically, the decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. This eliminates the need for learning to upsample. The upsampled maps are sparse and are then convolved with trainable filters to produce dense feature maps. We compare our proposed architecture with the fully convolutional network (FCN) architecture and its variants. This comparison reveals the memory versus accuracy trade-off involved in achieving good segmentation performance. The design of SegNet was primarily motivated by road scene understanding applications. Hence, it is efficient both in terms of memory and computational time during inference. It is also significantly smaller in the number of trainable parameters than competing architectures and can be trained end-to-end using stochastic gradient descent. We also benchmark the performance of SegNet on Pascal VOC12 salient object segmentation and the recent SUN RGB-D indoor scene understanding challenge. We show that SegNet provides competitive performance although it is significantly smaller than other architectures. We also provide a Caffe implementation of SegNet and a webdemo at http://mi.eng.cam.ac.uk/projects/segnet/},
	urldate = {2016-09-12},
	journal = {arXiv:1511.00561 [cs]},
	author = {Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.00561},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing, Computer Science - Learning},
	file = {arXiv\:1511.00561 PDF:/home/edecenciere/Zotero/storage/C2EXEX9G/Badrinarayanan et al. - 2015 - SegNet A Deep Convolutional Encoder-Decoder Archi.pdf:application/pdf;arXiv.org Snapshot:/home/edecenciere/Zotero/storage/ZC76VUF8/1511.html:text/html},
}

@inproceedings{jeong_marked_2014,
	title = {Marked point process model for facial wrinkle detection},
	doi = {10.1109/ICIP.2014.7025278},
	abstract = {We propose a new model for wrinkle detection in human faces using a marked point process. In order to detect an arbitrary shape of wrinkles, we represent them as a set of line segments, where each segment is characterized by its length and orientation. We propose a probability density of wrinkle model which exploits local edge profile and geometric properties of wrinkles. To optimize the probability density of wrinkle model, we employ reversible jump Markov chain Monte Carlo sampler with delayed rejection. Experimental results demonstrate that the new algorithm detects facial wrinkles more accurately than a recent state-of-the-art method.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	author = {Jeong, S. G. and Tarabalka, Y. and Zerubia, J.},
	month = oct,
	year = {2014},
	keywords = {Image segmentation, Markov processes, Kernel, Image edge detection, Transforms, delayed rejection, face recognition, facial wrinkle detection, line detection, local edge profile, marked point process, marked point process model, Monte Carlo methods, probability, probability density, reversible jump Markov chain Monte Carlo sampler, Shape, Skin image processing, stochastic optimization, wrinkle detection, wrinkle model, wrinkles geometric properties},
	pages = {1391--1394},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/4M5IM734/abs_all.html:text/html},
}

@article{batool_detection_2014,
	title = {Detection and {Inpainting} of {Facial} {Wrinkles} {Using} {Texture} {Orientation} {Fields} and {Markov} {Random} {Field} {Modeling}},
	volume = {23},
	issn = {1057-7149},
	doi = {10.1109/TIP.2014.2332401},
	abstract = {Facial retouching is widely used in media and entertainment industry. Professional software usually require a minimum level of user expertise to achieve the desirable results. In this paper, we present an algorithm to detect facial wrinkles/imperfection. We believe that any such algorithm would be amenable to facial retouching applications. The detection of wrinkles/imperfections can allow these skin features to be processed differently than the surrounding skin without much user interaction. For detection, Gabor filter responses along with texture orientation field are used as image features. A bimodal Gaussian mixture model (GMM) represents distributions of Gabor features of normal skin versus skin imperfections. Then, a Markov random field model is used to incorporate the spatial relationships among neighboring pixels for their GMM distributions and texture orientations. An expectation-maximization algorithm then classifies skin versus skin wrinkles/imperfections. Once detected automatically, wrinkles/imperfections are removed completely instead of being blended or blurred. We propose an exemplar-based constrained texture synthesis algorithm to inpaint irregularly shaped gaps left by the removal of detected wrinkles/imperfections. We present results conducted on images downloaded from the Internet to show the efficacy of our algorithms.},
	number = {9},
	journal = {IEEE Transactions on Image Processing},
	author = {Batool, N. and Chellappa, R.},
	month = sep,
	year = {2014},
	keywords = {object detection, Feature extraction, image restoration, Markov processes, Markov random field, skin, Gabor filters, image texture, bimodal Gaussian mixture model, exemplar-based constrained texture synthesis algorithm, expectation-maximisation algorithm, expectation-maximization algorithm, facial imperfection detection, facial retouching, facial retouching applications, Facial wrinkles, facial wrinkles detection, facial wrinkles inpainting, Gabor features, Gabor filter, Gaussian mixture model, GMM, image features, Markov random field modeling, Mathematical model, Painting, skin imperfections, Software, texture orientation fields, user expertise, user interaction},
	pages = {3773--3788},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/P3VKUUVF/abs_all.html:text/html},
}

@inproceedings{chang_automatic_2010,
	title = {Automatic {Facial} {Skin} {Defect} {Detection} {System}},
	doi = {10.1109/BWCCA.2010.126},
	abstract = {Skin analysis is one of the most important procedures before medical cosmetology. Most conventional skin analysis systems are semi-automatic. They often require human intervention. In this study, an automatic facial skin defect detection approach is proposed. The system first detects human face in the facial image. Based on the detected face, facial features are extracted to locate regions of interest. Then, a pattern recognition approach is applied to detect facial skin defects, such as spots and wrinkles, in the regions of interest. For a specific kind of defect, a classifier is designed to provide higher performance for recognition. Using few features extracted from the region of interest, the proposed approach can successfully detect the skin defects. Experimental results demonstrate effectiveness of the proposed approach.},
	booktitle = {2010 {International} {Conference} on {Broadband}, {Wireless} {Computing}, {Communication} and {Applications} ({BWCCA})},
	author = {Chang, C. Y. and Li, S. C. and Chung, P. C. and Kuo, J. Y. and Tu, Y. C.},
	month = nov,
	year = {2010},
	keywords = {image classification, Feature extraction, Image color analysis, skin, classifier, Transforms, face recognition, automatic facial skin defect detection system, Face, Facial features, facial skin defect detection, facial skin defects detection, Forehead, human face detection, medical cosmetology, pattern recognition approach, skin analysis, spot, wrinkle},
	pages = {527--532},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/FUCBTGQH/abs_all.html:text/html},
}

@inproceedings{mehta_selective_2014,
	title = {Selective quantifiable facial assessment of aging},
	doi = {10.1109/PAHCE.2014.6849637},
	abstract = {Imaging represents a technique of choice in evaluation of the visual effects of aging and associated with that occurrence of wrinkles. In particular, skin wrinkles typically occur due to aging processes, including loss of body mass, sun damage, smoking, squinting and other factors. They represent a clear and easily accessible indicator of changes. As such, one can also acquire useful information about the aging process in skin by analyzing the wrinkles. To this end, we utilize a combination of numerical techniques, including color quantization, image segmentation, and various edge detection algorithms in order to perform automated wrinkle counting and wrinkle density calculations. As a more appropriate alternative to chronological age, such a methodology allows us to come up with quantifiable measures for skin aging, which may be used for performing statistics and extracting general patterns associated with physiological aging of the skin, as well as extending such numerical techniques for other biomedical applications in which distinct topological features contain important information about biological processes. Different subjects were used to test the techniques and extract aging patterns by examining the skin immediately underneath the lower eyelid as our region of interest. Numerically processed photographs, included counting the number of wrinkles meeting predefined threshold conditions, and calculating the corresponding wrinkle density for a given subject and particular conditions. Applicability and practicality of different edge detection methods were also a part of the studies as demonstrated.},
	booktitle = {Health {Care} {Exchanges} ({PAHCE}), 2014 {Pan} {American}},
	author = {Mehta, G. and Druzgalski, C.},
	month = apr,
	year = {2014},
	keywords = {Image segmentation, Feature extraction, Image color analysis, biomedical optical imaging, medical image processing, image colour analysis, skin, Cameras, Edge detection, Image edge detection, Aging, Skin Aging, Gray-scale, biomedical applications, chronological age, color quantization, edge detection algorithms, edge detection methods, facial assessment, numerical analysis, numerical techniques, pattern extraction, photographs, Physiology, skin wrinkle counting, skin wrinkle density calculations, Skin wrinkles, Statistics, topological features, visual effect evaluation},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/UXIASNCQ/abs_all.html:text/html},
}

@inproceedings{sourati_unsupervised_2012,
	title = {Unsupervised wrinkle detection in reflectance confocal microscopy images of the human skin},
	doi = {10.1109/ICASSP.2012.6287981},
	abstract = {Reflectance confocal microscopy (RCM) is a non-invasive and in-vivo imaging modality, which can take images from different depths of the human skin. A challenging problem is to detect a clinically important subsurface section of the skin, the Dermis/Epidermis junction, in RCM images. This is a tough problem because of the huge variation of texture and intensity features across both intersubject and intrasubject tissues. On the other hand, there's almost no wrinkle-free part of the skin. This well-known phenomenon can be used as a histological clue for guessing the probability of being Dermis or Epidermis in the neighboring regions. In this paper, we develop a two-step wrinkle detector for RCM images. By analyzing the results on different RCM images, we conclude it has high sensitivity and specificity, but a relatively lower Jaccard index.},
	booktitle = {2012 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Sourati, J. and Brooks, D. H. and Dy, J. G. and Ataer-Cansizoglu, E. and Erdogmus, D. and Rajadhyaksha, M.},
	month = mar,
	year = {2012},
	keywords = {Feature extraction, Humans, Microscopy, optical microscopy, biomedical optical imaging, medical image processing, human skin, skin, epidermis, image texture, probability, wrinkle detection, dermis-epidermis junction, feature intensity, in-vivo imaging modality, Indexes, intersubject tissues, intrasubject tissues, Jaccard index, Junctions, noninvasive imaging modality, reflectance confocal microscopy, Reflectivity, sensitivity, two-step wrinkle detector, unsupervised wrinkle detection},
	pages = {705--708},
}

@article{arganda-carreras_crowdsourcing_2015,
	title = {Crowdsourcing the creation of image segmentation algorithms for connectomics},
	volume = {9},
	issn = {1662-5129},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4633678/},
	doi = {10.3389/fnana.2015.00142},
	abstract = {To stimulate progress in automating the reconstruction of neural circuits, we organized the first international challenge on 2D segmentation of electron microscopic (EM) images of the brain. Participants submitted boundary maps predicted for a test set of images, and were scored based on their agreement with a consensus of human expert annotations. The winning team had no prior experience with EM images, and employed a convolutional network. This “deep learning” approach has since become accepted as a standard for segmentation of EM images. The challenge has continued to accept submissions, and the best so far has resulted from cooperation between two teams. The challenge has probably saturated, as algorithms cannot progress beyond limits set by ambiguities inherent in 2D scoring and the size of the test dataset. Retrospective evaluation of the challenge scoring system reveals that it was not sufficiently robust to variations in the widths of neurite borders. We propose a solution to this problem, which should be useful for a future 3D segmentation challenge.},
	urldate = {2016-06-30},
	journal = {Frontiers in Neuroanatomy},
	author = {Arganda-Carreras, Ignacio and Turaga, Srinivas C. and Berger, Daniel R. and Cireşan, Dan and Giusti, Alessandro and Gambardella, Luca M. and Schmidhuber, Jürgen and Laptev, Dmitry and Dwivedi, Sarvesh and Buhmann, Joachim M. and Liu, Ting and Seyedhosseini, Mojtaba and Tasdizen, Tolga and Kamentsky, Lee and Burget, Radim and Uher, Vaclav and Tan, Xiao and Sun, Changming and Pham, Tuan D. and Bas, Erhan and Uzunbas, Mustafa G. and Cardona, Albert and Schindelin, Johannes and Seung, H. Sebastian},
	month = nov,
	year = {2015},
	pmid = {26594156},
	pmcid = {PMC4633678},
}

@inproceedings{cun_handwritten_1990,
	title = {Handwritten {Digit} {Recognition} with a {Back}-{Propagation} {Network}},
	abstract = {We present an application of back-propagation networks to handwritten digit recognition. Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task. The input of the network consists of normalized images of isolated digits. The method has 1\% error rate and about a 9\% reject rate on zipcode digits provided by the U.S. Postal Service.  1 INTRODUCTION  The main point of this paper is to show that large back-propagation (BP) networks can be applied to real image-recognition problems without a large, complex preprocessing stage requiring detailed engineering. Unlike most previous work on the subject (Denker et al., 1989), the learning network is directly fed with images, rather than feature vectors, thus demonstrating the ability of BP networks to deal with large amounts of low level information. Previous work performed on simple digit images (Le Cun, 1989) showed that the architecture of the network strongly...},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Morgan Kaufmann},
	author = {Cun, Le and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
	year = {1990},
	pages = {396--404},
	file = {Citeseer - Snapshot:/home/edecenciere/Zotero/storage/6DQ4BIQC/summary.html:text/html},
}

@inproceedings{lee_feature-based_2007,
	title = {Feature-based pairwise retinal image registration by radial distortion correction},
	volume = {6512},
	url = {http://dx.doi.org/10.1117/12.710676},
	doi = {10.1117/12.710676},
	abstract = {Fundus camera imaging is widely used to document disorders such as diabetic retinopathy and macular degeneration. Multiple retinal images can be combined together through a procedure known as mosaicing to form an image with a larger field of view. Mosaicing typically requires multiple pairwise registrations of partially overlapped images. We describe a new method for pairwise retinal image registration. The proposed method is unique in that the radial distortion due to image acquisition is corrected prior to the geometric transformation. Vessel lines are detected using the Hessian operator and are used as input features to the registration. Since the overlapping region is typically small in a retinal image pair, only a few correspondences are available, thus limiting the applicable model to an afine transform at best. To recover the distortion due to curved-surface of retina and lens optics, a combined approach of an afine model with a radial distortion correction is proposed. The parameters of the image acquisition and radial distortion models are estimated during an optimization step that uses Powell's method driven by the vessel line distance. Experimental results using 20 pairs of green channel images acquired from three subjects with a fundus camera confirmed that the afine model with distortion correction could register retinal image pairs to within 1.88±0.35 pixels accuracy (mean ± standard deviation) assessed by vessel line error, which is 17\% better than the afine-only approach. Because the proposed method needs only two correspondences, it can be applied to obtain good registration accuracy even in the case of small overlap between retinal image pairs.},
	urldate = {2016-06-16},
	author = {Lee, Sangyeol and Abràmoff, Michael D. and Reinhardt, Joseph M.},
	year = {2007},
	pages = {651220--651220--10},
}

@inproceedings{nguyen_deep_2015,
	title = {Deep neural networks are easily fooled: {High} confidence predictions for unrecognizable images},
	shorttitle = {Deep neural networks are easily fooled},
	doi = {10.1109/CVPR.2015.7298640},
	abstract = {Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study [30] revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99\% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call “fooling images” (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision.},
	booktitle = {2015 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Nguyen, A. and Yosinski, J. and Clune, J.},
	month = jun,
	year = {2015},
	keywords = {image classification, computer vision, neural nets, object recognition, convolutional neural networks, convolution, Biomedical imaging, image labeling, evolutionary computation, deep neural networks, DNNs, evolutionary algorithms, fooling images, gradient ascent, ImageNet datasets, Keyboards, MNIST datasets, pattern-recognition tasks, recognizable objects, unrecognizable images, visual classification problems, Volcanoes},
	pages = {427--436},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/HMXF785X/abs_all.html:text/html},
}

@article{grinsven_fast_2016,
	title = {Fast {Convolutional} {Neural} {Network} {Training} {Using} {Selective} {Data} {Sampling}: {Application} to {Hemorrhage} {Detection} in {Color} {Fundus} {Images}},
	volume = {35},
	issn = {0278-0062},
	shorttitle = {Fast {Convolutional} {Neural} {Network} {Training} {Using} {Selective} {Data} {Sampling}},
	doi = {10.1109/TMI.2016.2526689},
	abstract = {Convolutional neural networks (CNNs) are deep learning network architectures that have pushed forward the state-of-the-art in a range of computer vision applications and are increasingly popular in medical image analysis. However, training of CNNs is time-consuming and challenging. In medical image analysis tasks, the majority of training examples are easy to classify and therefore contribute little to the CNN learning process. In this paper, we propose a method to improve and speed-up the CNN training for medical image analysis tasks by dynamically selecting misclassified negative samples during training. Training samples are heuristically sampled based on classification by the current status of the CNN. Weights are assigned to the training samples and informative samples are more likely to be included in the next CNN training iteration. We evaluated and compared our proposed method by training a CNN with (SeS) and without (NSeS) the selective sampling method. We focus on the detection of hemorrhages in color fundus images. A decreased training time from 170 epochs to 60 epochs with an increased performance-on par with two human experts-was achieved with areas under the receiver operating characteristics curve of 0.894 and 0.972 on two data sets. The SeS CNN statistically outperformed the NSeS CNN on an independent test set.},
	number = {5},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Grinsven, M. J. J. P. van and Ginneken, B. van and Hoyng, C. B. and Theelen, T. and Sánchez, C. I.},
	month = may,
	year = {2016},
	keywords = {deep learning, Convolutional neural network, learning (artificial intelligence), Training, image classification, computer vision, Image analysis, neural nets, Image color analysis, biomedical optical imaging, medical image processing, Databases, image colour analysis, Biomedical imaging, blood, CNN learning process, CNN training iteration, color fundus images, computer vision applications, deep learning network architectures, dynamically selecting misclassified negative samples, fast convolutional neural network training, hemorrhage, hemorrhage detection, Hemorrhaging, image sampling, independent test set, medical image analysis tasks, Observers, receiver operating characteristics curve, selective data sampling, selective sampling, selective sampling method, sensitivity analysis},
	pages = {1273--1284},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/AZN8BXM9/abs_all.html:text/html},
}

@inproceedings{veras_assessing_2013,
	title = {Assessing the accuracy of macula detection methods in retinal images},
	doi = {10.1109/ICDSP.2013.6622734},
	abstract = {Fundus images are valuable resource in diagnosis because they often present indications about retinal, ophthalmic, and even systemic diseases such as diabetes, hypertension, and arteriosclerosis. Processing and analysis constitutes a relevant task to help specialists in detecting eye diseases. This paper focuses on algorithms to detect macula, a fundamental structure associated with the macular degeneration, that can be recognized from fundus image. We notice two typical ways in which macula detection algorithms have been evaluated: a) one uses a particular image or a single benchmark retina image database instead of several public ones; b) one selects an ad-hoc set of metrics to perform the evaluation for the lack of a standard. In this paper, we propose a set of rules to assess macula detection algorithms, then we compare four macula detection algorithms, using three public benchmark databases, using a total of 254 images. The contribution of this work is to devise a grading scheme that allows comparing different algorithms, as well as identifying cases that are likely to contain macular abnormalities. Finally, the proposed assessment methodology splits the results into success, satisfactory and failure, such that it provides an easier entry to the specialists to address and grade macular edema disease.},
	booktitle = {2013 18th {International} {Conference} on {Digital} {Signal} {Processing} ({DSP})},
	author = {Veras, R. and Medeiros, F. and Silva, R. and Ushizima, D.},
	month = jul,
	year = {2013},
	keywords = {Measurement, Image databases, medical image processing, eye, Retina, retinal images, diseases, fundus images, pathology, Detection algorithms, eye diseases, macula detection methods, macular edema disease, ophthalmic diseases, patient diagnosis, retina image database, systemic diseases, visual databases},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/DVB5JB97/abs_all.html:text/html},
}

@incollection{krizhevsky_imagenet_2012,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
	urldate = {2016-06-06},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
	pages = {1097--1105},
	file = {NIPS Snapshort:/home/edecenciere/Zotero/storage/945EI2D3/4824-imagenet-classification-w.html:text/html},
}

@article{rosenblatt_perceptron:_1958,
	title = {The perceptron: {A} probabilistic model for information storage and organization in the brain},
	volume = {65},
	copyright = {(c) 2012 APA, all rights reserved},
	issn = {1939-1471(Electronic);0033-295X(Print)},
	shorttitle = {The perceptron},
	doi = {10.1037/h0042519},
	abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems. 18 references.},
	number = {6},
	journal = {Psychological Review},
	author = {Rosenblatt, F.},
	year = {1958},
	keywords = {*Brain, *Cognition, *Memory, Nervous System},
	pages = {386--408},
}

@incollection{meyer_dynamics_1996,
	series = {Computational {Imaging} and {Vision}},
	title = {The {Dynamics} of {Minima} and {Contours}},
	copyright = {©1996 Kluwer Academic Publishers},
	isbn = {978-1-4613-8063-4 978-1-4613-0469-2},
	url = {http://link.springer.com/chapter/10.1007/978-1-4613-0469-2_38},
	abstract = {The dynamics has been introduced for ranking the minima of a topographic surface according to their contrast. Constructing the watershed associated to the set of markers with a dynamic higher than a given threshold will produce a tesselation of the space. As the threshold becomes higher, neighboring regions merge: the contours which vanish may be labeled by the dynamics for which the merging occurs. The paper shows that all information necessary for computing the dynamics of minima and of contours is contained in the minimal spanning tree of the neighborhood graph and efficient algorithms are presented for computing it.},
	language = {en},
	number = {5},
	urldate = {2016-06-03},
	booktitle = {Mathematical {Morphology} and its {Applications} to {Image} and {Signal} {Processing}},
	publisher = {Springer US},
	author = {Meyer, Fernand},
	editor = {Maragos, Petros and Schafer, Ronald W. and Butt, Muhammad Akmal},
	year = {1996},
	doi = {10.1007/978-1-4613-0469-2_38},
	keywords = {Image Processing and Computer Vision, Signal, Image and Speech Processing, Computer Imaging, Vision, Pattern Recognition and Graphics, Optics, Optoelectronics, Plasmonics and Optical Devices, Order, Lattices, Ordered Algebraic Structures},
	pages = {329--336},
	file = {Snapshot:/home/edecenciere/Zotero/storage/57KHRWG7/978-1-4613-0469-2_38.html:text/html},
}

@inproceedings{machairas_waterpixels:_2014,
	title = {Waterpixels: {Superpixels} based on the watershed transformation},
	shorttitle = {Waterpixels},
	doi = {10.1109/ICIP.2014.7025882},
	abstract = {Many sophisticated segmentation algorithms rely on a first low-level segmentation step where an image is partitioned into homogeneous regions with enforced compactness and adherence to object boundaries. These regions are called “superpixels”. While the marker controlled watershed transformation should in principle be well suited for this type of application, it has never been seriously tested in this setup, and comparisons to other methods were not made with the best possible settings. Here, we provide a scheme for applying the watershed transform for superpixel generation, where we use a spatially regularized gradient to achieve a tunable trade-off between superpixel regularity and adherence to object boundaries. We quantitatively evaluate our method on the Berkeley segmentation database and show that we achieve comparable results to a previously published state-of-the art algorithm, while avoiding some of the arbitrary postprocessing steps the latter requires.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	author = {Machairas, V. and Decenciere, E. and Walter, T.},
	month = oct,
	year = {2014},
	keywords = {Image segmentation, computer vision, Benchmark testing, Image color analysis, Databases, segmentation, superpixel generation, Superpixels, Shape, Art, Berkeley segmentation database, segmentation algorithms, waterpixels, watershed, watershed transformation},
	pages = {4343--4347},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/TJ6NIXZJ/login.html:text/html},
}

@misc{noauthor_ieee_nodate,
	title = {{IEEE} {Xplore} {Abstract} - {Waterpixels}: {Superpixels} based on the watershed transformation},
	url = {http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=7025882&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D7025882},
	urldate = {2015-10-22},
	file = {IEEE Xplore Abstract - Waterpixels\: Superpixels based on the watershed transformation:/home/edecenciere/Zotero/storage/V7ZTQIRH/login.html:text/html},
}

@article{gonzalez-castro_color_2014,
	series = {Advances in {Mathematical} {Morphology}},
	title = {Color {Adaptive} {Neighborhood} {Mathematical} {Morphology} and its application to pixel-level classification},
	volume = {47},
	issn = {0167-8655},
	url = {http://www.sciencedirect.com/science/article/pii/S016786551400021X},
	doi = {10.1016/j.patrec.2014.01.007},
	abstract = {In this paper spatially adaptive Mathematical Morphology (MM) is studied for color images. More precisely, the General Adaptive Neighborhood Image Processing (GANIP) approach is generalized to color images. The basic principle is to define a set of locally Color Adaptive Neighborhoods (CAN), one for each point of the image, and to use them as adaptive structuring elements (ASE) for morphological operations. These operators have been applied to images in different color spaces and compared with other kinds of ASEs extended to color images. Results show that the proposed method is more respectful with the borders of the objects, as well as with the color transitions within the image. Finally, the proposed adaptive morphological operators are applied to the classification of color texture images.},
	urldate = {2015-10-22},
	journal = {Pattern Recognition Letters},
	author = {González-Castro, Víctor and Debayle, Johan and Pinoli, Jean-Charles},
	month = oct,
	year = {2014},
	keywords = {mathematical morphology, Neural Networks, classification, Color Adaptive Neighborhoods, Color spaces},
	pages = {50--62},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/PDRAWN7I/S016786551400021X.html:text/html},
}

@article{pedregosa_scikit-learn:_2011-2,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	volume = {12},
	shorttitle = {Scikit-learn},
	url = {http://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language.  Emphasis is put on ease of use, performance, documentation, and API consistency.  It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings.  Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
	urldate = {2015-10-22},
	journal = {Journal of Machine Learning Research},
	author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
	month = oct,
	year = {2011},
	pages = {2825−2830},
	file = {Scikit-learn\: Machine Learning in Python:/home/edecenciere/Zotero/storage/NNHRQR3D/Pedregosa et al. - 2011 - Scikit-learn Machine Learning in Python.pdf:application/pdf},
}

@article{breiman_random_2001,
	title = {Random {Forests}},
	volume = {45},
	issn = {0885-6125, 1573-0565},
	url = {http://link.springer.com/article/10.1023/A%3A1010933404324},
	doi = {10.1023/A:1010933404324},
	abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
	language = {en},
	number = {1},
	urldate = {2015-10-22},
	journal = {Machine Learning},
	author = {Breiman, Leo},
	month = oct,
	year = {2001},
	keywords = {Artificial Intelligence (incl. Robotics), Automation and Robotics, classification, Computing Methodologies, ensemble, Language Translation and Linguistics, regression, Simulation and Modeling},
	pages = {5--32},
	file = {Snapshot:/home/edecenciere/Zotero/storage/JNW4PZBJ/A1010933404324.html:text/html},
}

@article{serna_segmentation_2014,
	series = {Advances in {Mathematical} {Morphology}},
	title = {Segmentation of elongated objects using attribute profiles and area stability: {Application} to melanocyte segmentation in engineered skin},
	volume = {47},
	issn = {0167-8655},
	shorttitle = {Segmentation of elongated objects using attribute profiles and area stability},
	url = {http://www.sciencedirect.com/science/article/pii/S0167865514000944},
	doi = {10.1016/j.patrec.2014.03.014},
	abstract = {In this paper, a method to segment elongated objects is proposed. It is based on attribute profiles and area stability. Images are represented as component trees using a threshold decomposition. Then, some attributes are computed on each node of the tree. Finally, the attribute profile is analyzed to identify important events useful for segmentation tasks. In this work, a new attribute, combining geodesic elongation and area stability is defined. This methodology is successfully applied to the segmentation of cells in multiphoton fluorescence microscopy images of engineered skin. Quantitative results are provided, demonstrating the performance and robustness of the new attribute. A comparison with MSER is also given.},
	urldate = {2015-10-22},
	journal = {Pattern Recognition Letters},
	author = {Serna, Andrés and Marcotegui, Beatriz and Decencière, Etienne and Baldeweck, Thérèse and Pena, Ana-Maria and Brizion, Sébastien},
	month = oct,
	year = {2014},
	keywords = {segmentation, mathematical morphology, Area stability, Attribute profile, Elongation, multiphoton microscopy},
	pages = {172--182},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/5NH6GKVA/S0167865514000944.html:text/html},
}

@article{achanta_slic_2012-1,
	title = {{SLIC} {Superpixels} {Compared} to {State}-of-the-{Art} {Superpixel} {Methods}},
	volume = {34},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2012.120},
	abstract = {Computer vision applications have come to rely increasingly on superpixels in recent years, but it is not always clear what constitutes a good superpixel algorithm. In an effort to understand the benefits and drawbacks of existing methods, we empirically compare five state-of-the-art superpixel algorithms for their ability to adhere to image boundaries, speed, memory efficiency, and their impact on segmentation performance. We then introduce a new superpixel algorithm, simple linear iterative clustering (SLIC), which adapts a k-means clustering approach to efficiently generate superpixels. Despite its simplicity, SLIC adheres to boundaries as well as or better than previous methods. At the same time, it is faster and more memory efficient, improves segmentation performance, and is straightforward to extend to supervoxel generation.},
	number = {11},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Achanta, R. and Shaji, A. and Smith, K. and Lucchi, A. and Fua, P. and Süsstrunk, S.},
	month = nov,
	year = {2012},
	keywords = {Image segmentation, Algorithms, computer vision, Image Enhancement, Image Interpretation, Computer-Assisted, Pattern Recognition, Automated, Reproducibility of Results, Sensitivity and Specificity, Image color analysis, segmentation, Approximation algorithms, clustering, Clustering algorithms, Complexity theory, image boundary, Image edge detection, iterative methods, k-means, k-means clustering approach, Measurement uncertainty, memory efficiency, pattern clustering, segmentation performance, Signal Processing, Computer-Assisted, simple linear iterative clustering, SLIC superpixels, superpixel generation, Superpixels, supervoxel generation},
	pages = {2274--2282},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/WP6FQ9V9/abs_all.html:text/html},
}

@article{machairas_waterpixels_2015,
	title = {Waterpixels},
	volume = {24},
	issn = {1057-7149},
	doi = {10.1109/TIP.2015.2451011},
	abstract = {Many approaches for image segmentation rely on a first low-level segmentation step, where an image is partitioned into homogeneous regions with enforced regularity and adherence to object boundaries. Methods to generate these superpixels have gained substantial interest in the last few years, but only a few have made it into applications in practice, in particular because the requirements on the processing time are essential but are not met by most of them. Here, we propose waterpixels as a general strategy for generating superpixels which relies on the marker controlled watershed transformation. We introduce a spatially regularized gradient to achieve a tunable tradeoff between the superpixel regularity and the adherence to object boundaries. The complexity of the resulting methods is linear with respect to the number of image pixels. We quantitatively evaluate our approach on the Berkeley segmentation database and compare it against the state-of-the-art.},
	number = {11},
	journal = {IEEE Transactions on Image Processing},
	author = {Machairas, V. and Faessel, M. and Cardenas-Pena, D. and Chabardes, T. and Walter, T. and Decenciere, E.},
	month = nov,
	year = {2015},
	keywords = {Image segmentation, Databases, segmentation, Complexity theory, iterative methods, Superpixels, Cost function, Shape, Art, watershed, image partitioning, image waterpixel, low-level image Berkeley segmentation, marker controlled watershed transformation, regularized gradient, superpixel regularity},
	pages = {3707--3716},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/RIV7VKG6/abs_all.html:text/html},
}

@inproceedings{v._morard_region_2011,
	address = {Etats-Unis},
	title = {Region growing structuring elements and new operators based on their shape},
	booktitle = {Signal and {Image} {Processing} ({SIP} 2011)},
	publisher = {ACTA Press},
	author = {{V. Morard} and {E. Decencière} and {P. Dokladal}},
	year = {2011},
}

@inproceedings{grimaud_new_1992-1,
	title = {New measure of contrast: the dynamics},
	booktitle = {San {Diego}'92},
	publisher = {International Society for Optics and Photonics},
	author = {Grimaud, Michel},
	year = {1992},
	pages = {292--305},
}

@inproceedings{marcotegui_fast_2005,
	title = {Fast implementation of waterfall based on graphs},
	booktitle = {Mathematical {Morphology}: 40 {Years} {On}},
	publisher = {Springer},
	author = {Marcotegui, Beatriz and Beucher, Serge},
	year = {2005},
	pages = {177--186},
}

@article{meyer_morphological_1990-1,
	title = {Morphological segmentation},
	volume = {1},
	issn = {1047-3203},
	url = {http://www.sciencedirect.com/science/article/pii/104732039090014M},
	doi = {10.1016/1047-3203(90)90014-M},
	abstract = {Methods for image segmentation using mathematical morphology are presented. These methods are based on two main tools: the watershed transform and the homotopy modification which solve the problem of the oversegmentation and introduce the notion of markers of the objects to be segmented in the image. Some examples in various domains (biology, medicine, scene analysis, 3D images, detection of moving objects, color images) are given. We tried in these examples to emphasize the problems encountered and to explain shortly the proposed solutions. The algorithms are given in the Appendix. The detection of the markers requiring a large amount of morphological tools, many of them, are presented, though not directly related to segmentation},
	number = {1},
	urldate = {2015-01-15},
	journal = {Journal of Visual Communication and Image Representation},
	author = {Meyer, F. and Beucher, S.},
	month = sep,
	year = {1990},
	pages = {21--46},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/5P755N5I/104732039090014M.html:text/html},
}

@article{kalinin_graph_2015,
	title = {A graph based approach to hierarchical image over-segmentation},
	volume = {130},
	issn = {1077-3142},
	url = {http://www.sciencedirect.com/science/article/pii/S1077314214001891},
	doi = {10.1016/j.cviu.2014.09.007},
	abstract = {The problem of image segmentation is formulated in terms of recursive partitioning of segments into subsegments by optimizing the proposed objective function via graph cuts. Our approach uses a special normalization of the objective function, which enables the production of a hierarchy of regular superpixels that adhere to image boundaries. To enforce compactness and visual homogeneity of segments a regularization strategy is proposed. Experiments on the Berkeley dataset show that the proposed algorithm is comparable in its performance to the state-of-the-art superpixel methods.},
	urldate = {2014-12-15},
	journal = {Computer Vision and Image Understanding},
	author = {Kalinin, Pavel and Sirota, Aleksandr},
	month = jan,
	year = {2015},
	keywords = {segmentation, Superpixels, Graph cuts},
	pages = {80--86},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/HIARJDZU/S1077314214001891.html:text/html},
}

@article{donois_stereological_1997,
	title = {Stereological image analysis of cultured human melanocytes observed by transmission electron microscopy},
	volume = {36},
	copyright = {Copyright © 1997 Wiley-Liss, Inc.},
	issn = {1097-0029},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/(SICI)1097-0029(19970201)36:3<188::AID-JEMT7>3.0.CO;2-L/abstract},
	doi = {10.1002/(SICI)1097-0029(19970201)36:3<188::AID-JEMT7>3.0.CO;2-L},
	abstract = {The aims of the study were to write an image analysis (IA) program allowing the stereological quantification of human epidermal melanocyte melanization at the ultrastructural level and to specify the suitable preparative methods, in keeping with IA limits and stereological principles. Micrographs of cultured human melanocytes obtained in transmission electron microscopy were digitized with a scanner. The key step of the designed IA program is a thresholding based on the gray levels. Hence, gray level histograms (pixel frequency as a function of gray level) of melanocyte images exhibit a peak specific to melanin. The gray level thresholding used consists in isolating the melanin pixels that form profiles on a binary image and in storing the numerical data produced for a given melanocyte profile. These primary data are used to calculate numerous parameters via stereology with melanocyte cytoplasm and melanized melanosome as main reference spaces. The most important stereological parameters obtained are v (mi,cy) (melanin volume per average cell), v (mi,m) (melanin volume per average melanized melanosome), and n m (number of melanized melanosomes per average cell), and their validity is discussed. Melanocytes embedded in situ were abandoned for stereological reasons but pelleted melanocytes were found suitable. Using this computerized tool and stereology, we are able to perform quantitative studies producing varied data even from small cell samples. To our knowledge, this is the first stereological approach for quantifying intracellular melanization. A quantitative comparison of spectrophotometrical results (melanin assay) with stereological results obtained in ultraviolet B-irradiated Caucasian epidermal melanocytes will be performed in order to appraise this method. Microsc. Res. Tech. 36:188–200, 1997. © 1997 Wiley-Liss, Inc.},
	language = {en},
	number = {3},
	urldate = {2014-12-09},
	journal = {Microscopy Research and Technique},
	author = {Donois, Eric and Freund, Olivier and Surlève-Bazeille, Jean-Étienne and Taïeb, Alain},
	month = feb,
	year = {1997},
	keywords = {eu- and pheomelanin, intracellular melanization, melanosomal maturation},
	pages = {188--200},
	file = {Snapshot:/home/edecenciere/Zotero/storage/66DZC7PI/abstract.html:text/html},
}

@article{koh_cigarette_2002,
	title = {Cigarette smoking associated with premature facial wrinkling: image analysis of facial skin replicas},
	volume = {41},
	issn = {1365-4632},
	shorttitle = {Cigarette smoking associated with premature facial wrinkling},
	url = {http://onlinelibrary.wiley.com/doi/10.1046/j.1365-4362.2002.01352.x/abstract},
	doi = {10.1046/j.1365-4362.2002.01352.x},
	abstract = {Background Despite the obvious relation between smoking and facial wrinkling, grossly undetectable wrinkling and the consequences of smoking on the face have been poorly studied. Objective To assess the risk factor of cigarette smoking on the development of premature facial wrinkling. Methods One hundred and twenty-three nonsmokers, 160 current smokers, and 67 past smokers, aged 20–69 years, were studied. Cigarette smoking status, weight changes, average sun exposure time (recreational and occupational) in 1 month, and past medical and facial cosmetic surgery were quantified by self-questionnaire. Computerized image analysis of silicone skin replicas was used in addition to clinical visual measurement, and a severity score based on predetermined criteria was assigned to each patient. Results Current smokers have a higher degree of facial wrinkling than nonsmokers and past smokers. Past smokers who smoked heavily at a younger age show less facial wrinkling than current smokers. In the analysis, which was adjusted for age group, the relative risk of moderate to severe wrinkling for current smokers compared with nonsmokers was 2.72 (confidence interval, CI: 1.32–3.21, P {\textless} 0.05). In current smokers, the relative risks associated with more than 19 pack-years and 11–19 pack-years of smoking compared with nonsmokers were 2.93 (CI: 1.14–4.1, P {\textless} 0.05) and 1.75 (CI: 1.54–3.67, P {\textless} 0.05), respectively. On image analysis of facial skin replicas, the mean values of Ra (arithmetic average roughness), Rz (average roughness), and Rt (distance between the highest and lowest values) of current smokers were higher than those of nonsmokers and past smokers in all age groups. This indicates a strong correlation between cigarette smoking and skin wrinkling. In addition, microscopic superficial wrinkling (Ra and Rt) was noted in current smokers in the younger age group (20–39 years). Conclusions This study suggests that attention should be paid to smoking-associated facial wrinkling (not evident from a visual assessment) in young people and added to the list of disorders seemingly caused by smoking.},
	language = {en},
	number = {1},
	urldate = {2014-12-05},
	journal = {International Journal of Dermatology},
	author = {Koh, Jae Sook and Kang, Hoon and Choi, Sung Woo and Kim, Hyung Ok},
	month = jan,
	year = {2002},
	pages = {21--27},
	file = {Snapshot:/home/edecenciere/Zotero/storage/XS2D6DNZ/abstract\;jsessionid=65D0E28CEEC16C37C66D60A6541E8109.html:text/html},
}

@article{nouveau-richard_skin_2005,
	title = {Skin ageing: {A} comparison between {Chinese} and {European} populations: {A} pilot study},
	volume = {40},
	issn = {0923-1811},
	shorttitle = {Skin ageing},
	url = {http://www.sciencedirect.com/science/article/pii/S0923181105001738},
	doi = {10.1016/j.jdermsci.2005.06.006},
	abstract = {SummaryBackground
Although limited data are available, it is commonly considered that Europeans and Asians have different skin ageing features.
Objectives
The present studies have been carried out to evaluate the influence of age and sun-exposure on the main clinical signs of Asian skin ageing.
Methods
One hundred and sixty Chinese and 160 French age-matched women (age range: 20–60 years old) were clinically examined and scored by the same dermatologist. Facial wrinkles (crow's-feet, glabella and perioral wrinkles) and pigmented spots (on face and hands) were assessed in situ and standardized photographs of the face were taken. Lifelong sun-exposure was estimated from answers to a questionnaire. Comparisons were made between 10-year age groups.
Results
Results show that, for each facial skin area, wrinkle onset is delayed by about 10 years in Chinese women as compared to French women. Facial wrinkling rate over the years is linear in French women and not linear in Chinese women who appear to experience a fast ageing process between age 40 and 50. Pigmented spot intensity is a much more important ageing sign in Chinese women (severe for 30\% of women over 40) than in French women (severe for less than 8\% of women, irrespective of age).
Conclusion
These first results underline that main skin ageing features (wrinkles, spots) progress differently in the Chinese and French women we have studied. They require to be confirmed on broad multicentre studies involving larger cohorts.},
	number = {3},
	urldate = {2014-12-05},
	journal = {Journal of Dermatological Science},
	author = {Nouveau-Richard, S. and Yang, Z. and Mac-Mary, S. and Li, L. and Bastien, P. and Tardy, I. and Bouillon, C. and Humbert, P. and de Lacharrière, O.},
	month = dec,
	year = {2005},
	keywords = {Ageing, Chinese, Spots, Wrinkles},
	pages = {187--193},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/XEBFZKRF/S0923181105001738.html:text/html},
}

@article{hoover_experimental_1996,
	title = {An experimental comparison of range image segmentation algorithms},
	volume = {18},
	issn = {0162-8828},
	doi = {10.1109/34.506791},
	abstract = {A methodology for evaluating range image segmentation algorithms is proposed. This methodology involves (1) a common set of 40 laser range finder images and 40 structured light scanner images that have manually specified ground truth and (2) a set of defined performance metrics for instances of correctly segmented, missed, and noise regions, over- and under-segmentation, and accuracy of the recovered geometry. A tool is used to objectively compare a machine generated segmentation against the specified ground truth. Four research groups have contributed to evaluate their own algorithm for segmenting a range image into planar patches.},
	number = {7},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Hoover, A. and Jean-Baptiste, G. and Jiang, X. and Flynn, P.J. and Bunke, H. and Goldgof, D.B. and Bowyer, K. and Eggert, D.W. and Fitzgibbon, A. and Fisher, R.B.},
	month = jul,
	year = {1996},
	keywords = {Image segmentation, image classification, Pixel, computer vision, Artificial Intelligence, Testing, Shape, Geometrical optics, Geometry, Laser noise, laser range finder images, laser ranging, Measurement standards, over-segmentation, performance metrics, planar patches, range image segmentation algorithms, recovered geometry, structured light scanner images, under-segmentation},
	pages = {673--689},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/8PT8NRZA/abs_all.html:text/html},
}

@article{hoffman_segmentation_1987,
	title = {Segmentation and {Classification} of {Range} {Images}},
	volume = {PAMI-9},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.1987.4767955},
	abstract = {The recognition of objects in three-dimensional space is a desirable capability of a computer vision system. Range images, which directly measure 3-D surface coordinates of a scene, are well suited for this task. In this paper we report a procedure to detect connected planar, convex, and concave surfaces of 3-D objects. This is accomplished in three stages. The first stage segments the range image into “surface patches” by a square error criterion clustering algorithm using surface points and associated surface normals. The second stage classifies these patches as planar, convex, or concave based on a non-parametric statistical test for trend, curvature values, and eigenvalue analysis. In the final stage, boundaries between adjacent surface patches are classified as crease or noncrease edges, and this information is used to merge compatible patches to produce reasonable faces of the object(s). This procedure has been successfully applied to a large number of real and synthetic images, four of which we present in this paper.},
	number = {5},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Hoffman, R. and Jain, Anil K.},
	month = sep,
	year = {1987},
	keywords = {Image segmentation, Face detection, object detection, computer vision, Layout, Testing, clustering, Clustering algorithms, Reflectivity, curvature, decision tree, eigenvalues, Eigenvalues and eigenfunctions, nonparametric statistical tests, range images, Surface fitting, surface normals, surface patches},
	pages = {608--620},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/RWTSVKHD/abs_all.html:text/html},
}

@inproceedings{ohtake_ridge-valley_2004,
	address = {New York, NY, USA},
	series = {{SIGGRAPH} '04},
	title = {Ridge-valley {Lines} on {Meshes} via {Implicit} {Surface} {Fitting}},
	url = {http://doi.acm.org/10.1145/1186562.1015768},
	doi = {10.1145/1186562.1015768},
	abstract = {We propose a simple and effective method for detecting view-and scale-independent ridge-valley lines defined via first- and second-order curvature derivatives on shapes approximated by dense triangle meshes. A high-quality estimation of high-order surface derivatives is achieved by combining multi-level implicit surface fitting and finite difference approximations. We demonstrate that the ridges and valleys are geometrically and perceptually salient surface features, and, therefore, can be potentially used for shape recognition, coding, and quality evaluation purposes.},
	urldate = {2014-12-04},
	booktitle = {{ACM} {SIGGRAPH} 2004 {Papers}},
	publisher = {ACM},
	author = {Ohtake, Yutaka and Belyaev, Alexander and Seidel, Hans-Peter},
	year = {2004},
	keywords = {curvature extrema, implicit surface fitting, ridges},
	pages = {609--612},
}

@inproceedings{yoshizawa_fast_2005,
	address = {New York, NY, USA},
	series = {{SPM} '05},
	title = {Fast and {Robust} {Detection} of {Crest} {Lines} on {Meshes}},
	isbn = {1-59593-015-9},
	url = {http://doi.acm.org/10.1145/1060244.1060270},
	doi = {10.1145/1060244.1060270},
	abstract = {We propose a fast and robust method for detecting crest lines on surfaces approximated by dense triangle meshes. The crest lines, salient surface features defined via first- and second-order curvature derivatives, are widely used for shape matching and interrogation purposes. Their practical extraction is difficult because it requires good estimation of high-order surface derivatives. Our approach to the crest line detection is based on estimating the curvature tensor and curvature derivatives via local polynomial fitting.Since the crest lines are not defined in the surface regions where the surface focal set (caustic) degenerates, we introduce a new thresholding scheme which exploits interesting relationships between curvature extrema, the so-called MVS functional of Moreton and Sequin, and Dupin cyclides,An application of the crest lines to adaptive mesh simplification is also considered.},
	urldate = {2014-12-04},
	booktitle = {Proceedings of the 2005 {ACM} {Symposium} on {Solid} and {Physical} {Modeling}},
	publisher = {ACM},
	author = {Yoshizawa, Shin and Belyaev, Alexander and Seidel, Hans-Peter},
	year = {2005},
	pages = {227--232},
}

@article{daniell_smokers_1971,
	title = {Smoker's {WrinklesA} {Study} in the {Epidemiology} of "{Crow}'s {Feet}"},
	volume = {75},
	issn = {0003-4819},
	url = {http://dx.doi.org/10.7326/0003-4819-75-6-873},
	doi = {10.7326/0003-4819-75-6-873},
	abstract = {A simple method of grading the severity of facial skin wrinkling is described. It can be rapidly learned and easily used by untrained students. In a study of 1,104 subjects the severity of wrinkling correlated with a history of habitual cigarette smoking, after adjustment for age and outdoor exposure. The association between cigarette smoking and wrinkling was striking in both sexes soon after age 30, was related to the duration and intensity of cigarette smoking, and was more pronounced than was the association between wrinkling and admitted outdoor exposure. Smokers in the 40- to 49-year age group were as likely to be prominently wrinkled as nonsmokers who were 20 years older.},
	number = {6},
	urldate = {2014-12-04},
	journal = {Annals of Internal Medicine},
	author = {DANIELL, HARRY W.},
	month = dec,
	year = {1971},
	pages = {873--880},
}

@article{daniell_smokers_1971-1,
	title = {Smoker's {WrinklesA} {Study} in the {Epidemiology} of "{Crow}'s {Feet}"},
	volume = {75},
	issn = {0003-4819},
	url = {http://dx.doi.org/10.7326/0003-4819-75-6-873},
	doi = {10.7326/0003-4819-75-6-873},
	abstract = {A simple method of grading the severity of facial skin wrinkling is described. It can be rapidly learned and easily used by untrained students. In a study of 1,104 subjects the severity of wrinkling correlated with a history of habitual cigarette smoking, after adjustment for age and outdoor exposure. The association between cigarette smoking and wrinkling was striking in both sexes soon after age 30, was related to the duration and intensity of cigarette smoking, and was more pronounced than was the association between wrinkling and admitted outdoor exposure. Smokers in the 40- to 49-year age group were as likely to be prominently wrinkled as nonsmokers who were 20 years older.},
	number = {6},
	urldate = {2014-12-04},
	journal = {Annals of Internal Medicine},
	author = {DANIELL, HARRY W.},
	month = dec,
	year = {1971},
	pages = {873--880},
}

@article{mimaroglu_combining_2011,
	title = {Combining multiple clusterings using similarity graph},
	volume = {44},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320310004486},
	doi = {10.1016/j.patcog.2010.09.008},
	abstract = {Multiple clusterings are produced for various needs and reasons in both distributed and local environments. Combining multiple clusterings into a final clustering which has better overall quality has gained importance recently. It is also expected that the final clustering is novel, robust, and scalable. In order to solve this challenging problem we introduce a new graph-based method. Our method uses the evidence accumulated in the previously obtained clusterings, and produces a very good quality final clustering. The number of clusters in the final clustering is obtained automatically; this is another important advantage of our technique. Experimental test results on real and synthetically generated data sets demonstrate the effectiveness of our new method.},
	number = {3},
	urldate = {2014-12-04},
	journal = {Pattern Recognition},
	author = {Mimaroglu, Selim and Erdil, Ertunc},
	month = mar,
	year = {2011},
	keywords = {clustering, Cluster ensemble, Combining clustering partitions, Evidence accumulation, mutual information, Robust clustering},
	pages = {694--703},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/MU7FJ2RA/S0031320310004486.html:text/html},
}

@article{iam-on_link-based_2011,
	title = {A {Link}-{Based} {Approach} to the {Cluster} {Ensemble} {Problem}},
	volume = {33},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2011.84},
	abstract = {Cluster ensembles have recently emerged as a powerful alternative to standard cluster analysis, aggregating several input data clusterings to generate a single output clustering, with improved robustness and stability. From the early work, these techniques held great promise; however, most of them generate the final solution based on incomplete information of a cluster ensemble. The underlying ensemble-information matrix reflects only cluster-data point relations, while those among clusters are generally overlooked. This paper presents a new link-based approach to improve the conventional matrix. It achieves this using the similarity between clusters that are estimated from a link network model of the ensemble. In particular, three new link-based algorithms are proposed for the underlying similarity assessment. The final clustering result is generated from the refined matrix using two different consensus functions of feature-based and graph-based partitioning. This approach is the first to address and explicitly employ the relationship between input partitions, which has not been emphasized by recent studies of matrix refinement. The effectiveness of the link-based approach is empirically demonstrated over 10 data sets (synthetic and real) and three benchmark evaluation measures. The results suggest the new approach is able to efficiently extract information embedded in the input clusterings, and regularly illustrate higher clustering quality in comparison to several state-of-the-art techniques.},
	number = {12},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Iam-On, N. and Boongoen, T. and Garrett, S. and Price, C.},
	month = dec,
	year = {2011},
	keywords = {Data mining, data mining., clustering, Clustering algorithms, pattern clustering, Partitioning algorithms, cluster ensemble problem, Cluster ensembles, cluster relations, conventional matrix, data clusterings, feature based partitioning, graph based partitioning, graph theory, link based approach, link-based similarity, matrix algebra, output clustering},
	pages = {2396--2409},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/VSAQGAIK/abs_all.html:text/html},
}

@article{ayad_cumulative_2008,
	title = {Cumulative {Voting} {Consensus} {Method} for {Partitions} with {Variable} {Number} of {Clusters}},
	volume = {30},
	issn = {0162-8828},
	url = {http://europepmc.org/abstract/MED/18000332},
	doi = {10.1109/TPAMI.2007.1138},
	number = {1},
	urldate = {2014-12-04},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Ayad, H.G. and Kamel, M.S.},
	month = jan,
	year = {2008},
	pages = {160--173},
	file = {Cumulative voting consensus method for partitions with variable number of clusters. - Abstract - Europe PubMed Central:/home/edecenciere/Zotero/storage/IPZT55MI/18000332.html:text/html},
}

@article{singh_ensemble_2010,
	title = {Ensemble clustering using semidefinite programming with applications},
	volume = {79},
	issn = {0885-6125, 1573-0565},
	url = {http://link.springer.com/article/10.1007/s10994-009-5158-y},
	doi = {10.1007/s10994-009-5158-y},
	abstract = {In this paper, we study the ensemble clustering problem, where the input is in the form of multiple clustering solutions. The goal of ensemble clustering algorithms is to aggregate the solutions into one solution that maximizes the agreement in the input ensemble. We obtain several new results for this problem. Specifically, we show that the notion of agreement under such circumstances can be better captured using a 2D string encoding rather than a voting strategy, which is common among existing approaches. Our optimization proceeds by first constructing a non-linear objective function which is then transformed into a 0-1 Semidefinite program (SDP) using novel convexification techniques. This model can be subsequently relaxed to a polynomial time solvable SDP. In addition to the theoretical contributions, our experimental results on standard machine learning and synthetic datasets show that this approach leads to improvements not only in terms of the proposed agreement measure but also the existing agreement measures based on voting strategies. In addition, we identify several new application scenarios for this problem. These include combining multiple image segmentations and generating tissue maps from multiple-channel Diffusion Tensor brain images to identify the underlying structure of the brain.},
	language = {en},
	number = {1-2},
	urldate = {2014-12-04},
	journal = {Machine Learning},
	author = {Singh, Vikas and Mukherjee, Lopamudra and Peng, Jiming and Xu, Jinhui},
	month = may,
	year = {2010},
	keywords = {Artificial Intelligence (incl. Robotics), Computing Methodologies, Language Translation and Linguistics, Simulation and Modeling, Cluster ensembles, Control , Robotics, Mechatronics, Ensemble clustering, Segmentation aggregation, Semidefinite programming},
	pages = {177--200},
	file = {Snapshot:/home/edecenciere/Zotero/storage/W5NQUW26/s10994-009-5158-y.html:text/html},
}

@article{strehl_cluster_2003,
	title = {Cluster {Ensembles} — a {Knowledge} {Reuse} {Framework} for {Combining} {Multiple} {Partitions}},
	volume = {3},
	issn = {1532-4435},
	url = {http://dx.doi.org/10.1162/153244303321897735},
	doi = {10.1162/153244303321897735},
	abstract = {This paper introduces the problem of combining multiple partitionings of a set of objects into a single consolidated clustering without accessing the features or algorithms that determined these partitionings. We first identify several application scenarios for the resultant 'knowledge reuse' framework that we call cluster ensembles. The cluster ensemble problem is then formalized as a combinatorial optimization problem in terms of shared mutual information. In addition to a direct maximization approach, we propose three effective and efficient techniques for obtaining high-quality combiners (consensus functions). The first combiner induces a similarity measure from the partitionings and then reclusters the objects. The second combiner is based on hypergraph partitioning. The third one collapses groups of clusters into meta-clusters which then compete for each object to determine the combined clustering. Due to the low computational costs of our techniques, it is quite feasible to use a supra-consensus function that evaluates all three approaches against the objective function and picks the best solution for a given situation. We evaluate the effectiveness of cluster ensembles in three qualitatively different application scenarios: (i) where the original clusters were formed based on non-identical sets of features, (ii) where the original clustering algorithms worked on non-identical sets of objects, and (iii) where a common data-set is used and the main purpose of combining multiple clusterings is to improve the quality and robustness of the solution. Promising results are obtained in all three situations for synthetic as well as real data-sets.},
	urldate = {2014-12-04},
	journal = {J. Mach. Learn. Res.},
	author = {Strehl, Alexander and Ghosh, Joydeep},
	month = mar,
	year = {2003},
	keywords = {unsupervised learning, Cluster Analysis, clustering, ensemble, mutual information, consensus functions, knowledge reuse, multi-learner systems, partitioning},
	pages = {583--617},
}

@article{cho_image_1997,
	title = {Image {Segmentation} from {Consensus} {Information}},
	volume = {68},
	issn = {1077-3142},
	url = {http://www.sciencedirect.com/science/article/pii/S1077314297905464},
	doi = {10.1006/cviu.1997.0546},
	abstract = {A new approach toward image segmentation is proposed. A set of slightly different segmentations is derived from the same input and the final result is based on the consensus among them. The perturbations are introduced by exploiting the probabilistic component of a region adjacency graph (RAG) pyramid-based segmentation. From the set of initial segmentations the cooccurrence probability field is obtained in which global information about the delineated regions becomes locally available. The final segmentation is based on this field and is obtained with the same hierarchical, RAG pyramid technique. No user set parameters or context-dependent thresholds are required.},
	number = {1},
	urldate = {2014-12-04},
	journal = {Computer Vision and Image Understanding},
	author = {Cho, Kyujin and Meer, Peter},
	month = oct,
	year = {1997},
	pages = {72--89},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/VJV3F247/S1077314297905464.html:text/html},
}

@article{schmitt_strong_1994,
	title = {Strong and weak convex hulls in non-{Euclidean} metric: theory and application},
	volume = {15},
	issn = {0167-8655},
	shorttitle = {Strong and weak convex hulls in non-{Euclidean} metric},
	url = {http://www.sciencedirect.com/science/article/pii/0167865594901570},
	doi = {10.1016/0167-8655(94)90157-0},
	abstract = {The notion of convexity is usually defined in the plane supplied with the Euclidean metric. This paper examines what remains if we equip the plane with a distance induced by a norm which is not necessarily the Euclidean one. The basic properties of the geodesic arcs according to these non-Euclidean metrics are stated. In some cases there exists more than one geodesic arc between two points. The two associated notions of convexity, both strong and weak, are the presented. The relationships between the notion of weak convex hull and the limit of closings of increasing size are stated. Finally an application in binary image pattern recognition is described.},
	number = {9},
	urldate = {2014-11-21},
	journal = {Pattern Recognition Letters},
	author = {Schmitt, Michel and Mattioli, Juliette},
	month = sep,
	year = {1994},
	keywords = {mathematical morphology, Convexity, Geodesic arcs, Morphological closing, Weakly convex hull},
	pages = {943--947},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/PF5HJHAS/0167865594901570.html:text/html},
}

@article{schmitt_strong_1994-1,
	title = {Strong and weak convex hulls in non-{Euclidean} metric: theory and application},
	volume = {15},
	issn = {0167-8655},
	shorttitle = {Strong and weak convex hulls in non-{Euclidean} metric},
	url = {http://www.sciencedirect.com/science/article/pii/0167865594901570},
	doi = {10.1016/0167-8655(94)90157-0},
	abstract = {The notion of convexity is usually defined in the plane supplied with the Euclidean metric. This paper examines what remains if we equip the plane with a distance induced by a norm which is not necessarily the Euclidean one. The basic properties of the geodesic arcs according to these non-Euclidean metrics are stated. In some cases there exists more than one geodesic arc between two points. The two associated notions of convexity, both strong and weak, are the presented. The relationships between the notion of weak convex hull and the limit of closings of increasing size are stated. Finally an application in binary image pattern recognition is described.},
	number = {9},
	urldate = {2014-11-21},
	journal = {Pattern Recognition Letters},
	author = {Schmitt, Michel and Mattioli, Juliette},
	month = sep,
	year = {1994},
	keywords = {mathematical morphology, Convexity, Geodesic arcs, Morphological closing, Weakly convex hull},
	pages = {943--947},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/VTGZ6SGW/0167865594901570.html:text/html},
}

@inproceedings{tepper_fast_2013,
	title = {Fast {L1} smoothing splines with an application to {Kinect} depth data},
	doi = {10.1109/ICIP.2013.6738104},
	abstract = {Splines are a popular and attractive way of smoothing noisy data. Computing splines involves minimizing a functional which is a linear combination of a fitting term and a regularization term. The former is classically computed using a (sometimes weighted) L2 norm while the latter ensures smoothness. In this work we propose to replace the L2 norm in the fitting term with an L1 norm, leading to automatic robustness to outliers. To solve the resulting minimization problem we propose an extremely simple and efficient numerical scheme based on split-Bregman iteration and a DCT-based filter. The algorithm is applied to the problem of smoothing and impainting range data, where high-quality results are obtained in short processing times.},
	booktitle = {2013 20th {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	author = {Tepper, M. and Sapiro, G.},
	month = sep,
	year = {2013},
	keywords = {image reconstruction, Robustness, filtering theory, iterative methods, Noise, Convergence, DCT-based filter, discrete cosine transforms, fast L1 smoothing splines, fitting term, functional analysis, functional minimization, grid data, Kinect depth data, L1 norm, minimisation, Optical imaging, range data impainting, range data smoothing, regularization term, robust fitting, smoothing methods, Splines, splines (mathematics), split-Bregman, split-Bregman iteration},
	pages = {504--508},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/K9VMW73G/articleDetails.html:text/html},
}

@article{decenciere_feedback_2014,
	title = {{FEEDBACK} {ON} {A} {PUBLICLY} {DISTRIBUTED} {IMAGE} {DATABASE}: {THE} {MESSIDOR} {DATABASE}},
	volume = {33},
	copyright = {Copyright (c) 2014 Image Analysis \& Stereology},
	issn = {1854-5165},
	shorttitle = {{FEEDBACK} {ON} {A} {PUBLICLY} {DISTRIBUTED} {IMAGE} {DATABASE}},
	url = {http://www.ias-iss.org/ojs/IAS/article/view/1155},
	doi = {10.5566/ias.1155},
	abstract = {The Messidor database, which contains hundreds of eye fundus images, has been publicly distributed since 2008. It was created by the Messidor project in order to evaluate automatic lesion segmentation and diabetic retinopathy grading methods. Designing, producing and maintaining such a database entails significant costs. By publicly sharing it, one hopes to bring a valuable resource to the public research community. However, the real interest and benefit of the research community is not easy to quantify. We analyse here the feedback on the Messidor database, after more than 6 years of diffusion. This analysis should apply to other similar research databases.},
	language = {en},
	number = {3},
	urldate = {2014-11-20},
	journal = {Image Analysis \& Stereology},
	author = {Decencière, Etienne and Zhang, Xiwei and Cazuguel, Guy and Lay, Bruno and Cochener, Béatrice and Trone, Caroline and Gain, Philippe and Ordonez, Richard and Massin, Pascale and Erginay, Ali and Charton, Béatrice and Klein, Jean-Claude},
	month = aug,
	year = {2014},
	keywords = {Diabetic Retinopathy, Image Processing, image database, Messidor},
	pages = {231--234},
	file = {Snapshot:/home/edecenciere/Zotero/storage/CI7Q85XF/1155.html:text/html},
}

@article{vincent_watersheds_1991-1,
	title = {Watersheds in digital spaces: an efficient algorithm based on immersion simulations},
	volume = {13},
	issn = {0162-8828},
	shorttitle = {Watersheds in digital spaces},
	doi = {10.1109/34.87344},
	abstract = {A fast and flexible algorithm for computing watersheds in digital gray-scale images is introduced. A review of watersheds and related motion is first presented, and the major methods to determine watersheds are discussed. The algorithm is based on an immersion process analogy, in which the flooding of the water in the picture is efficiently simulated using of queue of pixel. It is described in detail provided in a pseudo C language. The accuracy of this algorithm is proven to be superior to that of the existing implementations, and it is shown that its adaptation to any kind of digital grid and its generalization to n-dimensional images (and even to graphs) are straightforward. The algorithm is reported to be faster than any other watershed algorithm. Applications of this algorithm with regard to picture segmentation are presented for magnetic resonance (MR) imagery and for digital elevation models. An example of 3-D watershed is also provided},
	number = {6},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Vincent, L. and Soille, P.},
	month = jun,
	year = {1991},
	keywords = {Image segmentation, Image Processing, Morphology, Digital images, Gray-scale, Computational modeling, computerised picture processing, digital elevation models, digital gray-scale images, Floods, magnetic resonance imagery, Oceans, picture segmentation, pseudo C language, Surfaces, watersheds},
	pages = {583--598},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/XQ4T397W/articleDetails.html:text/html},
}

@inproceedings{dolz_combining_2014,
	title = {Combining watershed and graph cuts methods to segment organs at risk in radiotherapy},
	volume = {9034},
	url = {http://dx.doi.org/10.1117/12.2042768},
	doi = {10.1117/12.2042768},
	abstract = {Computer-aided segmentation of anatomical structures in medical images is a valuable tool for efficient radiation therapy planning (RTP). As delineation errors highly affect the radiation oncology treatment, it is crucial to delineate geometric structures accurately. In this paper, a semi-automatic segmentation approach for computed tomography (CT) images, based on watershed and graph-cuts methods, is presented. The watershed pre-segmentation groups small areas of similar intensities in homogeneous labels, which are subsequently used as input for the graph-cuts algorithm. This methodology does not require of prior knowledge of the structure to be segmented; even so, it performs well with complex shapes and low intensity. The presented method also allows the user to add foreground and background strokes in any of the three standard orthogonal views – axial, sagittal or coronal - making the interaction with the algorithm easy and fast. Hence, the segmentation information is propagated within the whole volume, providing a spatially coherent result. The proposed algorithm has been evaluated using 9 CT volumes, by comparing its segmentation performance over several organs - lungs, liver, spleen, heart and aorta - to those of manual delineation from experts. A Dice´s coefficient higher than 0.89 was achieved in every case. That demonstrates that the proposed approach works well for all the anatomical structures analyzed. Due to the quality of the results, the introduction of the proposed approach in the RTP process will be a helpful tool for organs at risk (OARs) segmentation.},
	urldate = {2014-05-02},
	author = {Dolz, Jose and Kirisli, Hortense A. and Viard, Romain and Massoptier, Laurent},
	year = {2014},
	pages = {90343Z--90343Z--7},
}

@article{heijmans_composing_1997,
	title = {Composing morphological filters},
	volume = {6},
	issn = {1057-7149},
	doi = {10.1109/83.568928},
	abstract = {A morphological filter is an operator on a complete lattice that is increasing and idempotent. Two well-known classes of morphological filters are openings and closings. Furthermore, an interesting class of filters, the alternating sequential filters, is obtained if one composes openings and closings. This paper explains how to construct morphological filters, and derived notions such as overfilters, underfilters, inf-overfilters, and sup-underfilters by composition, the main ingredients being dilations, erosions, openings, and closings. The class of alternating sequential filters is extended by composing overfilters and underfilters. Finally, it is shown that any composition consisting of an equal number of dilations and erosions from an adjunction is a filter. The abstract approach is illustrated with some experimental results},
	number = {5},
	journal = {IEEE Transactions on Image Processing},
	author = {Heijmans, H. J A M},
	month = may,
	year = {1997},
	keywords = {Filters, filtering theory, Image Processing, mathematical morphology, Morphology, adjunction, alternating sequential filter, closings, construction, digital filters, dilations, erosions, inf-overfilters, lattice, lattice filters, Lattices, mathematical operators, morphological filters, openings, overfilters, sup-underfilters, underfilter, Upper bound},
	pages = {713--723},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/9VQM5WAH/abs_all.html:text/html},
}

@article{giancardo_exudate-based_2012,
	title = {Exudate-based diabetic macular edema detection in fundus images using publicly available datasets},
	volume = {16},
	issn = {1361-8415},
	url = {http://www.sciencedirect.com/science/article/pii/S1361841511001010},
	doi = {10.1016/j.media.2011.07.004},
	abstract = {Diabetic macular edema (DME) is a common vision threatening complication of diabetic retinopathy. In a large scale screening environment DME can be assessed by detecting exudates (a type of bright lesions) in fundus images. In this work, we introduce a new methodology for diagnosis of DME using a novel set of features based on colour, wavelet decomposition and automatic lesion segmentation. These features are employed to train a classifier able to automatically diagnose DME through the presence of exudation. We present a new publicly available dataset with ground-truth data containing 169 patients from various ethnic groups and levels of DME. This and other two publicly available datasets are employed to evaluate our algorithm. We are able to achieve diagnosis performance comparable to retina experts on the MESSIDOR (an independently labelled dataset with 1200 images) with cross-dataset testing (e.g., the classifier was trained on an independent dataset and tested on MESSIDOR). Our algorithm obtained an AUC between 0.88 and 0.94 depending on the dataset/features used. Additionally, it does not need ground truth at lesion level to reject false positives and is computationally efficient, as it generates a diagnosis on an average of 4.4 s (9.3 s, considering the optic nerve localisation) per image on an 2.6 GHz platform with an unoptimised Matlab implementation.},
	number = {1},
	urldate = {2014-02-25},
	journal = {Medical Image Analysis},
	author = {Giancardo, Luca and Meriaudeau, Fabrice and Karnowski, Thomas P. and Li, Yaqin and Garg, Seema and Tobin Jr., Kenneth W. and Chaum, Edward},
	month = jan,
	year = {2012},
	keywords = {Feature extraction, Automatic diagnosis, Exudates segmentation, Lesion probability, Wavelets},
	pages = {216--226},
	file = {ScienceDirect Snapshot:/home/edecenciere/Zotero/storage/W5BDI2XM/S1361841511001010.html:text/html},
}

@article{niemeijer_retinopathy_2010,
	title = {Retinopathy {Online} {Challenge}: {Automatic} {Detection} of {Microaneurysms} in {Digital} {Color} {Fundus} {Photographs}},
	volume = {29},
	issn = {0278-0062},
	shorttitle = {Retinopathy {Online} {Challenge}},
	doi = {10.1109/TMI.2009.2033909},
	abstract = {The detection of microaneurysms in digital color fundus photographs is a critical first step in automated screening for diabetic retinopathy (DR), a common complication of diabetes. To accomplish this detection numerous methods have been published in the past but none of these was compared with each other on the same data. In this work we present the results of the first international microaneurysm detection competition, organized in the context of the Retinopathy Online Challenge (ROC), a multiyear online competition for various aspects of DR detection. For this competition, we compare the results of five different methods, produced by five different teams of researchers on the same set of data. The evaluation was performed in a uniform manner using an algorithm presented in this work. The set of data used for the competition consisted of 50 training images with available reference standard and 50 test images where the reference standard was withheld by the organizers (M. Niemeijer, B. van Ginneken, and M. D. AbrA??moff). The results obtained on the test data was submitted through a website after which standardized evaluation software was used to determine the performance of each of the methods. A human expert detected microaneurysms in the test set to allow comparison with the performance of the automatic methods. The overall results show that microaneurysm detection is a challenging task for both the automatic methods as well as the human expert. There is room for improvement as the best performing system does not reach the performance of the human expert. The data associated with the ROC microaneurysm detection competition will remain publicly available and the website will continue accepting submissions.},
	number = {1},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Niemeijer, M. and van Ginneken, B. and Cree, M.J. and Mizutani, A. and Quellec, G. and Sanchez, C.I. and Zhang, B. and Hornero, R. and Lamard, M. and Muramatsu, C. and Wu, Xiangqian and Cazuguel, G. and You, J. and Mayo, A. and Li, Qin and Hatanaka, Y. and Cochener, B. and Roux, C. and Karray, F. and Garcia, M. and Fujita, H. and Abramoff, M.D.},
	month = jan,
	year = {2010},
	keywords = {Algorithms, Humans, medical image processing, Databases, Factual, Diabetes, Diabetic Retinopathy, eye, Retina, Retinal Vessels, Retinopathy, Biomedical imaging, Retinal Diseases, diseases, Fundus Oculi, Photography, Aneurysm, Diagnostic Techniques, Ophthalmological, False Positive Reactions, Cities and towns, Statistics, automated screening, automatic microaneurysm detection, Bayes Theorem, Biomedical engineering, Blindness, Computer aided detection, computer aided diagnosis, digital color fundus photograph, digital photography, fundus photographs, microaneurysms, multiyear online competition, Retinopathy Online Challenge, Retinopathy Online Challenge (ROC) competition, ROC Curve, Systems engineering and theory, Telecommunications, USA Councils},
	pages = {185--195},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/DMWNX6AJ/login.html:text/html},
}

@article{mahmood_deep_2018,
	title = {Deep {Adversarial} {Training} for {Multi}-{Organ} {Nuclei} {Segmentation} in {Histopathology} {Images}},
	url = {http://arxiv.org/abs/1810.00236},
	abstract = {Nuclei segmentation is a fundamental task that is critical for various computational pathology applications including nuclei morphology analysis, cell type classification, and cancer grading. Conventional vision-based methods for nuclei segmentation struggle in challenging cases and deep learning approaches have proven to be more robust and generalizable. However, CNNs require large amounts of labeled histopathology data. Moreover, conventional CNN-based approaches lack structured prediction capabilities which are required to distinguish overlapping and clumped nuclei. Here, we present an approach to nuclei segmentation that overcomes these challenges by utilizing a conditional generative adversarial network (cGAN) trained with synthetic and real data. We generate a large dataset of H\&E training images with perfect nuclei segmentation labels using an unpaired GAN framework. This synthetic data along with real histopathology data from six different organs are used to train a conditional GAN with spectral normalization and gradient penalty for nuclei segmentation. This adversarial regression framework enforces higher order consistency when compared to conventional CNN models. We demonstrate that this nuclei segmentation approach generalizes across different organs, sites, patients and disease states, and outperforms conventional approaches, especially in isolating individual and overlapping nuclei.},
	urldate = {2019-01-11},
	journal = {arXiv:1810.00236 [cs]},
	author = {Mahmood, Faisal and Borders, Daniel and Chen, Richard and McKay, Gregory N. and Salimian, Kevan J. and Baras, Alexander and Durr, Nicholas J.},
	month = sep,
	year = {2018},
	note = {arXiv: 1810.00236},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{pessoa_neural_2000,
	title = {Neural networks with hybrid morphological/rank/linear nodes: a unifying framework with applications to handwritten character recognition},
	volume = {33},
	shorttitle = {Neural networks with hybrid morphological/rank/linear nodes},
	number = {6},
	journal = {Pattern Recognition},
	author = {Pessoa, Lucio FC and Maragos, Petros},
	year = {2000},
	pages = {945--960},
}

@inproceedings{pessoa_morphological/rank_1996,
	title = {Morphological/rank neural networks and their adaptive optimal design for image processing},
	volume = {6},
	booktitle = {Acoustics, {Speech}, and {Signal} {Processing}, 1996. {ICASSP}-96. {Conference} {Proceedings}., 1996 {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Pessoa, Lucio FC and Maragos, Petros},
	year = {1996},
	pages = {3398--3401},
}

@article{sussner_morphological_2011,
	title = {Morphological perceptrons with competitive learning: {Lattice}-theoretical framework and constructive learning algorithm},
	volume = {181},
	shorttitle = {Morphological perceptrons with competitive learning},
	number = {10},
	journal = {Information Sciences},
	author = {Sussner, Peter and Esmi, Estevão Laureano},
	year = {2011},
	pages = {1929--1950},
}

@article{ritter_lattice_2003,
	title = {Lattice algebra approach to single-neuron computation},
	volume = {14},
	number = {2},
	journal = {IEEE Transactions on Neural Networks},
	author = {Ritter, Gerhard X. and Urcid, Gonzalo},
	year = {2003},
	pages = {282--295},
}

@inproceedings{wilson_morphological_1989,
	title = {Morphological networks},
	volume = {1199},
	booktitle = {Visual {Communications} and {Image} {Processing} {IV}},
	publisher = {International Society for Optics and Photonics},
	author = {Wilson, Stephen S.},
	year = {1989},
	pages = {483--496},
}

@inproceedings{davidson_theory_1990,
	title = {Theory of morphological neural networks},
	volume = {1215},
	booktitle = {Digital {Optical} {Computing} {II}},
	publisher = {International Society for Optics and Photonics},
	author = {Davidson, Jennifer L. and Ritter, Gerhard X.},
	year = {1990},
	pages = {378--389},
}

@inproceedings{ritter_introduction_1996,
	title = {An introduction to morphological neural networks},
	volume = {4},
	booktitle = {Pattern {Recognition}, 1996., {Proceedings} of the 13th {International} {Conference} on},
	publisher = {IEEE},
	author = {Ritter, Gerhard X. and Sussner, Peter},
	year = {1996},
	pages = {709--717},
}

@inproceedings{rastegari_xnor-net:_2016,
	title = {Xnor-net: {Imagenet} classification using binary convolutional neural networks},
	shorttitle = {Xnor-net},
	booktitle = {European {Conference} on {Computer} {Vision}},
	publisher = {Springer},
	author = {Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph and Farhadi, Ali},
	year = {2016},
	pages = {525--542},
}

@article{howard_mobilenets:_2017,
	title = {Mobilenets: {Efficient} convolutional neural networks for mobile vision applications},
	shorttitle = {Mobilenets},
	journal = {arXiv preprint arXiv:1704.04861},
	author = {Howard, Andrew G. and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
	year = {2017},
}

@article{chollet_xception:_2017,
	title = {Xception: {Deep} learning with depthwise separable convolutions},
	shorttitle = {Xception},
	journal = {arXiv preprint},
	author = {Chollet, François},
	year = {2017},
	pages = {1610--02357},
}

@techreport{ronse_regular_1990,
	address = {Brussels, Belgium},
	type = {Working document},
	title = {Regular open or closed sets},
	number = {WD59},
	institution = {Philips Research Lab.},
	author = {Ronse, Christian},
	year = {1990},
}

@inproceedings{zhao_uniqueness-driven_2018,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Uniqueness-{Driven} {Saliency} {Analysis} for {Automated} {Lesion} {Detection} with {Applications} to {Retinal} {Diseases}},
	isbn = {978-3-030-00934-2},
	abstract = {Saliency is important in medical image analysis in terms of detection and segmentation tasks. We propose a new method to extract uniqueness-driven saliency based on the uniqueness of intensity and spatial distributions within the images. The main novelty of this new saliency feature is that it is powerful in the detection of different types of lesions in different types of images without the need of tuning parameters for different problems. To evaluate its effectiveness, we have applied our method to the detection lesions of retinal images. Four different types of lesions: exudate, hemorrhage, microaneurysms and leakage from 7 independent public retinal image datasets of diabetic retinopathy and malarial retinopathy, were studied and the experimental results show that the proposed method is superior to the state-of-the-art methods.},
	language = {en},
	booktitle = {Medical {Image} {Computing} and {Computer} {Assisted} {Intervention} – {MICCAI} 2018},
	publisher = {Springer International Publishing},
	author = {Zhao, Yitian and Zheng, Yalin and Zhao, Yifan and Liu, Yonghuai and Chen, Zhili and Liu, Peng and Liu, Jiang},
	editor = {Frangi, Alejandro F. and Schnabel, Julia A. and Davatzikos, Christos and Alberola-López, Carlos and Fichtinger, Gabor},
	year = {2018},
	keywords = {Retinopathy, Computer aided-diagnosis, Saliency, Uniqueness},
	pages = {109--118},
}

@incollection{goodfellow_generative_2014,
	title = {Generative {Adversarial} {Nets}},
	url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf},
	urldate = {2018-11-30},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 27},
	publisher = {Curran Associates, Inc.},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	year = {2014},
	pages = {2672--2680},
}

@incollection{goodfellow_generative_2014-1,
	title = {Generative {Adversarial} {Nets}},
	url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 27},
	publisher = {Curran Associates, Inc.},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. D. and Weinberger, K. Q.},
	year = {2014},
	pages = {2672--2680},
}

@article{mcculloch_logical_1943,
	title = {A logical calculus of the ideas immanent in nervous activity},
	volume = {5},
	issn = {1522-9602},
	url = {https://doi.org/10.1007/BF02478259},
	doi = {10.1007/BF02478259},
	abstract = {Because of the “all-or-none” character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.},
	language = {en},
	number = {4},
	urldate = {2018-11-30},
	journal = {The bulletin of mathematical biophysics},
	author = {McCulloch, Warren S. and Pitts, Walter},
	month = dec,
	year = {1943},
	keywords = {Excitatory Synapse, Inhibitory Synapse, Nervous Activity, Spatial Summation, Temporal Summation},
	pages = {115--133},
}

@article{lerme_fully_2016,
	series = {Special {Issue} on {ICPR} 2014 {Awarded} {Papers}},
	title = {A fully automatic method for segmenting retinal artery walls in adaptive optics images},
	volume = {72},
	issn = {0167-8655},
	url = {http://www.sciencedirect.com/science/article/pii/S0167865515003621},
	doi = {10.1016/j.patrec.2015.10.011},
	abstract = {Adaptive optics imaging of the retina has recently proven its capability to image micrometric structures such as blood vessels, involved in common ocular diseases. In this paper, we propose an approach for automatically segmenting the walls of retinal arteries in the images acquired with this technology. The walls are modeled as four curves approximately parallel to a previously detected reference line located near the vessel center (axial reflection). These curves are first initialized using a tracking procedure and then more accurately positioned using an active contour model embedding a parallelism constraint. We consider both healthy and pathological subjects in the same framework and show that the proposed method applies in all cases. Extensive experiments are also proposed, by analyzing the robustness of the axial reflections detection, the influence of the tracking parameters as well as the performance of the tracking and the active contour model. Noticeably, the results show a good robustness for detecting axial reflections and a moderate influence of the tracking parameters. Compared to a naive initialization, the active contour model coupled with the tracking also offers faster convergence and better accuracy while keeping an overall error smaller or very near the inter-physicians error.},
	urldate = {2018-11-27},
	journal = {Pattern Recognition Letters},
	author = {Lermé, Nicolas and Rossant, Florence and Bloch, Isabelle and Paques, Michel and Koch, Edouard and Benesty, Jonathan},
	month = mar,
	year = {2016},
	keywords = {Mathematical morphology, Active contour model, Adaptive optics, Retina imaging},
	pages = {72--81},
}

@article{luc_semantic_2016,
	title = {Semantic {Segmentation} using {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1611.08408},
	abstract = {Adversarial training has been shown to produce state of the art results for generative image modeling. In this paper we propose an adversarial training approach to train semantic segmentation models. We train a convolutional semantic segmentation network along with an adversarial network that discriminates segmentation maps coming either from the ground truth or from the segmentation network. The motivation for our approach is that it can detect and correct higher-order inconsistencies between ground truth segmentation maps and the ones produced by the segmentation net. Our experiments show that our adversarial training approach leads to improved accuracy on the Stanford Background and PASCAL VOC 2012 datasets.},
	urldate = {2018-11-18},
	journal = {arXiv:1611.08408 [cs]},
	author = {Luc, Pauline and Couprie, Camille and Chintala, Soumith and Verbeek, Jakob},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.08408},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{zhang_exudate_2014,
	title = {Exudate detection in color retinal images for mass screening of diabetic retinopathy},
	volume = {18},
	issn = {1361-8415},
	url = {http://www.sciencedirect.com/science/article/pii/S1361841514000693},
	doi = {10.1016/j.media.2014.05.004},
	abstract = {The automatic detection of exudates in color eye fundus images is an important task in applications such as diabetic retinopathy screening. The presented work has been undertaken in the framework of the TeleOphta project, whose main objective is to automatically detect normal exams in a tele-ophthalmology network, thus reducing the burden on the readers. A new clinical database, e-ophtha EX, containing precisely manually contoured exudates, is introduced. As opposed to previously available databases, e-ophtha EX is very heterogeneous. It contains images gathered within the OPHDIAT telemedicine network for diabetic retinopathy screening. Image definition, quality, as well as patients condition or the retinograph used for the acquisition, for example, are subject to important changes between different examinations. The proposed exudate detection method has been designed for this complex situation. We propose new preprocessing methods, which perform not only normalization and denoising tasks, but also detect reflections and artifacts in the image. A new candidates segmentation method, based on mathematical morphology, is proposed. These candidates are characterized using classical features, but also novel contextual features. Finally, a random forest algorithm is used to detect the exudates among the candidates. The method has been validated on the e-ophtha EX database, obtaining an AUC of 0.95. It has been also validated on other databases, obtaining an AUC between 0.93 and 0.95, outperforming state-of-the-art methods.},
	number = {7},
	urldate = {2018-11-18},
	journal = {Medical Image Analysis},
	author = {Zhang, Xiwei and Thibault, Guillaume and Decencière, Etienne and Marcotegui, Beatriz and Laÿ, Bruno and Danno, Ronan and Cazuguel, Guy and Quellec, Gwénolé and Lamard, Mathieu and Massin, Pascale and Chabouis, Agnès and Victor, Zeynep and Erginay, Ali},
	month = oct,
	year = {2014},
	keywords = {Mathematical morphology, Exudates segmentation, Diabetic retinopathy screening, e-Ophtha EX database},
	pages = {1026--1043},
}

@inproceedings{girshick_rich_2014,
	title = {Rich {Feature} {Hierarchies} for {Accurate} {Object} {Detection} and {Semantic} {Segmentation}},
	url = {http://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.html},
	urldate = {2017-03-23},
	booktitle = {Proceedings {CVPR}},
	author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
	year = {2014},
	pages = {580--587},
}

@inproceedings{lecun_procedure_1985,
	title = {Une procedure d'apprentissage pour reseau a seuil asymmetrique ({A} learning scheme for asymmetric threshold networks)},
	url = {https://nyu.pure.elsevier.com/en/publications/une-procedure-dapprentissage-pour-reseau-a-seuil-asymmetrique-a-l},
	language = {English (US)},
	urldate = {2016-06-06},
	booktitle = {proceedings of {Cognitiva} 85},
	author = {LeCun, Yann},
	year = {1985},
	file = {Snapshot:/home/edecenciere/Zotero/storage/3Z77FDMX/une-procedure-dapprentissage-pour-reseau-a-seuil-asymmetrique-a-l.html:text/html},
}

@article{szegedy_rethinking_2015,
	title = {Rethinking the {Inception} {Architecture} for {Computer} {Vision}},
	url = {http://arxiv.org/abs/1512.00567},
	abstract = {Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2\% top-1 and 5.6\% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5\% top-5 error on the validation set (3.6\% error on the test set) and 17.3\% top-1 error on the validation set.},
	urldate = {2018-11-08},
	journal = {arXiv:1512.00567 [cs]},
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.00567},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{deniz_segmentation_2018,
	title = {Segmentation of the {Proximal} {Femur} from {MR} {Images} using {Deep} {Convolutional} {Neural} {Networks}},
	volume = {8},
	copyright = {2018 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-018-34817-6},
	doi = {10.1038/s41598-018-34817-6},
	abstract = {Magnetic resonance imaging (MRI) has been proposed as a complimentary method to measure bone quality and assess fracture risk. However, manual segmentation of MR images of bone is time-consuming, limiting the use of MRI measurements in the clinical practice. The purpose of this paper is to present an automatic proximal femur segmentation method that is based on deep convolutional neural networks (CNNs). This study had institutional review board approval and written informed consent was obtained from all subjects. A dataset of volumetric structural MR images of the proximal femur from 86 subjects were manually-segmented by an expert. We performed experiments by training two different CNN architectures with multiple number of initial feature maps, layers and dilation rates, and tested their segmentation performance against the gold standard of manual segmentations using four-fold cross-validation. Automatic segmentation of the proximal femur using CNNs achieved a high dice similarity score of 0.95 ± 0.02 with precision = 0.95 ± 0.02, and recall = 0.95 ± 0.03. The high segmentation accuracy provided by CNNs has the potential to help bring the use of structural MRI measurements of bone quality into clinical practice for management of osteoporosis.},
	language = {En},
	number = {1},
	urldate = {2018-11-08},
	journal = {Scientific Reports},
	author = {Deniz, Cem M. and Xiang, Siyuan and Hallyburton, R. Spencer and Welbeck, Arakua and Babb, James S. and Honig, Stephen and Cho, Kyunghyun and Chang, Gregory},
	month = nov,
	year = {2018},
	pages = {16485},
}

@article{ciresan_deep_2010,
	title = {Deep {Big} {Simple} {Neural} {Nets} {Excel} on {Handwritten} {Digit} {Recognition}},
	volume = {22},
	issn = {0899-7667, 1530-888X},
	url = {http://arxiv.org/abs/1003.0358},
	doi = {10.1162/NECO_a_00052},
	abstract = {Good old on-line back-propagation for plain multi-layer perceptrons yields a very low 0.35\% error rate on the famous MNIST handwritten digits benchmark. All we need to achieve this best result so far are many hidden layers, many neurons per layer, numerous deformed training images, and graphics cards to greatly speed up learning.},
	number = {12},
	urldate = {2018-11-02},
	journal = {Neural Computation},
	author = {Ciresan, Dan Claudiu and Meier, Ueli and Gambardella, Luca Maria and Schmidhuber, Juergen},
	month = dec,
	year = {2010},
	note = {arXiv: 1003.0358},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
	pages = {3207--3220},
}

@inproceedings{simard_efficient_1993,
	title = {Efficient pattern recognition using a new transformation distance},
	booktitle = {Advances in neural information processing systems},
	author = {Simard, Patrice and LeCun, Yann and Denker, John S},
	year = {1993},
	pages = {50--58},
}

@misc{noauthor_notitle_nodate,
	url = {https://scholar.googleusercontent.com/scholar.bib?q=info:fgQKTamC7QIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAW9bm0I7vxEVJRpdizqjtYGbyJ46G-1HL&scisf=4&ct=citation&cd=-1&hl=en},
	urldate = {2018-10-29},
}

@article{lecun_gradient-based_1998,
	title = {Gradient-based learning applied to document recognition},
	volume = {86},
	issn = {0018-9219},
	doi = {10.1109/5.726791},
	abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
	number = {11},
	journal = {Proceedings of the IEEE},
	author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	month = nov,
	year = {1998},
	keywords = {Pattern recognition, Neural networks, Machine learning, Feature extraction, Hidden Markov models, convolution, 2D shape variability, back-propagation, backpropagation, Character recognition, cheque reading, complex decision surface synthesis, convolutional neural network character recognizers, document recognition, document recognition systems, field extraction, gradient based learning technique, gradient-based learning, graph transformer networks, GTN, handwritten character recognition, handwritten digit recognition task, high-dimensional patterns, language modeling, Multi-layer neural network, multilayer neural networks, multilayer perceptrons, multimodule systems, optical character recognition, Optical character recognition software, Optical computing, performance measure minimization, Principal component analysis, segmentation recognition},
	pages = {2278--2324},
}

@article{lecun_gradient-based_1998-1,
	title = {Gradient-based learning applied to document recognition},
	volume = {86},
	issn = {0018-9219},
	doi = {10.1109/5.726791},
	abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
	number = {11},
	journal = {Proceedings of the IEEE},
	author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	month = nov,
	year = {1998},
	keywords = {Pattern recognition, Neural networks, Machine learning, Feature extraction, Hidden Markov models, convolution, 2D shape variability, back-propagation, backpropagation, Character recognition, cheque reading, complex decision surface synthesis, convolutional neural network character recognizers, document recognition, document recognition systems, field extraction, gradient based learning technique, gradient-based learning, graph transformer networks, GTN, handwritten character recognition, handwritten digit recognition task, high-dimensional patterns, language modeling, Multi-layer neural network, multilayer neural networks, multilayer perceptrons, multimodule systems, optical character recognition, Optical character recognition software, Optical computing, performance measure minimization, Principal component analysis, segmentation recognition},
	pages = {2278--2324},
}

@article{everingham_pascal_2010,
	title = {The {Pascal} {Visual} {Object} {Classes} ({VOC}) {Challenge}},
	volume = {88},
	issn = {1573-1405},
	url = {https://doi.org/10.1007/s11263-009-0275-4},
	doi = {10.1007/s11263-009-0275-4},
	abstract = {The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection.This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classification and detection, analyse whether the methods are statistically different, what they are learning from the images (e.g. the object or its context), and what the methods find easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension.},
	language = {en},
	number = {2},
	urldate = {2018-10-29},
	journal = {International Journal of Computer Vision},
	author = {Everingham, Mark and Van Gool, Luc and Williams, Christopher K. I. and Winn, John and Zisserman, Andrew},
	month = jun,
	year = {2010},
	keywords = {Object detection, Object recognition, Benchmark, Database},
	pages = {303--338},
}

@article{he_deep_2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://arxiv.org/abs/1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	urldate = {2018-10-28},
	journal = {arXiv:1512.03385 [cs]},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.03385},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{szegedy_going_2014,
	title = {Going {Deeper} with {Convolutions}},
	url = {http://arxiv.org/abs/1409.4842},
	abstract = {We propose a deep convolutional neural network architecture codenamed "Inception", which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
	urldate = {2018-10-28},
	journal = {arXiv:1409.4842 [cs]},
	author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	month = sep,
	year = {2014},
	note = {arXiv: 1409.4842},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{chellapilla_high_2006,
	title = {High {Performance} {Convolutional} {Neural} {Networks} for {Document} {Processing}},
	url = {https://hal.inria.fr/inria-00112631/document},
	abstract = {Convolutional neural networks (CNNs) are well known for producing state-of-the-art recognizers for document processing [1]. However, they can be difficult to implement and are usually slower than traditional multi-layer perceptrons (MLPs). We present three novel approaches to speeding up CNNs: a) unrolling convolution, b) using BLAS (basic linear algebra subroutines), and c) using GPUs (graphic processing units). Unrolled convolution converts the processing in each convolutional layer (both forward-propagation and back-propagation) into a matrix-matrix product. The matrix-matrix product representation of CNNs makes their implementation as easy as MLPs. BLAS is used to efficiently compute matrix products on the CPU. We also present a pixel shader based GPU implementation of CNNs. Results on character recognition problems indicate that unrolled convolution with BLAS produces a dramatic 2.4X−3.0X speedup. The GPU implementation is even faster and produces a 3.1X−4.1X speedup.},
	language = {en},
	urldate = {2018-10-28},
	booktitle = {Tenth {International} {Workshop} on {Frontiers} in {Handwriting} {Recognition}},
	publisher = {Suvisoft},
	author = {Chellapilla, Kumar and Puri, Sidd and Simard, Patrice},
	month = oct,
	year = {2006},
}

@article{ciresan_deep_2010-1,
	title = {Deep, {Big}, {Simple} {Neural} {Nets} for {Handwritten} {Digit} {Recognition}},
	volume = {22},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/NECO_a_00052},
	doi = {10.1162/NECO_a_00052},
	abstract = {Good old online backpropagation for plain multilayer perceptrons yields a very low 0.35\% error rate on the MNIST handwritten digits benchmark. All we need to achieve this best result so far are many hidden layers, many neurons per layer, numerous deformed training images to avoid overfitting, and graphics cards to greatly speed up learning.},
	number = {12},
	urldate = {2018-10-28},
	journal = {Neural Computation},
	author = {Cireşan, Dan Claudiu and Meier, Ueli and Gambardella, Luca Maria and Schmidhuber, Jürgen},
	month = sep,
	year = {2010},
	pages = {3207--3220},
}

@misc{noauthor_deep_nodate,
	title = {Deep, {Big}, {Simple} {Neural} {Nets} for {Handwritten} {Digit} {Recognition} {\textbar} {Neural} {Computation} {\textbar} {MIT} {Press} {Journals}},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00052},
	urldate = {2018-10-28},
}

@incollection{lecun_efficient_1998,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Efficient {BackProp}},
	abstract = {The convergence of back-propagation learning is analyzed so as to explain common phenomenon observed by practitioners. Many undesirable behaviors of backprop can be avoided with tricks that are rarely exposed in serious technical publications. This paper gives some of those tricks, and offers explanations of why they work.Many authors have suggested that second-order optimization methods are advantageous for neural net training. It is shown that most “classical” second-order methods are impractical for large neural networks. A few methods are proposed that do not have these limitations.},
	language = {en},
	booktitle = {Neural {Networks}: {Tricks} of the {Trade}},
	publisher = {Springer},
	author = {LeCun, Yann A. and Bottou, Léon and Orr, Genevieve B. and Müller, Klaus-Robert},
	editor = {Orr, Geneviève B. and Müller, Klaus-Robert},
	year = {1998},
	keywords = {Conjugate Gradient, Gradient Descent, Handwritten Digit, Neural Information Processing System, Newton Algorithm},
	pages = {9--50},
}

@inproceedings{glorot_understanding_2010-1,
	title = {Understanding the difficulty of training deep feedforward neural networks},
	url = {http://proceedings.mlr.press/v9/glorot10a.html},
	abstract = {Whereas before 2006 it appears that deep multi-layer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental resul...},
	language = {en},
	urldate = {2018-10-17},
	booktitle = {Proceedings of the {Thirteenth} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	author = {Glorot, Xavier and Bengio, Yoshua},
	month = mar,
	year = {2010},
	pages = {249--256},
}

@article{he_delving_2015,
	title = {Delving {Deep} into {Rectifiers}: {Surpassing} {Human}-{Level} {Performance} on {ImageNet} {Classification}},
	shorttitle = {Delving {Deep} into {Rectifiers}},
	url = {http://arxiv.org/abs/1502.01852},
	abstract = {Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on our PReLU networks (PReLU-nets), we achieve 4.94\% top-5 test error on the ImageNet 2012 classification dataset. This is a 26\% relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66\%). To our knowledge, our result is the first to surpass human-level performance (5.1\%, Russakovsky et al.) on this visual recognition challenge.},
	urldate = {2018-10-17},
	journal = {arXiv:1502.01852 [cs]},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = feb,
	year = {2015},
	note = {arXiv: 1502.01852},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{masci_learning_2013,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Learning} {Framework} for {Morphological} {Operators} {Using} {Counter}–{Harmonic} {Mean}},
	isbn = {978-3-642-38294-9},
	abstract = {We present a novel framework for learning morphological operators using counter-harmonic mean. It combines concepts from morphology and convolutional neural networks. A thorough experimental validation analyzes basic morphological operators dilation and erosion, opening and closing, as well as the much more complex top-hat transform, for which we report a real-world application from the steel industry. Using online learning and stochastic gradient descent, our system learns both the structuring element and the composition of operators. It scales well to large datasets and online settings.},
	language = {en},
	booktitle = {Mathematical {Morphology} and {Its} {Applications} to {Signal} and {Image} {Processing}},
	publisher = {Springer Berlin Heidelberg},
	author = {Masci, Jonathan and Angulo, Jesús and Schmidhuber, Jürgen},
	editor = {Hendriks, Cris L. Luengo and Borgefors, Gunilla and Strand, Robin},
	year = {2013},
	keywords = {machine learning, convolutional networks, mathematical morphology, online learning},
	pages = {329--340},
}

@inproceedings{pal_capsdemm:_2018,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{CapsDeMM}: {Capsule} {Network} for {Detection} of {Munro}’s {Microabscess} in {Skin} {Biopsy} {Images}},
	isbn = {978-3-030-00934-2},
	shorttitle = {{CapsDeMM}},
	abstract = {This paper presents an approach for automatic detection of Munro’s Microabscess in stratum corneum (SC) of human skin biopsy in order to realize a machine assisted diagnosis of Psoriasis. The challenge of detecting neutrophils in presence of nucleated cells is solved using the recent advances of deep learning algorithms. Separation of SC layer, extraction of patches from the layer followed by classification of patches with respect to presence or absence of neutrophils form the basis of the overall approach which is effected through an integration of a U-Net based segmentation network and a capsule network for classification. The novel design of the present capsule net leads to a drastic reduction in the number of parameters without any noticeable compromise in the overall performance. The research further addresses the challenge of dealing with Mega-pixel images (in 10X) vis-à-vis Giga-pixel ones (in 40X). The promising result coming out of an experiment on a dataset consisting of 273 real-life images shows that a practical system is possible based on the present research. The implementation of our system is available at https://github.com/Anabik/CapsDeMM.},
	language = {en},
	booktitle = {Medical {Image} {Computing} and {Computer} {Assisted} {Intervention} – {MICCAI} 2018},
	publisher = {Springer International Publishing},
	author = {Pal, Anabik and Chaturvedi, Akshay and Garain, Utpal and Chandra, Aditi and Chatterjee, Raghunath and Senapati, Swapan},
	editor = {Frangi, Alejandro F. and Schnabel, Julia A. and Davatzikos, Christos and Alberola-López, Carlos and Fichtinger, Gabor},
	year = {2018},
	keywords = {Convolutional neural network, Evaluation, Biopsy image, Capsule network, Dataset, Munro’s microabscess, Neutrophil, Psoriasis histopathology, Segmentation, Stratum corneum, Super-pixel},
	pages = {389--397},
}

@inproceedings{werbos_applications_1982-2,
	series = {Lecture {Notes} in {Control} and {Information} {Sciences}},
	title = {Applications of advances in nonlinear sensitivity analysis},
	isbn = {978-3-540-39459-4},
	abstract = {The following paper summarizes the major properties and applications of a collection of algorithms involving differentiation and optimization at minimum cost. The areas of application include the sensitivity analysis of models, new work in statistical or econometric estimation, optimization, artificial intelligence and neuron modelling. The details, references and derivations can be obtained by requesting „Sensitivity Analysis Methods for Nonlinear Systems“ from Forecast Analysis and Evaluation Team, Quality Assurance, OSS/EIA, Room 7413, Department of Energy, Washington, DC 20461.},
	language = {en},
	booktitle = {System {Modeling} and {Optimization}},
	publisher = {Springer Berlin Heidelberg},
	author = {Werbos, Paul J.},
	editor = {Drenick, R. F. and Kozin, F.},
	year = {1982},
	keywords = {Deterministic Optimization, Energy Information Administration, Evaluation Team, Sensitivity Analysis Method, Stochastic Optimization},
	pages = {762--770},
}

@article{cybenko_approximations_1989,
	title = {Approximations by superpositions of a sigmoidal function},
	volume = {2},
	url = {https://ci.nii.ac.jp/naid/10008983330/},
	urldate = {2018-10-08},
	journal = {Mathematics of Control, Signals and Systems},
	author = {Cybenko, G.},
	year = {1989},
	pages = {183--192},
}

@article{hornik_approximation_1991,
	title = {Approximation capabilities of multilayer feedforward networks},
	volume = {4},
	issn = {0893-6080},
	url = {http://www.sciencedirect.com/science/article/pii/089360809190009T},
	doi = {10.1016/0893-6080(91)90009-T},
	abstract = {We show that standard multilayer feedforward networks with as few as a single hidden layer and arbitrary bounded and nonconstant activation function are universal approximators with respect to Lp(μ) performance criteria, for arbitrary finite input environment measures μ, provided only that sufficiently many hidden units are available. If the activation function is continuous, bounded and nonconstant, then continuous mappings can be learned uniformly over compact input sets. We also give very general conditions ensuring that networks with sufficiently smooth activation functions are capable of arbitrarily accurate approximation to a function and its derivatives.},
	number = {2},
	urldate = {2018-10-08},
	journal = {Neural Networks},
	author = {Hornik, Kurt},
	month = jan,
	year = {1991},
	keywords = {() approximation, Activation function, Input environment measure, Multilayer feedforward networks, Smooth approximation, Sobolev spaces, Uniform approximation, Universal approximation capabilities},
	pages = {251--257},
}

@article{mcculloch_logical_1943-1,
	title = {A logical calculus of the ideas immanent in nervous activity},
	volume = {5},
	issn = {1522-9602},
	url = {https://doi.org/10.1007/BF02478259},
	doi = {10.1007/BF02478259},
	abstract = {Because of the “all-or-none” character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.},
	language = {en},
	number = {4},
	urldate = {2018-10-05},
	journal = {The bulletin of mathematical biophysics},
	author = {McCulloch, Warren S. and Pitts, Walter},
	month = dec,
	year = {1943},
	keywords = {Excitatory Synapse, Inhibitory Synapse, Nervous Activity, Spatial Summation, Temporal Summation},
	pages = {115--133},
}

@article{bejnordi_diagnostic_2017,
	title = {Diagnostic {Assessment} of {Deep} {Learning} {Algorithms} for {Detection} of {Lymph} {Node} {Metastases} in {Women} {With} {Breast} {Cancer}},
	volume = {318},
	issn = {0098-7484},
	url = {https://jamanetwork.com/journals/jama/fullarticle/2665774},
	doi = {10.1001/jama.2017.14585},
	abstract = {{\textless}h3{\textgreater}Importance{\textless}/h3{\textgreater}{\textless}p{\textgreater}Application of deep learning algorithms to whole-slide pathology images can potentially improve diagnostic accuracy and efficiency.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Objective{\textless}/h3{\textgreater}{\textless}p{\textgreater}Assess the performance of automated deep learning algorithms at detecting metastases in hematoxylin and eosin–stained tissue sections of lymph nodes of women with breast cancer and compare it with pathologists’ diagnoses in a diagnostic setting.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Design, Setting, and Participants{\textless}/h3{\textgreater}{\textless}p{\textgreater}Researcher challenge competition (CAMELYON16) to develop automated solutions for detecting lymph node metastases (November 2015-November 2016). A training data set of whole-slide images from 2 centers in the Netherlands with (n = 110) and without (n = 160) nodal metastases verified by immunohistochemical staining were provided to challenge participants to build algorithms. Algorithm performance was evaluated in an independent test set of 129 whole-slide images (49 with and 80 without metastases). The same test set of corresponding glass slides was also evaluated by a panel of 11 pathologists with time constraint (WTC) from the Netherlands to ascertain likelihood of nodal metastases for each slide in a flexible 2-hour session, simulating routine pathology workflow, and by 1 pathologist without time constraint (WOTC).{\textless}/p{\textgreater}{\textless}h3{\textgreater}Exposures{\textless}/h3{\textgreater}{\textless}p{\textgreater}Deep learning algorithms submitted as part of a challenge competition or pathologist interpretation.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Main Outcomes and Measures{\textless}/h3{\textgreater}{\textless}p{\textgreater}The presence of specific metastatic foci and the absence vs presence of lymph node metastasis in a slide or image using receiver operating characteristic curve analysis. The 11 pathologists participating in the simulation exercise rated their diagnostic confidence as definitely normal, probably normal, equivocal, probably tumor, or definitely tumor.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}The area under the receiver operating characteristic curve (AUC) for the algorithms ranged from 0.556 to 0.994. The top-performing algorithm achieved a lesion-level, true-positive fraction comparable with that of the pathologist WOTC (72.4\% [95\% CI, 64.3\%-80.4\%]) at a mean of 0.0125 false-positives per normal whole-slide image. For the whole-slide image classification task, the best algorithm (AUC, 0.994 [95\% CI, 0.983-0.999]) performed significantly better than the pathologists WTC in a diagnostic simulation (mean AUC, 0.810 [range, 0.738-0.884];\textit{P} \&lt; .001). The top 5 algorithms had a mean AUC that was comparable with the pathologist interpreting the slides in the absence of time constraints (mean AUC, 0.960 [range, 0.923-0.994] for the top 5 algorithms vs 0.966 [95\% CI, 0.927-0.998] for the pathologist WOTC).{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions and Relevance{\textless}/h3{\textgreater}{\textless}p{\textgreater}In the setting of a challenge competition, some deep learning algorithms achieved better diagnostic performance than a panel of 11 pathologists participating in a simulation exercise designed to mimic routine pathology workflow; algorithm performance was comparable with an expert pathologist interpreting whole-slide images without time constraints. Whether this approach has clinical utility will require evaluation in a clinical setting.{\textless}/p{\textgreater}},
	language = {en},
	number = {22},
	urldate = {2018-08-06},
	journal = {JAMA},
	author = {Bejnordi, Babak Ehteshami and Veta, Mitko and Diest, Paul Johannes van and Ginneken, Bram van and Karssemeijer, Nico and Litjens, Geert and Laak, Jeroen A. W. M. van der and Hermsen, Meyke and Manson, Quirine F. and Balkenhol, Maschenka and Geessink, Oscar and Stathonikos, Nikolaos and Dijk, Marcory CRF van and Bult, Peter and Beca, Francisco and Beck, Andrew H. and Wang, Dayong and Khosla, Aditya and Gargeya, Rishab and Irshad, Humayun and Zhong, Aoxiao and Dou, Qi and Li, Quanzheng and Chen, Hao and Lin, Huang-Jing and Heng, Pheng-Ann and Haß, Christian and Bruni, Elia and Wong, Quincy and Halici, Ugur and Öner, Mustafa Ümit and Cetin-Atalay, Rengul and Berseth, Matt and Khvatkov, Vitali and Vylegzhanin, Alexei and Kraus, Oren and Shaban, Muhammad and Rajpoot, Nasir and Awan, Ruqayya and Sirinukunwattana, Korsuk and Qaiser, Talha and Tsang, Yee-Wah and Tellez, David and Annuscheit, Jonas and Hufnagl, Peter and Valkonen, Mira and Kartasalo, Kimmo and Latonen, Leena and Ruusuvuori, Pekka and Liimatainen, Kaisa and Albarqouni, Shadi and Mungal, Bharti and George, Ami and Demirci, Stefanie and Navab, Nassir and Watanabe, Seiryo and Seno, Shigeto and Takenaka, Yoichi and Matsuda, Hideo and Phoulady, Hady Ahmady and Kovalev, Vassili and Kalinovsky, Alexander and Liauchuk, Vitali and Bueno, Gloria and Fernandez-Carrobles, M. Milagro and Serrano, Ismael and Deniz, Oscar and Racoceanu, Daniel and Venâncio, Rui},
	month = dec,
	year = {2017},
	pages = {2199--2210},
}

@inproceedings{k_retinal_2018,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Retinal {Image} {Synthesis} for {CAD} {Development}},
	isbn = {978-3-319-92999-6 978-3-319-93000-8},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-93000-8_70},
	doi = {10.1007/978-3-319-93000-8_70},
	abstract = {Automatic disease detection and classification have been attracting much interest. High performance is critical in adoption of such systems, which generally rely on training with a wide variety of annotated data. Availability of such varied annotated data in medical imaging is very scarce. Synthetic data generation is a promising solution to address this problem. We propose a novel method, based on generative adversarial networks (GAN), to generate images with lesions such that the overall severity level can be controlled. We demonstrate the reliability of the generated synthetic images independently as well as by training a computer aided diagnosis (CAD) system with the generated data. We showcase this approach for heamorrhage detection in retinal images with 4 levels of severity. Quantitative assessment results show that the generated synthetic images are very close to the real data. Haemorrhage detection was found to improve with inclusion of synthetic data in the training set with improvements in sensitivity ranging from 20\% to 27\% over training with just expert marked data.},
	language = {en},
	urldate = {2018-06-28},
	booktitle = {Image {Analysis} and {Recognition}},
	publisher = {Springer, Cham},
	author = {K, Pujitha Appan and Sivaswamy, Jayanthi},
	month = jun,
	year = {2018},
	pages = {613--621},
}

@article{morard_parsimonious_2014,
	title = {Parsimonious {Path} {Openings} and {Closings}},
	volume = {23},
	issn = {1057-7149},
	doi = {10.1109/TIP.2014.2303647},
	abstract = {Path openings and closings are morphological tools used to preserve long, thin, and tortuous structures in gray level images. They explore all paths from a defined class, and filter them with a length criterion. However, most paths are redundant, making the process generally slow. Parsimonious path openings and closings are introduced in this paper to solve this problem. These operators only consider a subset of the paths considered by classical path openings, thus achieving a substantial speed-up, while obtaining similar results. In addition, a recently introduced 1D opening algorithm is applied along each selected path. Its complexity is linear with respect to the number of pixels, independent of the size of the opening. Furthermore, it is fast for any input data accuracy (integer or floating point) and works in stream. Parsimonious path openings are also extended to incomplete paths, i.e., paths containing gaps. Noise-corrupted paths can thus be processed with the same approach and complexity. These parsimonious operators achieve a several orders of magnitude speed-up. Examples are shown for incomplete path openings, where computing times are brought from minutes to tens of milliseconds, while obtaining similar results.},
	number = {4},
	journal = {IEEE Transactions on Image Processing},
	author = {Morard, V. and Dokládal, P. and Decencière, E.},
	month = apr,
	year = {2014},
	keywords = {image processing, Robustness, filtering theory, Complexity theory, mathematical morphology, Noise, Morphology, Electronic mail, 1D opening algorithm, classical path openings, complete and incomplete paths, computing times, curvilinear structures, gray level images, Heuristic algorithms, incomplete path openings, incomplete paths, length criterion, long-structure preservation, magnitude speed-up, morphological tools, noise-corrupted paths, parsimonious operators, parsimonious path closings, parsimonious path openings, path filtering, Path operators, substantial speed-up, thin-structure preservation, Timing, tortuous structure preservation},
	pages = {1543--1555},
}

@article{morard_one-dimensional_2012-1,
	title = {One-{Dimensional} {Openings}, {Granulometries} and {Component} {Trees} in {O}(1)  {Per} {Pixel}},
	volume = {6},
	issn = {1932-4553},
	doi = {10.1109/JSTSP.2012.2201694},
	abstract = {We introduce a new, efficient and adaptable algorithm to compute openings, granulometries and the component tree for one-dimensional (1-D) signals. The algorithm requires only one scan of the signal, runs in place in O(1) per pixel, and supports any scalar data precision (integer or floating-point data). The algorithm is applied to two-dimensional images along straight lines, in arbitrary orientations. Oriented size distributions can thus be efficiently computed, and textures characterized. Extensive benchmarks are reported. They show that the proposed algorithm allows computing 1-D openings faster than existing algorithms for data precisions higher than 8 bits, and remains competitive with respect to the algorithm proposed by Van Droogenbroeck when dealing with 8-bit images. When computing granulometries, the new algorithm runs faster than any other method of the state of the art. Moreover, it allows efficient computation of 1-D component trees.},
	number = {7},
	journal = {IEEE Journal of Selected Topics in Signal Processing},
	author = {Morard, V. and Dokladal, P. and Decenciere, E.},
	month = nov,
	year = {2012},
	keywords = {Image segmentation, Algorithms, Histograms, Complexity theory, mathematical morphology, Algorithm design and analysis, Morphology, trees (mathematics), Indexes, 1D openings, 1D signals, 8-bit images, adaptable algorithm, arbitrary orientations, component tree, component trees, computational complexity, compute openings, computing granulometry, data precisions, extensive benchmarks, filtering, floating-point data, granulometry, integer data, one-dimensional openings, one-dimensional signals, opening, oriented size distribution, oriented size distributions, Powders, scalar data precision, signal processing, straight lines, two-dimensional images, Van Droogenbroeck},
	pages = {840--848},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/PWBDRTXI/abs_all.html:text/html},
}

@inproceedings{hradis_convolutional_2015,
	title = {Convolutional neural networks for direct text deblurring},
	volume = {10},
	booktitle = {Proceedings of {BMVC}},
	author = {Hradiš, Michal and Kotera, Jan and Zemcík, Pavel and Šroubek, Filip},
	year = {2015},
}

@article{zhu_self-assembly_2018,
	title = {Self-assembly of collagen-based biomaterials: preparation, characterizations and biomedical applications},
	issn = {2050-7518},
	shorttitle = {Self-assembly of collagen-based biomaterials},
	url = {http://pubs.rsc.org/en/content/articlelanding/2018/tb/c7tb02999c},
	doi = {10.1039/C7TB02999C},
	abstract = {The desired mechanical and biological performance of collagen enable its abroad applications as building blocks for biomedical fields, which are attributed to its intrinsic hierarchical structure from nanoscale to macroscale. Modulating self-assembly process using regulatory factors can obtain collagenous materials with tunable functional performance that determine distinctive cellular responses. Meanwhile, an overview of the corresponding characterization techniques used to detect the changes in light transmittance, architecture and mechanics during collagen fibrillogenesis are provided. By combining regulatory parameters with characterization methods, researchers can selectively fabricate collagenous biomaterials with various functional responses.},
	language = {en},
	urldate = {2018-04-09},
	journal = {Journal of Materials Chemistry B},
	author = {Zhu, Shichen and Yuan, Qi-Juan and Yin, Tao and You, Juan and Gu, Zhipeng and Xiong, Shanbai and Hu, Yang},
	month = apr,
	year = {2018},
}

@incollection{jimenez-del-toro_analysis_2017,
	title = {Analysis of {Histopathology} {Images}: {From} {Traditional} {Machine} {Learning} to {Deep} {Learning}},
	isbn = {978-0-12-812133-7},
	shorttitle = {Chapter 10 - {Analysis} of {Histopathology} {Images}},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128121337000107},
	abstract = {Digitizing pathology is a current trend that makes large amounts of visual data available for automatic analysis. It allows to visualize and interpret pathologic cell and tissue samples in high-resolution images and with the help of computer tools. This opens the possibility to develop image analysis methods that help pathologists and support their image descriptions (i.e., staging, grading) with objective quantification of image features. Numerous detection, classification and segmentation algorithms of the underlying tissue primitives in histopathology images have been proposed in this respect. To better select the most suitable algorithms for histopathology tasks, biomedical image analysis challenges have evaluated and compared both traditional feature extraction with machine learning and deep learning techniques. This chapter provides an overview of methods addressing the analysis of histopathology images, as well as a brief description of the tasks they aim to solve. It is focused on histopathology images containing textured areas of different types.},
	urldate = {2018-04-03},
	booktitle = {Biomedical {Texture} {Analysis}},
	publisher = {Academic Press},
	author = {Jimenez-del-Toro, Oscar and Otálora, Sebastian and Andersson, Mats and Eurén, Kristian and Hedlund, Martin and Rousson, Mikael and Müller, Henning and Atzori, Manfredo},
	editor = {Depeursinge, Adrien and Al-Kadi, Omar S. and Mitchell, J. Ross},
	year = {2017},
	doi = {10.1016/B978-0-12-812133-7.00010-7},
	keywords = {Deep learning, Biomedical texture analysis, Digital pathology, Histopathology},
	pages = {281--314},
}

@article{tennakoon_image_2016,
	title = {Image {Quality} {Classification} for {DR} {Screening} {Using} {Convolutional} {Neural} {Networks}},
	url = {http://ir.uiowa.edu/omia/2016_Proceedings/2016/15},
	journal = {Proceedings of the Ophthalmic Medical Image Analysis International Workshop},
	author = {Tennakoon, Ruwan and Mahapatra, Dwarikanath and Roy, Pallab and Sedai, Suman and Garnavi, Rahil},
	month = oct,
	year = {2016},
	pages = {113--120},
}

@article{welikala_automated_2016,
	title = {Automated retinal image quality assessment on the {UK} {Biobank} dataset for epidemiological studies},
	volume = {71},
	issn = {0010-4825},
	url = {http://www.sciencedirect.com/science/article/pii/S0010482516300178},
	doi = {10.1016/j.compbiomed.2016.01.027},
	abstract = {Morphological changes in the retinal vascular network are associated with future risk of many systemic and vascular diseases. However, uncertainty over the presence and nature of some of these associations exists. Analysis of data from large population based studies will help to resolve these uncertainties. The QUARTZ (QUantitative Analysis of Retinal vessel Topology and siZe) retinal image analysis system allows automated processing of large numbers of retinal images. However, an image quality assessment module is needed to achieve full automation. In this paper, we propose such an algorithm, which uses the segmented vessel map to determine the suitability of retinal images for use in the creation of vessel morphometric data suitable for epidemiological studies. This includes an effective 3-dimensional feature set and support vector machine classification. A random subset of 800 retinal images from UK Biobank (a large prospective study of 500,000 middle aged adults; where 68,151 underwent retinal imaging) was used to examine the performance of the image quality algorithm. The algorithm achieved a sensitivity of 95.33\% and a specificity of 91.13\% for the detection of inadequate images. The strong performance of this image quality algorithm will make rapid automated analysis of vascular morphometry feasible on the entire UK Biobank dataset (and other large retinal datasets), with minimal operator involvement, and at low cost.},
	urldate = {2018-03-20},
	journal = {Computers in Biology and Medicine},
	author = {Welikala, R. A. and Fraz, M. M. and Foster, P. J. and Whincup, P. H. and Rudnicka, A. R. and Owen, C. G. and Strachan, D. P. and Barman, S. A.},
	month = apr,
	year = {2016},
	keywords = {Epidemiological studies, Image quality, Large retinal datasets, Retinal image, UK Biobank, Vessel segmentation},
	pages = {67--76},
}

@inproceedings{pires_retinal_2012,
	title = {Retinal {Image} {Quality} {Analysis} for {Automatic} {Diabetic} {Retinopathy} {Detection}},
	doi = {10.1109/SIBGRAPI.2012.39},
	abstract = {Sufficient image quality is a necessary prerequisite for reliable automatic detection systems in several healthcare environments. Specifically for Diabetic Retinopathy (DR) detection, poor quality fund us makes more difficult the analysis of discontinuities that characterize lesions, as well as to generate evidence that can incorrectly diagnose the presence of anomalies. Several methods have been applied for classification of image quality and recently, have shown satisfactory results. However, most of the authors have focused only on the visibility of blood vessels through detection of blurring. Furthermore, these studies frequently only used fund us images from specific cameras which are not validated on datasets obtained from different retinographers. In this paper, we propose an approach to verify essential requirements of retinal image quality for DR screening: field definition and blur detection. The methods were developed and validated on two large, representative datasets collected by different cameras. The first dataset comprises 5,776 images and the second, 920 images. For field definition, the method yields a performance close to optimal with an area under the Receiver Operating Characteristic curve (ROC) of 96.0\%. For blur detection, the method achieves an area under the ROC curve of 95.5\%.},
	booktitle = {2012 25th {SIBGRAPI} {Conference} on {Graphics}, {Patterns} and {Images}},
	author = {Pires, R. and Jelinek, H. F. and Wainer, J. and Rocha, A.},
	month = aug,
	year = {2012},
	keywords = {Training, image classification, object detection, medical image processing, eye, Retina, Biomedical imaging, blood vessels, diseases, Vectors, Image quality, automatic diabetic retinopathy detection, Blur Detection, blurring detection, Dictionaries, DR detection, DR screening, field definition, Field Definition, image quality classification, receiver operating characteristic curve, retinal image quality analysis, Retinal Quality Assessment, ROC, Visualization},
	pages = {229--236},
}

@inproceedings{hunter_automated_2011,
	title = {An automated retinal image quality grading algorithm},
	doi = {10.1109/IEMBS.2011.6091472},
	abstract = {This paper introduces an algorithm for the automated assessment of retinal fundus image quality grade. Retinal image quality grading assesses whether the quality of the image is sufficient to allow diagnostic procedures to be applied. Automated quality analysis is an important preprocessing step in algorithmic diagnosis, as it is necessary to ensure that images are sufficiently clear to allow pathologies to be visible. The algorithm is based on standard recommendations for quality analysis by human screeners, examining the clarity of retinal vessels within the macula region. An evaluation against a reference standard data-set is given; it is shown that the algorithm's performance correlates closely with that of clinicians manually grading image quality.},
	booktitle = {2011 {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society}},
	author = {Hunter, A. and Lowell, J. A. and Habib, M. and Ryder, B. and Basu, A. and Steel, D.},
	month = aug,
	year = {2011},
	keywords = {Algorithms, Measurement, Humans, Image Enhancement, Image Interpretation, Computer-Assisted, Pattern Recognition, Automated, Reproducibility of Results, Sensitivity and Specificity, Histograms, biomedical optical imaging, medical image processing, eye, Retina, Biomedical imaging, Optical imaging, Image quality, automated quality analysis, automated retinal image quality grading algorithm, Blood vessels, retinal fundus image, retinal vessels, Retinoscopy},
	pages = {5955--5958},
}

@inproceedings{kohler_automatic_2013,
	title = {Automatic no-reference quality assessment for retinal fundus images using vessel segmentation},
	doi = {10.1109/CBMS.2013.6627771},
	abstract = {Fundus imaging is the most commonly used modality to collect information about the human eye background. Objective and quantitative assessment of quality for the acquired images is essential for manual, computer-aided and fully automatic diagnosis. In this paper, we present a no-reference quality metric to quantify image noise and blur and its application to fundus image quality assessment. The proposed metric takes the vessel tree visible on the retina as guidance to determine an image quality score. In our experiments, the performance of this approach is demonstrated by correlation analysis with the established full-reference metrics peak-signal-to-noise ratio (PSNR) and structural similarity (SSIM). We found a Spearman rank correlation for PSNR and SSIM of 0.89 and 0.91. For real data, our metric correlates reasonable to a human observer, indicating high agreement to human visual perception.},
	booktitle = {Proceedings of the 26th {IEEE} {International} {Symposium} on {Computer}-{Based} {Medical} {Systems}},
	author = {Köhler, T. and Budai, A. and Kraus, M. F. and Odstrčilik, J. and Michelson, G. and Hornegger, J.},
	month = jun,
	year = {2013},
	keywords = {image segmentation, medical image processing, eye, Retina, blood vessels, computer aided diagnosis, automatic no-reference quality assessment, Correlation, fully automatic diagnosis, human eye background, human visual perception, image blur, image denoising, image noise, image retrieval, manual diagnosis, Noise measurement, PSNR, retinal fundus images, Spearman rank correlation, Standards, structural similarity, vessel segmentation},
	pages = {95--100},
}

@inproceedings{lee_automatic_1999,
	title = {Automatic retinal image quality assessment and enhancement},
	volume = {3661},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/3661/0000/Automatic-retinal-image-quality-assessment-and-enhancement/10.1117/12.348562.short},
	doi = {10.1117/12.348562},
	abstract = {This paper describes a method for machine (computer) assessment of the quality of a retinal image. The method provides an over-all quantitative and objective measure using a quality index Q. The Q of a retinal image is calculated by the convolution of a template intensity histogram obtained from a set of typically good retinal images and the intensity histogram of the retinal image. After normalization, the Q has a maximum value of 1, indicating excellent quality, and a minimum value of 0, indicating bad quality. The paper also presents several application examples of Q in image enhancement. It is shown that the use of Q can help computer scientists evaluate the suitability and effectiveness of image enhancement methods, both quantitatively and objectively. It can further help computer scientists improve retinal image quality on a more scientific basis. Additionally, this machine image quality measure can also help physicians make medical diagnosis with more certainty and higher accuracy. Finally, it should be noted that although retinal images are used in this study, the methodology is applicable to the image quality assessment and enhancement of other types of medical images.},
	urldate = {2018-03-20},
	booktitle = {Medical {Imaging} 1999: {Image} {Processing}},
	publisher = {International Society for Optics and Photonics},
	author = {Lee, Samuel C. and Wang, Yiming},
	month = may,
	year = {1999},
	pages = {1581--1591},
}

@article{fleming_automated_2006,
	title = {Automated {Assessment} of {Diabetic} {Retinal} {Image} {Quality} {Based} on {Clarity} and {Field} {Definition}},
	volume = {47},
	issn = {1552-5783},
	url = {http://iovs.arvojournals.org/article.aspx?articleid=2183453},
	doi = {10.1167/iovs.05-1155},
	language = {en},
	number = {3},
	urldate = {2018-03-20},
	journal = {Investigative Ophthalmology \& Visual Science},
	author = {Fleming, Alan D. and Philip, Sam and Goatman, Keith A. and Olson, John A. and Sharp, Peter F.},
	month = mar,
	year = {2006},
	pages = {1120--1125},
}

@article{niemeijer_image_2006,
	title = {Image structure clustering for image quality verification of color retina images in diabetic retinopathy screening},
	volume = {10},
	issn = {1361-8415},
	url = {http://www.medicalimageanalysisjournal.com/article/S1361-8415(06)00073-9/abstract},
	doi = {10.1016/j.media.2006.09.006},
	language = {English},
	number = {6},
	urldate = {2018-03-20},
	journal = {Medical Image Analysis},
	author = {Niemeijer, Meindert and Abràmoff, Michael D. and Ginneken, Bram van},
	month = dec,
	year = {2006},
	pmid = {17138215},
	keywords = {Retina, Screening, Image quality, Diabetic retinopathy, Image structure},
	pages = {888--898},
}

@article{pires_dias_retinal_2014,
	series = {Special {Issue} on {Information} {Fusion} in {Medical} {Image} {Computing} and {Systems}},
	title = {Retinal image quality assessment using generic image quality indicators},
	volume = {19},
	issn = {1566-2535},
	url = {http://www.sciencedirect.com/science/article/pii/S1566253512000656},
	doi = {10.1016/j.inffus.2012.08.001},
	abstract = {A retinal image gradability assessment algorithm based on the fusion of generic image quality indicators is introduced. Four features quantifying image colour, focus, contrast and illumination are computed using novel image processing techniques. These quality indicators are also combined and classified to evaluate the image suitability for diagnostic purposes. The algorithm performance is thoroughly appraised through comparison of the automatic classification results of 2032 retinal images from proprietary, DRIVE, Messidor, ROC and STARE datasets with human made classification, revealing a sensitivity of 99.76\% and a specificity of 99.49\%. The algorithm computational complexity and sensitivity to image noise and resolution were also experimentally quantified demonstrating very good performance and confirming the usability of the solution in an ambulatory application environment.},
	urldate = {2018-03-20},
	journal = {Information Fusion},
	author = {Pires Dias, João Miguel and Oliveira, Carlos Manta and da Silva Cruz, Luís A.},
	month = sep,
	year = {2014},
	keywords = {Colour measure, Contrast measure, Focus measure, Illumination measure, Retinal image quality},
	pages = {73--90},
}

@incollection{ritchie_neurally-guided_2016,
	title = {Neurally-{Guided} {Procedural} {Models}: {Amortized} {Inference} for {Procedural} {Graphics} {Programs} using {Neural} {Networks}},
	shorttitle = {Neurally-{Guided} {Procedural} {Models}},
	url = {http://papers.nips.cc/paper/6353-neurally-guided-procedural-models-amortized-inference-for-procedural-graphics-programs-using-neural-networks.pdf},
	urldate = {2018-02-09},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 29},
	publisher = {Curran Associates, Inc.},
	author = {Ritchie, Daniel and Thomas, Anna and Hanrahan, Pat and Goodman, Noah},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
	pages = {622--630},
}

@incollection{du_plessis_analysis_2014,
	title = {Analysis of {Learning} from {Positive} and {Unlabeled} {Data}},
	url = {http://papers.nips.cc/paper/5509-analysis-of-learning-from-positive-and-unlabeled-data.pdf},
	urldate = {2018-02-09},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 27},
	publisher = {Curran Associates, Inc.},
	author = {du Plessis, Marthinus C and Niu, Gang and Sugiyama, Masashi},
	editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. D. and Weinberger, K. Q.},
	year = {2014},
	pages = {703--711},
}

@article{madabhushi_image_2016,
	series = {20th anniversary of the {Medical} {Image} {Analysis} journal ({MedIA})},
	title = {Image analysis and machine learning in digital pathology: {Challenges} and opportunities},
	volume = {33},
	issn = {1361-8415},
	shorttitle = {Image analysis and machine learning in digital pathology},
	url = {http://www.sciencedirect.com/science/article/pii/S1361841516301141},
	doi = {10.1016/j.media.2016.06.037},
	abstract = {With the rise in whole slide scanner technology, large numbers of tissue slides are being scanned and represented and archived digitally. While digital pathology has substantial implications for telepathology, second opinions, and education there are also huge research opportunities in image computing with this new source of “big data”. It is well known that there is fundamental prognostic data embedded in pathology images. The ability to mine “sub-visual” image features from digital pathology slide images, features that may not be visually discernible by a pathologist, offers the opportunity for better quantitative modeling of disease appearance and hence possibly improved prediction of disease aggressiveness and patient outcome. However the compelling opportunities in precision medicine offered by big digital pathology data come with their own set of computational challenges. Image analysis and computer assisted detection and diagnosis tools previously developed in the context of radiographic images are woefully inadequate to deal with the data density in high resolution digitized whole slide images. Additionally there has been recent substantial interest in combining and fusing radiologic imaging and proteomics and genomics based measurements with features extracted from digital pathology images for better prognostic prediction of disease aggressiveness and patient outcome. Again there is a paucity of powerful tools for combining disease specific features that manifest across multiple different length scales. The purpose of this review is to discuss developments in computational image analysis tools for predictive modeling of digital pathology images from a detection, segmentation, feature extraction, and tissue classification perspective. We discuss the emergence of new handcrafted feature approaches for improved predictive modeling of tissue appearance and also review the emergence of deep learning schemes for both object detection and tissue classification. We also briefly review some of the state of the art in fusion of radiology and pathology images and also combining digital pathology derived image measurements with molecular “omics” features for better predictive modeling. The review ends with a brief discussion of some of the technical and computational challenges to be overcome and reflects on future opportunities for the quantitation of histopathology.},
	urldate = {2018-01-25},
	journal = {Medical Image Analysis},
	author = {Madabhushi, Anant and Lee, George},
	month = oct,
	year = {2016},
	keywords = {Deep learning, Digital pathology, Omics, Radiology},
	pages = {170--175},
}

@article{gulshan_development_2016,
	title = {Development and {Validation} of a {Deep} {Learning} {Algorithm} for {Detection} of {Diabetic} {Retinopathy} in {Retinal} {Fundus} {Photographs}},
	volume = {316},
	issn = {0098-7484},
	url = {https://jamanetwork.com/journals/jama/fullarticle/2588763},
	doi = {10.1001/jama.2016.17216},
	abstract = {{\textless}h3{\textgreater}Importance{\textless}/h3{\textgreater}{\textless}p{\textgreater}Deep learning is a family of computational methods that allow an algorithm to program itself by learning from a large set of examples that demonstrate the desired behavior, removing the need to specify rules explicitly. Application of these methods to medical imaging requires further assessment and validation.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Objective{\textless}/h3{\textgreater}{\textless}p{\textgreater}To apply deep learning to create an algorithm for automated detection of diabetic retinopathy and diabetic macular edema in retinal fundus photographs.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Design and Setting{\textless}/h3{\textgreater}{\textless}p{\textgreater}A specific type of neural network optimized for image classification called a deep convolutional neural network was trained using a retrospective development data set of 128 175 retinal images, which were graded 3 to 7 times for diabetic retinopathy, diabetic macular edema, and image gradability by a panel of 54 US licensed ophthalmologists and ophthalmology senior residents between May and December 2015. The resultant algorithm was validated in January and February 2016 using 2 separate data sets, both graded by at least 7 US board-certified ophthalmologists with high intragrader consistency.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Exposure{\textless}/h3{\textgreater}{\textless}p{\textgreater}Deep learning–trained algorithm.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Main Outcomes and Measures{\textless}/h3{\textgreater}{\textless}p{\textgreater}The sensitivity and specificity of the algorithm for detecting referable diabetic retinopathy (RDR), defined as moderate and worse diabetic retinopathy, referable diabetic macular edema, or both, were generated based on the reference standard of the majority decision of the ophthalmologist panel. The algorithm was evaluated at 2 operating points selected from the development set, one selected for high specificity and another for high sensitivity.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}The EyePACS-1 data set consisted of 9963 images from 4997 patients (mean age, 54.4 years; 62.2\% women; prevalence of RDR, 683/8878 fully gradable images [7.8\%]); the Messidor-2 data set had 1748 images from 874 patients (mean age, 57.6 years; 42.6\% women; prevalence of RDR, 254/1745 fully gradable images [14.6\%]). For detecting RDR, the algorithm had an area under the receiver operating curve of 0.991 (95\% CI, 0.988-0.993) for EyePACS-1 and 0.990 (95\% CI, 0.986-0.995) for Messidor-2. Using the first operating cut point with high specificity, for EyePACS-1, the sensitivity was 90.3\% (95\% CI, 87.5\%-92.7\%) and the specificity was 98.1\% (95\% CI, 97.8\%-98.5\%). For Messidor-2, the sensitivity was 87.0\% (95\% CI, 81.1\%-91.0\%) and the specificity was 98.5\% (95\% CI, 97.7\%-99.1\%). Using a second operating point with high sensitivity in the development set, for EyePACS-1 the sensitivity was 97.5\% and specificity was 93.4\% and for Messidor-2 the sensitivity was 96.1\% and specificity was 93.9\%.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions and Relevance{\textless}/h3{\textgreater}{\textless}p{\textgreater}In this evaluation of retinal fundus photographs from adults with diabetes, an algorithm based on deep machine learning had high sensitivity and specificity for detecting referable diabetic retinopathy. Further research is necessary to determine the feasibility of applying this algorithm in the clinical setting and to determine whether use of the algorithm could lead to improved care and outcomes compared with current ophthalmologic assessment.{\textless}/p{\textgreater}},
	language = {en},
	number = {22},
	urldate = {2018-01-17},
	journal = {JAMA},
	author = {Gulshan, Varun and Peng, Lily and Coram, Marc and Stumpe, Martin C. and Wu, Derek and Narayanaswamy, Arunachalam and Venugopalan, Subhashini and Widner, Kasumi and Madams, Tom and Cuadros, Jorge and Kim, Ramasamy and Raman, Rajiv and Nelson, Philip C. and Mega, Jessica L. and Webster, Dale R.},
	month = dec,
	year = {2016},
	pages = {2402--2410},
}

@misc{noauthor_camelyon16_nodate,
	title = {{CAMELYON16} -},
	url = {https://camelyon16.grand-challenge.org/},
	urldate = {2018-01-16},
}

@article{wang_deep_2016,
	title = {Deep {Learning} for {Identifying} {Metastatic} {Breast} {Cancer}},
	url = {http://arxiv.org/abs/1606.05718},
	abstract = {The International Symposium on Biomedical Imaging (ISBI) held a grand challenge to evaluate computational systems for the automated detection of metastatic breast cancer in whole slide images of sentinel lymph node biopsies. Our team won both competitions in the grand challenge, obtaining an area under the receiver operating curve (AUC) of 0.925 for the task of whole slide image classification and a score of 0.7051 for the tumor localization task. A pathologist independently reviewed the same images, obtaining a whole slide image classification AUC of 0.966 and a tumor localization score of 0.733. Combining our deep learning system's predictions with the human pathologist's diagnoses increased the pathologist's AUC to 0.995, representing an approximately 85 percent reduction in human error rate. These results demonstrate the power of using deep learning to produce significant improvements in the accuracy of pathological diagnoses.},
	urldate = {2018-01-16},
	journal = {arXiv:1606.05718 [cs, q-bio]},
	author = {Wang, Dayong and Khosla, Aditya and Gargeya, Rishab and Irshad, Humayun and Beck, Andrew H.},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.05718},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Quantitative Biology - Quantitative Methods},
}

@article{yu_multi-scale_2015,
	title = {Multi-{Scale} {Context} {Aggregation} by {Dilated} {Convolutions}},
	url = {http://arxiv.org/abs/1511.07122},
	abstract = {State-of-the-art models for semantic segmentation are based on adaptations of convolutional networks that had originally been designed for image classification. However, dense prediction and image classification are structurally different. In this work, we develop a new convolutional network module that is specifically designed for dense prediction. The presented module uses dilated convolutions to systematically aggregate multi-scale contextual information without losing resolution. The architecture is based on the fact that dilated convolutions support exponential expansion of the receptive field without loss of resolution or coverage. We show that the presented context module increases the accuracy of state-of-the-art semantic segmentation systems. In addition, we examine the adaptation of image classification networks to dense prediction and show that simplifying the adapted network can increase accuracy.},
	urldate = {2018-01-15},
	journal = {arXiv:1511.07122 [cs]},
	author = {Yu, Fisher and Koltun, Vladlen},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.07122},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{schlegl_unsupervised_2017,
	title = {Unsupervised {Anomaly} {Detection} with {Generative} {Adversarial} {Networks} to {Guide} {Marker} {Discovery}},
	url = {http://arxiv.org/abs/1703.05921},
	abstract = {Obtaining models that capture imaging markers relevant for disease progression and treatment monitoring is challenging. Models are typically based on large amounts of data with annotated examples of known markers aiming at automating detection. High annotation effort and the limitation to a vocabulary of known markers limit the power of such approaches. Here, we perform unsupervised learning to identify anomalies in imaging data as candidates for markers. We propose AnoGAN, a deep convolutional generative adversarial network to learn a manifold of normal anatomical variability, accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space. Applied to new data, the model labels anomalies, and scores image patches indicating their fit into the learned distribution. Results on optical coherence tomography images of the retina demonstrate that the approach correctly identifies anomalous images, such as images containing retinal fluid or hyperreflective foci.},
	urldate = {2018-01-09},
	journal = {arXiv:1703.05921 [cs]},
	author = {Schlegl, Thomas and Seeböck, Philipp and Waldstein, Sebastian M. and Schmidt-Erfurth, Ursula and Langs, Georg},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.05921},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning},
}

@article{liu_ssd:_2016,
	title = {{SSD}: {Single} {Shot} {MultiBox} {Detector}},
	volume = {9905},
	shorttitle = {{SSD}},
	url = {http://arxiv.org/abs/1512.02325},
	doi = {10.1007/978-3-319-46448-0_2},
	abstract = {We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. Our SSD model is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stage and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, MS COCO, and ILSVRC datasets confirm that SSD has comparable accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. Compared to other single stage methods, SSD has much better accuracy, even with a smaller input image size. For \$300{\textbackslash}times 300\$ input, SSD achieves 72.1\% mAP on VOC2007 test at 58 FPS on a Nvidia Titan X and for \$500{\textbackslash}times 500\$ input, SSD achieves 75.1\% mAP, outperforming a comparable state of the art Faster R-CNN model. Code is available at https://github.com/weiliu89/caffe/tree/ssd .},
	urldate = {2018-01-08},
	journal = {arXiv:1512.02325 [cs]},
	author = {Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C.},
	year = {2016},
	note = {arXiv: 1512.02325},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {21--37},
}

@article{redmon_yolo9000:_2016,
	title = {{YOLO9000}: {Better}, {Faster}, {Stronger}},
	shorttitle = {{YOLO9000}},
	url = {http://arxiv.org/abs/1612.08242},
	abstract = {We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on object detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that don't have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. But YOLO can detect more than just 200 classes; it predicts detections for more than 9000 different object categories. And it still runs in real-time.},
	urldate = {2018-01-08},
	journal = {arXiv:1612.08242 [cs]},
	author = {Redmon, Joseph and Farhadi, Ali},
	month = dec,
	year = {2016},
	note = {arXiv: 1612.08242},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{hu_learning_2017,
	title = {Learning to {Segment} {Every} {Thing}},
	url = {http://arxiv.org/abs/1711.10370},
	abstract = {Existing methods for object instance segmentation require all training instances to be labeled with segmentation masks. This requirement makes it expensive to annotate new categories and has restricted instance segmentation models to {\textasciitilde}100 well-annotated classes. The goal of this paper is to propose a new partially supervised training paradigm, together with a novel weight transfer function, that enables training instance segmentation models over a large set of categories for which all have box annotations, but only a small fraction have mask annotations. These contributions allow us to train Mask R-CNN to detect and segment 3000 visual concepts using box annotations from the Visual Genome dataset and mask annotations from the 80 classes in the COCO dataset. We carefully evaluate our proposed approach in a controlled study on the COCO dataset. This work is a first step towards instance segmentation models that have broad comprehension of the visual world.},
	urldate = {2017-12-05},
	journal = {arXiv:1711.10370 [cs]},
	author = {Hu, Ronghang and Dollár, Piotr and He, Kaiming and Darrell, Trevor and Girshick, Ross},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.10370},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{feng_deep_2017,
	title = {Deep {Retinal} {Image} {Segmentation}: {A} {FCN}-{Based} {Architecture} with {Short} and {Long} {Skip} {Connections} for {Retinal} {Image} {Segmentation}},
	shorttitle = {Deep {Retinal} {Image} {Segmentation}},
	booktitle = {International {Conference} on {Neural} {Information} {Processing}},
	publisher = {Springer},
	author = {Feng, Zhongwei and Yang, Jie and Yao, Lixiu and Qiao, Yu and Yu, Qi and Xu, Xun},
	year = {2017},
	pages = {713--722},
}

@article{cang_topologynet:_2017,
	title = {{TopologyNet}: {Topology} based deep convolutional and multi-task neural networks for biomolecular property predictions},
	volume = {13},
	issn = {1553-7358},
	shorttitle = {{TopologyNet}},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005690},
	doi = {10.1371/journal.pcbi.1005690},
	abstract = {Author summary The predictions of biomolecular functions and properties from biomolecular structures are of fundamental importance in computational biophysics. The structural and biological complexities of biomolecules and their interactions hinder successful predictions. Machine learning has become an important tool for such predictions. Recent advances in deep learning architectures, particularly convolutional neural network (CNN), have profoundly impacted a number of disciplines, such as image classification and voice recognition. Though CNN can be directly applied to molecular sciences by using a three-dimensional (3D) image-like brute-force representation, it is computationally intractable when applied to large biomolecules and large datasets. We propose a topological strategy to significantly reduce the structural and biological complexity of biomolecules and provide an efficient topology based CNN architecture. Element-specific persistent homology, a new algebraic topology, has been developed to cast biomolecules in a multichannel image-like representation suitable for CNN. The power of the proposed topology based neural network (TopologyNet) is further enhanced by auxiliary descriptors and a multi-task deep learning architecture. It has been demonstrated that TopologyNet framework outperforms other methods in the predictions of protein-ligand binding affinities and mutation induced protein stability changes.},
	number = {7},
	urldate = {2017-11-13},
	journal = {PLOS Computational Biology},
	author = {Cang, Zixuan and Wei, Guo-Wei},
	month = jul,
	year = {2017},
	keywords = {Neural networks, Machine learning algorithms, Algebraic topology, Free energy, Globular proteins, Membrane proteins, Protein structure prediction, Topological invariants},
	pages = {e1005690},
}

@article{zeiler_adadelta:_2012,
	title = {{ADADELTA}: {An} {Adaptive} {Learning} {Rate} {Method}},
	volume = {abs/1212.5701},
	shorttitle = {{ADADELTA}},
	url = {http://arxiv.org/abs/1212.5701},
	urldate = {2017-11-10},
	journal = {CoRR},
	author = {Zeiler, Matthew D.},
	year = {2012},
}

@inproceedings{krahenbuhl_efficient_2011,
	title = {Efficient inference in fully connected crfs with gaussian edge potentials},
	booktitle = {Advances in neural information processing systems},
	author = {Krähenbühl, Philipp and Koltun, Vladlen},
	year = {2011},
	pages = {109--117},
}

@article{shi_superpixel-based_2018,
	title = {Superpixel-based {3D} deep neural networks for hyperspectral image classification},
	volume = {74},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320317303515},
	doi = {10.1016/j.patcog.2017.09.007},
	abstract = {This paper presents a novel hyperspectral image (HSI) classification method to effectively exploit the 3D spectral-spatial information via superpixel-based 3D deep neural networks (3D DNNs). Superpixel can represent the structure of HSI with adaptive sizes and shapes, and therefore, it is incorporated into 3D DNNs to improve the classification performance, especially for noisy classification and boundary misclassification. First, a spatial feature image via superpixel is constructed to increase the spectral-spatial similarity and diversity. Second, a 3D superpixel-based sample filling method is designed to solve the misclassification problem of boundaries. Third, a 3D recurrent convolutional networks (3D RCNNs) are designed to further exploit spatial continuity and suppress noisy prediction. Experimental results on real HSI datasets demonstrate the superiority of the proposed method over several well-known methods in both visual appearance and classification accuracy.},
	number = {Supplement C},
	urldate = {2017-10-30},
	journal = {Pattern Recognition},
	author = {Shi, Cheng and Pun, Chi-Man},
	month = feb,
	year = {2018},
	keywords = {3D deep neural networks, Hyperspectral image classification, Superpixel},
	pages = {600--616},
}

@article{colas_deep_2016,
	title = {Deep learning approach for diabetic retinopathy screening},
	volume = {94},
	issn = {1755-3768},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1755-3768.2016.0635/abstract},
	doi = {10.1111/j.1755-3768.2016.0635},
	abstract = {Purpose

Diabetic retinopathy (DR) is the major cause of blindness in the working-age population. With an increasing number of diabetic patients worldwide, automated screening tools become indispensable. Recent progress in machine learning and image analysis enables efficient automated screening.


Methods

DreamUp Vision uses state-of the art technology based on deep-learning. Our algorithm was trained on over 70,000 labeled retinal images. Images were graded by ophthalmologists as follows: 0 (no retinopathy), 1 (mild non proliferative DR), 2 (moderate non proliferative DR), 3 (severe non proliferative DR) and 4 (proliferative retinopathy). Each patient in the dataset is represented by two images of left and right eyes. Grading is done for each eye image separately. Our algorithm performs quick and reliable detection of anomalies in retinal images, diagnoses their stage of diabetic retinopathy and provides the location of the anomalies detected in the pictures. We consider a patient as referable if the DR stage is between 2 and 4, otherwise we consider the patient as non-referable. We evaluate our model on over 10,000 fundus images from 5,000 patients taken from the Kaggle DR Detection Challenge dataset, provided by California Healthcare Foundation.


Results

Our algorithm achieves an area under the receiver operating characteristic curve AUROC of 0.946 with 96.2\% sensitivity (95\% CI: 95.8–96.5) and 66.6\% specificity (95\% CI: 65.7–67.5) for identifying referable DR on the Kaggle dataset.


Conclusions

The performances we have obtained enable a reliable automated DR screening. As the amount of available labeled data grows and given our technology's ability to learn from labeled images, we believe that significant performance improvement can be achieved. The same process can be applied to the detection of other eye diseases as well.},
	language = {en},
	urldate = {2017-10-19},
	journal = {Acta Ophthalmologica},
	author = {Colas, E. and Besse, A. and Orgogozo, A. and Schmauch, B. and Meric, N. and Besse, E.},
	month = oct,
	year = {2016},
	pages = {n/a--n/a},
}

@article{erfani_high-dimensional_2016,
	title = {High-dimensional and large-scale anomaly detection using a linear one-class {SVM} with deep learning},
	volume = {58},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320316300267},
	doi = {10.1016/j.patcog.2016.03.028},
	abstract = {High-dimensional problem domains pose significant challenges for anomaly detection. The presence of irrelevant features can conceal the presence of anomalies. This problem, known as the ‘curse of dimensionality’, is an obstacle for many anomaly detection techniques. Building a robust anomaly detection model for use in high-dimensional spaces requires the combination of an unsupervised feature extractor and an anomaly detector. While one-class support vector machines are effective at producing decision surfaces from well-behaved feature vectors, they can be inefficient at modelling the variation in large, high-dimensional datasets. Architectures such as deep belief networks (DBNs) are a promising technique for learning robust features. We present a hybrid model where an unsupervised DBN is trained to extract generic underlying features, and a one-class SVM is trained from the features learned by the DBN. Since a linear kernel can be substituted for nonlinear ones in our hybrid model without loss of accuracy, our model is scalable and computationally efficient. The experimental results show that our proposed model yields comparable anomaly detection performance with a deep autoencoder, while reducing its training and testing time by a factor of 3 and 1000, respectively.},
	number = {Supplement C},
	urldate = {2017-10-19},
	journal = {Pattern Recognition},
	author = {Erfani, Sarah M. and Rajasegarar, Sutharshan and Karunasekera, Shanika and Leckie, Christopher},
	month = oct,
	year = {2016},
	keywords = {Feature extraction, Anomaly detection, Deep learning, Deep belief net, High-dimensional data, One-class SVM, Outlier detection},
	pages = {121--134},
}

@article{fukushima_neocognitron_2003,
	title = {Neocognitron for handwritten digit recognition},
	volume = {51},
	issn = {0925-2312, 1872-8286},
	language = {английский},
	journal = {Neurocomputing},
	author = {Fukushima, K.},
	year = {2003},
	keywords = {Handwritten Digit, Multi-Layered Network, Neocognitron, Neural Network Model, Visual Pattern Recognition},
	pages = {161--180},
}

@incollection{otalora_training_2017,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Training {Deep} {Convolutional} {Neural} {Networks} with {Active} {Learning} for {Exudate} {Classification} in {Eye} {Fundus} {Images}},
	isbn = {978-3-319-67533-6 978-3-319-67534-3},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-67534-3_16},
	abstract = {Training deep convolutional neural network for classification in medical tasks is often difficult due to the lack of annotated data samples. Deep convolutional networks (CNN) has been successfully used as an automatic detection tool to support the grading of diabetic retinopathy and macular edema. Nevertheless, the manual annotation of exudates in eye fundus images used to classify the grade of the DR is very time consuming and repetitive for clinical personnel. Active learning algorithms seek to reduce the labeling effort in training machine learning models. This work presents a label-efficient CNN model using the expected gradient length, an active learning algorithm to select the most informative patches and images, converging earlier and to a better local optimum than the usual SGD (Stochastic Gradient Descent) strategy. Our method also generates useful masks for prediction and segments regions of interest.},
	language = {en},
	urldate = {2017-09-25},
	booktitle = {Intravascular {Imaging} and {Computer} {Assisted} {Stenting}, and {Large}-{Scale} {Annotation} of {Biomedical} {Data} and {Expert} {Label} {Synthesis}},
	publisher = {Springer, Cham},
	author = {Otálora, Sebastian and Perdomo, Oscar and González, Fabio and Müller, Henning},
	month = sep,
	year = {2017},
	doi = {10.1007/978-3-319-67534-3_16},
	pages = {146--154},
}

@article{pontes_flexible_2016,
	title = {A flexible hierarchical approach for facial age estimation based on multiple features},
	volume = {54},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320315004458},
	doi = {10.1016/j.patcog.2015.12.003},
	abstract = {Age estimation from facial images is increasingly receiving attention to solve age-based access control, age-adaptive targeted marketing, amongst other applications. Since even humans can be induced in error due to the complex biological processes involved, finding a robust method remains a research challenge today. In this paper, we propose a new framework for the integration of Active Appearance Models (AAM), Local Binary Patterns (LBP), Gabor wavelets (GW) and Local Phase Quantization (LPQ) in order to obtain a highly discriminative feature representation which is able to model shape, appearance, wrinkles and skin spots. In addition, this paper proposes a novel flexible hierarchical age estimation approach consisting of a multi-class Support Vector Machine (SVM) to classify a subject into an age group followed by a Support Vector Regression (SVR) to estimate a specific age. The errors that may happen in the classification step, caused by the hard boundaries between age classes, are compensated in the specific age estimation by a flexible overlapping of the age ranges. The performance of the proposed approach was evaluated on FG-NET Aging and MORPH Album 2 datasets and a mean absolute error (MAE) of 4.50 and 5.86 years was achieved respectively. The robustness of the proposed approach was also evaluated on a merge of both datasets and a MAE of 5.20 years was achieved. Furthermore, we have also compared the age estimation made by humans with the proposed approach and it has shown that the machine outperforms humans. The proposed approach is competitive with current state-of-the-art and it provides an additional robustness to blur, lighting and expression variance brought about by the local phase features.},
	urldate = {2017-07-19},
	journal = {Pattern Recognition},
	author = {Pontes, Jhony K. and Britto, Alceu S. and Fookes, Clinton and Koerich, Alessandro L.},
	month = jun,
	year = {2016},
	keywords = {face recognition, classification, regression, Active appearance models, Age estimation, Local phase quantization},
	pages = {34--51},
}

@article{bibiloni_survey_2016,
	title = {A survey on curvilinear object segmentation in multiple applications},
	volume = {60},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320316301704},
	doi = {10.1016/j.patcog.2016.07.023},
	abstract = {Curvilinear object segmentation is a paramount step for many applications ranging from medical to aerial image processing. In particular, vessel segmentation in retinal images, detection of spiculated lesions in mammograms or extraction of airways in CT scans provide essential information to experts to evaluate, diagnose and propose a treatment. The significance of these applications has conducted important efforts to propose curvilinear object segmentation algorithms based on the most different techniques. The main objective of this review is to clearly present the similarities and differences between curvilinear structures in different applications and the different techniques used to segment them more effectively. To do so, we propose a general definition of curvilinear structures that encompasses the distinct models considered in the literature. In addition, we analyse and classify the mathematical techniques used to segment the curvilinear structures found across all considered applications, studying their strengths and weaknesses. In particular, we present the most relevant benchmarks related to curvilinear object segmentation as well as the best algorithms according to several performance measures. By doing so, it is acquired a wider point of view to extend the results from some fields to others, and to understand under which conditions some methodologies should be favoured over the rest of them.},
	urldate = {2017-07-18},
	journal = {Pattern Recognition},
	author = {Bibiloni, P. and González-Hidalgo, M. and Massanet, S.},
	month = dec,
	year = {2016},
	keywords = {Pattern recognition, segmentation, Image Processing, Curvilinear objects, Review, Survey},
	pages = {949--970},
}

@article{cula_assessing_2013,
	title = {Assessing facial wrinkles: automatic detection and quantification},
	volume = {19},
	issn = {1600-0846},
	shorttitle = {Assessing facial wrinkles},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1600-0846.2012.00635.x/abstract},
	doi = {10.1111/j.1600-0846.2012.00635.x},
	abstract = {Background

As people mature, their skin gradually presents lines, wrinkles, and folds that become more pronounced with time. Skin wrinkles are perceived as important cues in communicating information about the age of the person. Nowadays, documenting the facial appearance through imaging is prevalent in skin research, therefore detection and quantitative assessment of the degree of facial wrinkling can be a useful tool for establishing an objective baseline and for assessing benefits to facial appearance due to various dermatological treatments. However, few image-based algorithms for computationally assessing facial wrinkles are present in the literature, and those that exist have limited reliability.


Methods

In this work, an algorithm for automatic detection of facial wrinkles is developed, based on estimating the orientation and the frequency of elongated spatial features, captured via digital image filtering.


Results

The algorithm is tested against one set of clinically validated 11-point wrinkle scales present on the face. The algorithm is employed for assessing the presence of forehead furrows on a set of 100 clinically graded facial images. The proposed computational assessment correlates well with the corresponding clinical scores.


Conclusion

We find that the results are in better agreement with clinical scoring when the wrinkle depth information, approximated via filter responses, is combined with the wrinkle length information as opposed to the case when the two measures are considered separately.},
	language = {en},
	number = {1},
	urldate = {2017-07-18},
	journal = {Skin Research and Technology},
	author = {Cula, G. O. and Bargo, P. R. and Nkengne, A. and Kollias, N.},
	month = feb,
	year = {2013},
	keywords = {skin, automatic detection, Aging, Facial wrinkles, quantification},
	pages = {e243--e251},
}

@article{batool_fast_2015,
	title = {Fast detection of facial wrinkles based on {Gabor} features using image morphology and geometric constraints},
	volume = {48},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320314002945},
	doi = {10.1016/j.patcog.2014.08.003},
	abstract = {Facial wrinkles are important features of aging human skin which can be incorporated in several image-based applications related to aging. Facial wrinkles are 3D features of skin and appear as subtle discontinuities or cracks in surrounding skin texture. However, facial wrinkles can easily be masked by illumination/acquisition conditions in 2D images due to the specific nature of skin surface texture and its reflective properties. Existing approaches to image-based analysis of aging skin are based on the analysis of wrinkles as texture and not as curvilinear discontinuity/crack features. Previously, we proposed a stochastic approach based on Marked Point Processes (MPP) to localize facial wrinkles as curves. In this paper, we present a fast deterministic algorithm based on Gabor filters and image morphology to improve localization results. We propose image features based on Gabor filter bank to highlight the subtle curvilinear discontinuities in skin texture caused by wrinkles. Then, image morphology is used to incorporate geometric constraints to localize curvilinear shapes of wrinkles at image sites of large Gabor filter responses. Experiments are conducted on two sets of low and high resolution images and results are compared with those of MPP modeling. Experiments show that the proposed algorithm not only is significantly faster than MPP-based approach but also provides visually better results.},
	number = {3},
	urldate = {2017-07-18},
	journal = {Pattern Recognition},
	author = {Batool, Nazre and Chellappa, Rama},
	month = mar,
	year = {2015},
	keywords = {wrinkle detection, Facial wrinkles, Gabor features, Aging skin, Curvilinear object detection, Geometric constraints, Image morphology, Skin texture},
	pages = {642--658},
}

@article{kwon_age_1999,
	title = {Age {Classification} from {Facial} {Images}},
	volume = {74},
	issn = {1077-3142},
	url = {http://www.sciencedirect.com/science/article/pii/S107731429790549X},
	doi = {10.1006/cviu.1997.0549},
	abstract = {This paper presents a theory and practical computations for visual age classification from facial images. Currently, the theory has only been implemented to classify input images into one of three age-groups: babies, young adults, and senior adults. The computations are based on cranio-facial development theory and skin wrinkle analysis. In the implementation, primary features of the face are found first, followed by secondary feature analysis. The primary features are the eyes, nose, mouth, chin, virtual-top of the head and the sides of the face. From these features, ratios that distinguish babies from young adults and seniors are computed. In secondary feature analysis, a wrinkle geography map is used to guide the detection and measurement of wrinkles. The wrinkle index computed is sufficient to distinguish seniors from young adults and babies. A combination rule for the ratios and the wrinkle index thus permits categorization of a face into one of three classes. Results using real images are presented. This is the first work involving age classification, and the first work that successfully extracts and uses natural wrinkles. It is also a successful demonstration that facial features are sufficient for a classification task, a finding that is important to the debate about what are appropriate representations for facial analysis.},
	number = {1},
	urldate = {2017-07-18},
	journal = {Computer Vision and Image Understanding},
	author = {Kwon, Young H and Lobo, Niels da Vitoria},
	month = apr,
	year = {1999},
	pages = {1--21},
}

@article{becerra-riera_facial_2017,
	title = {Facial marks for improving face recognition},
	issn = {0167-8655},
	url = {http://www.sciencedirect.com/science/article/pii/S0167865517301423},
	doi = {10.1016/j.patrec.2017.05.005},
	abstract = {Recent studies have shown that the use of soft biometrics (e.g. gender, ethnicity, facial marks) as supplementary information in face images, can increase the accuracy of the recognition process of individuals. Facial marks (e.g. moles, freckles, warts) have shown to be useful, particularly, in this regard. In this paper we propose a new method for combining existing face recognition systems with the information obtained from facial marks in order to improve their performance. We first introduce an algorithm for automatically detecting facial marks, which are then represented using Histograms of Oriented Gradients (HoG), and are matched taking into account their position in the face image. Extensive experiments are conducted in order to show the effectiveness of the proposed facial mark detection algorithm, and to corroborate the benefits of using the information of facial marks on top of traditional face recognition systems. Due to the lack of proper public benchmarks to validate facial mark detection, we also present and make available a dataset with manual annotations for this purpose.},
	urldate = {2017-07-18},
	journal = {Pattern Recognition Letters},
	author = {Becerra-Riera, Fabiola and Morales-González, Annette and Méndez-Vázquez, Heydi},
	month = may,
	year = {2017},
	keywords = {face recognition, Facial mark benchmark, Facial marks, Soft biometrics},
}

@inproceedings{rusinkiewicz_efficient_2001,
	title = {Efficient variants of the {ICP} algorithm},
	doi = {10.1109/IM.2001.924423},
	abstract = {The ICP (Iterative Closest Point) algorithm is widely used for geometric alignment of three-dimensional models when an initial estimate of the relative pose is known. Many variants of ICP have been proposed, affecting all phases of the algorithm from the selection and matching of points to the minimization strategy. We enumerate and classify many of these variants, and evaluate their effect on the speed with which the correct alignment is reached. In order to improve convergence for nearly-flat meshes with small features, such as inscribed surfaces, we introduce a new variant based on uniform sampling of the space of normals. We conclude by proposing a combination of ICP variants optimized for high speed. We demonstrate an implementation that is able to align two range images in a few tens of milliseconds, assuming a good initial guess. This capability has potential application to real-time 3D model acquisition and model-based tracking},
	booktitle = {Proceedings {Third} {International} {Conference} on 3-{D} {Digital} {Imaging} and {Modeling}},
	author = {Rusinkiewicz, S. and Levoy, M.},
	year = {2001},
	keywords = {Layout, Image Processing, iterative methods, Iterative algorithms, Iterative closest point algorithm, image sampling, Geometry, range images, Convergence, minimisation, distance measurement, geometric alignment, inscribed surfaces, Minimization methods, minimization strategy, model-based tracking, nearly-flat meshes, real-time 3D model acquisition, real-time systems, Rough surfaces, Solid modeling, three-dimensional models, uniform sampling},
	pages = {145--152},
}

@article{magnenat-thalmann_computational_2002,
	title = {A computational skin model: fold and wrinkle formation},
	volume = {6},
	issn = {1089-7771},
	shorttitle = {A computational skin model},
	doi = {10.1109/TITB.2002.806097},
	abstract = {Not Available},
	number = {4},
	journal = {IEEE Transactions on Information Technology in Biomedicine},
	author = {Magnenat-Thalmann, N. and Kalra, P. and Leveque, J. Luc and Bazin, R. and Batisse, D. and Querleux, B.},
	month = dec,
	year = {2002},
	keywords = {Humans, skin, Aging, Dermis, Skin Aging, Computer Simulation, Mathematical model, Physiology, Computational modeling, Elasticity, Mechanical factors, Models, Biological, Muscles, Plastics, Skin Physiology, Stress, Mechanical, Surgery},
	pages = {317--323},
}

@article{chen_object_1992-1,
	series = {Range {Image} {Understanding}},
	title = {Object modelling by registration of multiple range images},
	volume = {10},
	issn = {0262-8856},
	url = {http://www.sciencedirect.com/science/article/pii/026288569290066C},
	doi = {10.1016/0262-8856(92)90066-C},
	abstract = {We study the problem of creating a complete model of a physical object. Although this may be possible using intensity images, we here use images which directly provide access to three dimensional information. The first problem that we need to solve is to find the transformation between the different views. Previous approaches either assume this transformation to be known (which is extremely difficult for a complete model), or compute it with feature matching (which is not accurate enough for integration). In this paper, we propose a new approach which works on range data directly and registers successive views with enough overlapping area to get an accurate transformation between views. This is performed by minimizing a functional which does not require point-to-point matches. We give the details of the registration method and modelling procedure and illustrate them on real range images of complex objects.},
	number = {3},
	urldate = {2017-06-16},
	journal = {Image and Vision Computing},
	author = {Chen, Yang and Medioni, Gérard},
	month = apr,
	year = {1992},
	keywords = {3D surface registration, object modelling, range image registration},
	pages = {145--155},
}

@article{besl_method_1992-1,
	title = {A method for registration of 3-{D} shapes},
	volume = {14},
	issn = {0162-8828},
	doi = {10.1109/34.121791},
	abstract = {The authors describe a general-purpose, representation-independent method for the accurate and computationally efficient registration of 3-D shapes including free-form curves and surfaces. The method handles the full six degrees of freedom and is based on the iterative closest point (ICP) algorithm, which requires only a procedure to find the closest point on a geometric entity to a given point. The ICP algorithm always converges monotonically to the nearest local minimum of a mean-square distance metric, and the rate of convergence is rapid during the first few iterations. Therefore, given an adequate set of initial rotations and translations for a particular class of objects with a certain level of 'shape complexity', one can globally minimize the mean-square distance metric over all six degrees of freedom by testing each initial registration. One important application of this method is to register sensed data from unfixtured rigid objects with an ideal geometric model, prior to shape inspection. Experimental results show the capabilities of the registration algorithm on point sets, curves, and surfaces.{\textless}{\textgreater}},
	number = {2},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Besl, P. J. and McKay, N. D.},
	month = feb,
	year = {1992},
	keywords = {Pattern recognition, Inspection, optimisation, Testing, iterative methods, Iterative algorithms, Iterative closest point algorithm, Convergence, Solid modeling, 3D shape registration, computational geometry, convergence of numerical methods, geometric entity, geometric model, iterative closest point, mean-square distance metric, Motion estimation, picture processing, point set registration, Quaternions, Shape measurement},
	pages = {239--256},
}

@inproceedings{vachier_extinction_1995,
	title = {Extinction values: a new measurement of persistence},
	booktitle = {{IEEE} {Workshop} on nonlinear signal and image processing},
	author = {Vachier, Corinne and Meyer, Fernand},
	month = jun,
	year = {1995},
	pages = {254--257},
}

@article{bae_robust_2017,
	title = {Robust skin-roughness estimation based on co-occurrence matrix},
	volume = {46},
	issn = {1047-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S1047320317300664},
	doi = {10.1016/j.jvcir.2017.03.003},
	abstract = {As the interest in one’s appearance has recently increased, the demand for diagnosing skin conditions has also increased. However, conventional specialized skin diagnostic devices are generally expensive, and people have to visit a skin-care shop to diagnose their skin condition. This is time consuming and troublesome. In this paper, we propose a skin-roughness estimation method that uses a mobile-phone camera in daily environments. In order to achieve accurate evaluation, the illumination variation is alleviated using texture components of the facial skin image. We also propose a new feature-extraction method based on the gray-level co-occurrence matrix, which effectively measures the skin roughness from the texture components. The performance of the proposed method is compared with the conventional commonly used features, and we verify the superiority of the proposed method.},
	urldate = {2017-06-01},
	journal = {Journal of Visual Communication and Image Representation},
	author = {Bae, Ji-Sang and Lee, Sang-Ho and Choi, Kang-Sun and Kim, Jong-Ok},
	month = jul,
	year = {2017},
	keywords = {Gray-level co-occurrence matrix (GLCM), Skin image, Skin roughness, Texture domain},
	pages = {13--22},
}

@article{zhang_review_2004,
	title = {Review of shape representation and description techniques},
	volume = {37},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320303002759},
	doi = {10.1016/j.patcog.2003.07.008},
	abstract = {More and more images have been generated in digital form around the world. There is a growing interest in finding images in large collections or from remote databases. In order to find an image, the image has to be described or represented by certain features. Shape is an important visual feature of an image. Searching for images using shape features has attracted much attention. There are many shape representation and description techniques in the literature. In this paper, we classify and review these important techniques. We examine implementation procedures for each technique and discuss its advantages and disadvantages. Some recent research results are also included and discussed in this paper. Finally, we identify some promising techniques for image retrieval according to standard principles.},
	number = {1},
	urldate = {2017-05-09},
	journal = {Pattern Recognition},
	author = {Zhang, Dengsheng and Lu, Guojun},
	month = jan,
	year = {2004},
	keywords = {Shape, Review, CBIR, Image retrieval, Shape descriptor},
	pages = {1--19},
}

@incollection{ren_faster_2015-1,
	title = {Faster {R}-{CNN}: {Towards} {Real}-{Time} {Object} {Detection} with {Region} {Proposal} {Networks}},
	shorttitle = {Faster {R}-{CNN}},
	url = {http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf},
	urldate = {2017-03-23},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 28},
	publisher = {Curran Associates, Inc.},
	author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
	editor = {Cortes, C. and Lawrence, N. D. and Lee, D. D. and Sugiyama, M. and Garnett, R.},
	year = {2015},
	pages = {91--99},
	file = {NIPS Snapshort:/home/edecenciere/Zotero/storage/8ZH5XRQK/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.html:text/html},
}

@article{he_mask_2017,
	title = {Mask {R}-{CNN}},
	url = {http://arxiv.org/abs/1703.06870},
	abstract = {We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without tricks, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code will be made available.},
	urldate = {2017-03-23},
	journal = {arXiv:1703.06870 [cs]},
	author = {He, Kaiming and Gkioxari, Georgia and Dollár, Piotr and Girshick, Ross},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.06870},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{heijmans_path_2005,
	title = {Path {Openings} and {Closings}},
	volume = {22},
	issn = {0924-9907, 1573-7683},
	url = {https://link.springer.com/article/10.1007/s10851-005-4885-3},
	doi = {10.1007/s10851-005-4885-3},
	abstract = {This paper lays the theoretical foundations to path openings and closings.The traditional morphological filter used for the analysis of linear structures in images is the union of openings (or the intersection of closings) by linear segments. However structures in images are rarely strictly straight, and as a result a more flexible approach is needed.An extension to the idea of using straight line segments as structuring elements is to use constrained paths, i.e. discrete, one-pixel thick successions of pixels oriented in a particular direction, but in general forming curved lines rather than perfectly straight lines. However the number of such paths is prohibitive and the resulting algorithm by simple composition is inefficient.In this paper we propose a way to compute openings and closings over large numbers of constrained, oriented paths in an efficient manner, suitable for building filters with applications to the analysis of oriented features, such as for example texture.},
	language = {en},
	number = {2-3},
	urldate = {2017-03-10},
	journal = {Journal of Mathematical Imaging and Vision},
	author = {Heijmans, Henk and Buckley, Michael and Talbot, Hugues},
	month = may,
	year = {2005},
	pages = {107--119},
	file = {Full Text PDF:/home/edecenciere/Zotero/storage/NNH9QQWP/Heijmans et al. - 2005 - Path Openings and Closings.pdf:application/pdf;Snapshot:/home/edecenciere/Zotero/storage/W5SKE6I3/10.html:text/html},
}

@article{morard_parsimonious_2014-1,
	title = {Parsimonious {Path} {Openings} and {Closings}},
	volume = {23},
	issn = {1057-7149},
	doi = {10.1109/TIP.2014.2303647},
	abstract = {Path openings and closings are morphological tools used to preserve long, thin, and tortuous structures in gray level images. They explore all paths from a defined class, and filter them with a length criterion. However, most paths are redundant, making the process generally slow. Parsimonious path openings and closings are introduced in this paper to solve this problem. These operators only consider a subset of the paths considered by classical path openings, thus achieving a substantial speed-up, while obtaining similar results. In addition, a recently introduced 1D opening algorithm is applied along each selected path. Its complexity is linear with respect to the number of pixels, independent of the size of the opening. Furthermore, it is fast for any input data accuracy (integer or floating point) and works in stream. Parsimonious path openings are also extended to incomplete paths, i.e., paths containing gaps. Noise-corrupted paths can thus be processed with the same approach and complexity. These parsimonious operators achieve a several orders of magnitude speed-up. Examples are shown for incomplete path openings, where computing times are brought from minutes to tens of milliseconds, while obtaining similar results.},
	number = {4},
	journal = {IEEE Transactions on Image Processing},
	author = {Morard, V. and Dokládal, P. and Decencière, E.},
	month = apr,
	year = {2014},
	keywords = {Robustness, filtering theory, Image Processing, Complexity theory, mathematical morphology, Noise, Morphology, Electronic mail, 1D opening algorithm, classical path openings, complete and incomplete paths, computing times, curvilinear structures, gray level images, Heuristic algorithms, incomplete path openings, incomplete paths, length criterion, long-structure preservation, magnitude speed-up, morphological tools, noise-corrupted paths, parsimonious operators, parsimonious path closings, parsimonious path openings, path filtering, Path operators, substantial speed-up, thin-structure preservation, Timing, tortuous structure preservation},
	pages = {1543--1555},
	file = {IEEE Xplore Full Text PDF:/home/edecenciere/Zotero/storage/J9S54T59/Morard et al. - 2014 - Parsimonious Path Openings and Closings.pdf:application/pdf;IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/MNNJJZ52/6728734.html:text/html},
}

@inproceedings{pang_cell_2010,
	title = {Cell {Nucleus} {Segmentation} in {Color} {Histopathological} {Imagery} {Using} {Convolutional} {Networks}},
	doi = {10.1109/CCPR.2010.5659313},
	abstract = {Recent studies have shown that convolutional networks can achieve a great deal of success in high-level vision problems such as objection recognition. In this paper, convolutional networks are used to solve a typical low-level image processing task, image segmentation. Here, the convolutional networks are trained using gradient descent techniques to solve the problem of segmenting the cell nuclei from the background in the histopathology images. Using a dataset with 58 H\&E stained breast cancer biopsy images, we find that the convolutional networks, with 3 hidden layers and 8 feature maps per hidden layer, provide superior performance to other pixel classification methods including FLDA and SVM. We also show two important properties of the convolutional networks as a segmentation method. First, as a machine learning approach, the convolution networks encode enough high-level domain-specific knowledge into the final segmentation strategy by learning the training data. Second, the convolutional networks can use appropriate amount of context information in segmenting by optimizing the weights of the filters in the networks through the learning process. In the end of this paper, several possible directions for future research are also proposed.},
	booktitle = {2010 {Chinese} {Conference} on {Pattern} {Recognition} ({CCPR})},
	author = {Pang, B. and Zhang, Y. and Chen, Q. and Gao, Z. and Peng, Q. and You, X.},
	month = oct,
	year = {2010},
	keywords = {Image segmentation, learning (artificial intelligence), Machine learning, image classification, Pixel, Computer architecture, object recognition, Labeling, Image color analysis, medical image processing, image colour analysis, Convolutional networks, breast cancer biopsy images, cell nucleus segmentation, color histopathological imagery, feature maps per hidden layer, FLDA, gradient descent techniques, high level domain specific knowledge, high level vision problem, histopathology images, machine learning approach, Microprocessors, objection recognition, pixel classification methods, support vector machines, SVM, typical low level image processing task},
	pages = {1--5},
	file = {IEEE Xplore Abstract Record:/home/edecenciere/Zotero/storage/UF9B5NWP/5659313.html:text/html},
}

@article{zhang_understanding_2016,
	title = {Understanding deep learning requires rethinking generalization},
	url = {http://arxiv.org/abs/1611.03530},
	abstract = {Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models.},
	urldate = {2017-01-13},
	journal = {arXiv:1611.03530 [cs]},
	author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.03530},
	keywords = {Computer Science - Learning},
}

@article{shrivastava_learning_2016,
	title = {Learning from {Simulated} and {Unsupervised} {Images} through {Adversarial} {Training}},
	url = {http://arxiv.org/abs/1612.07828},
	abstract = {With recent progress in graphics, it has become more tractable to train models on synthetic images, potentially avoiding the need for expensive annotations. However, learning from synthetic images may not achieve the desired performance due to a gap between synthetic and real image distributions. To reduce this gap, we propose Simulated+Unsupervised (S+U) learning, where the task is to learn a model to improve the realism of a simulator's output using unlabeled real data, while preserving the annotation information from the simulator. We develop a method for S+U learning that uses an adversarial network similar to Generative Adversarial Networks (GANs), but with synthetic images as inputs instead of random vectors. We make several key modifications to the standard GAN algorithm to preserve annotations, avoid artifacts and stabilize training: (i) a 'self-regularization' term, (ii) a local adversarial loss, and (iii) updating the discriminator using a history of refined images. We show that this enables generation of highly realistic images, which we demonstrate both qualitatively and with a user study. We quantitatively evaluate the generated images by training models for gaze estimation and hand pose estimation. We show a significant improvement over using synthetic images, and achieve state-of-the-art results on the MPIIGaze dataset without any labeled real data.},
	urldate = {2017-01-12},
	journal = {arXiv:1612.07828 [cs]},
	author = {Shrivastava, Ashish and Pfister, Tomas and Tuzel, Oncel and Susskind, Josh and Wang, Wenda and Webb, Russ},
	month = dec,
	year = {2016},
	note = {arXiv: 1612.07828},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing, Computer Science - Learning},
	file = {arXiv.org Snapshot:/home/edecenciere/Zotero/storage/X3BC45IB/1612.html:text/html},
}

@inproceedings{long_fully_2015,
	title = {Fully {Convolutional} {Networks} for {Semantic} {Segmentation}},
	url = {http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html},
	urldate = {2016-09-12},
	booktitle = {{IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	year = {2015},
	pages = {3431--3440},
	file = {Snapshot:/home/edecenciere/Zotero/storage/QSXCC3ZF/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html:text/html},
}

@article{trockman_patches_2022,
	title = {Patches {Are} {All} {You} {Need}?},
	journal = {arXiv preprint arXiv:2201.09792},
	author = {Trockman, Asher and Kolter, J. Zico},
	year = {2022},
	file = {Full Text:/home/edecenciere/Zotero/storage/PUELF9RC/Trockman et Kolter - 2022 - Patches Are All You Need.pdf:application/pdf;Snapshot:/home/edecenciere/Zotero/storage/64NJDGFY/2201.html:text/html},
}
