#bib file
@book{Hastie2009,
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  biburl = {https://www.bibsonomy.org/bibtex/200d858c0bd2826d4eb5f39450192d1f5/ukoethe},
  edition = 2,
  file = {:Books\\HastieTibshiraniFriedman-09-Elements-of-Statistical-Learning-2nd-edition\\hastie_09_elements-of.statistical-learning.pdf:PDF},
  interhash = {52d1772f39be836e3b298d37b8c0cfa1},
  intrahash = {00d858c0bd2826d4eb5f39450192d1f5},
  keywords = {inference mathmatics dataanalysis method clutering statistics},
  publisher = {Springer},
  timestamp = {2010-06-03T15:15:09.000+0200},
  title = {The elements of statistical learning: data mining, inference and prediction},
  url = {http://www-stat.stanford.edu/~tibs/ElemStatLearn/},
  year = 2009
}
@book{Bishop2006,
 author = {Bishop, Christopher M.},
 title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
 year = {2006},
 isbn = {0387310738},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 
@article{Fisher1936,
author = {Fisher, Ronald A.},
title = {The use of multiple measurements in taxonomic problems},
journal = {Annals of Eugenics},
volume = {7},
number = {2},
pages = {179-188},
year = {1936},
doi = {10.1111/j.1469-1809.1936.tb02137.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-1809.1936.tb02137.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-1809.1936.tb02137.x},
abstract = {The articles published by the Annals of Eugenics (1925–1954) have been made available online as an historical archive intended for scholarly use. The work of eugenicists was often pervaded by prejudice against racial, ethnic and disabled groups. The online publication of this material for scholarly research purposes is not an endorsement of those views nor a promotion of eugenics in any way.}
}

@inproceedings{Krizhevsky:2012,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1},
 series = {NIPS'12},
 year = {2012},
 location = {Lake Tahoe, Nevada},
 pages = {1097--1105},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=2999134.2999257},
 acmid = {2999257},
 publisher = {Curran Associates Inc.},
 address = {USA},
} 

@article{Esteva2017,
  title = {Dermatologist-Level Classification of Skin Cancer with Deep Neural Networks},
  author = {Esteva, Andre and Kuprel, Brett and Novoa, Roberto A. and Ko, Justin and Swetter, Susan M. and Blau, Helen M. and Thrun, Sebastian},
  year = {2017},
  volume = {542},
  pages = {115--118},
  publisher = {{Nature Publishing Group}},
  issn = {14764687},
  doi = {10.1038/nature21056},
  abstract = {Skin cancer, the most common human malignancy1, 2, 3, is primarily diagnosed visually, beginning with an initial clinical screening and followed potentially by dermoscopic analysis, a biopsy and histopathological examination. Automated classification of skin lesions using images is a challenging task owing to the fine-grained variability in the appearance of skin lesions. Deep convolutional neural networks (CNNs)4, 5 show potential for general and highly variable tasks across many fine-grained object categories6, 7, 8, 9, 10, 11. Here we demonstrate classification of skin lesions using a single CNN, trained end-to-end from images directly, using only pixels and disease labels as inputs. We train a CNN using a dataset of 129,450 clinical images\textemdash two orders of magnitude larger than previous datasets12\textemdash consisting of 2,032 different diseases. We test its performance against 21 board-certified dermatologists on biopsy-proven clinical images with two critical binary classification use cases: keratinocyte carcinomas versus benign seborrheic keratoses; and malignant melanomas versus benign nevi. The first case represents the identification of the most common cancers, the second represents the identification of the deadliest skin cancer. The CNN achieves performance on par with all tested experts across both tasks, demonstrating an artificial intelligence capable of classifying skin cancer with a level of competence comparable to dermatologists. Outfitted with deep neural networks, mobile devices can potentially extend the reach of dermatologists outside of the clinic. It is projected that 6.3 billion smartphone subscriptions will exist by the year 2021 (ref. 13) and can therefore potentially provide low-cost universal access to vital diagnostic care.},
  file = {/Users/twalter/Zotero/storage/DZ2CADRC/Esteva et al. - 2017 - Dermatologist-level classification of skin cancer with deep neural networks.pdf},
  isbn = {0028-0836},
  journal = {Nature},
  keywords = {Deep Learning,Dermatology,Image Classification,Melanoma},
  number = {7639},
  pmid = {28117445}
}


@article{Lin2020,
  title = {The Limits of Human Predictions of Recidivism},
  author = {Lin, Zhiyuan ``Jerry'' and Jung, Jongbin and Goel, Sharad and Skeem, Jennifer},
  year = {2020},
  month = feb,
  volume = {6},
  pages = {eaaz0652},
  doi = {10.1126/sciadv.aaz0652},
  abstract = {Dressel and Farid recently found that laypeople were as accurate as statistical algorithms in predicting whether a defendant would reoffend, casting doubt on the value of risk assessment tools in the criminal justice system. We report the results of a replication and extension of Dressel and Farid's experiment. Under conditions similar to the original study, we found nearly identical results, with humans and algorithms performing comparably. However, algorithms beat humans in the three other datasets we examined. The performance gap between humans and algorithms was particularly pronounced when, in a departure from the original study, participants were not provided with immediate feedback on the accuracy of their responses. Algorithms also outperformed humans when the information provided for predictions included an enriched (versus restricted) set of risk factors. These results suggest that algorithms can outperform human predictions of recidivism in ecologically valid settings.},
  journal = {Science Advances},
  number = {7}
}




@article{Poplin2018,
  title = {Prediction of Cardiovascular Risk Factors from Retinal Fundus Photographs via Deep Learning},
  author = {Poplin, Ryan and Varadarajan, Avinash V. and Blumer, Katy and Liu, Yun and McConnell, Michael V. and Corrado, Greg S. and Peng, Lily and Webster, Dale R.},
  year = {2018},
  month = mar,
  volume = {2},
  pages = {158--164},
  issn = {2157-846X},
  doi = {10.1038/s41551-018-0195-0},
  abstract = {Deep learning predicts, from retinal images, cardiovascular risk factors\textemdash such as smoking status, blood pressure and age\textemdash not previously thought to be present or quantifiable in these images.},
  copyright = {2018 The Author(s)},
  file = {/Users/twalter/Zotero/storage/KWHKD369/Poplin et al. - 2018 - Prediction of cardiovascular risk factors from ret.pdf;/Users/twalter/Zotero/storage/PQS7WZZF/s41551-018-0195-0.html},
  journal = {Nature Biomedical Engineering},
  language = {en},
  number = {3}
}



@article{Abramoff2018,
  title = {Pivotal Trial of an Autonomous {{AI}}-Based Diagnostic System for Detection of Diabetic Retinopathy in Primary Care Offices},
  author = {Abr{\`a}moff, Michael D and Lavin, Philip T and Birch, Michele and Shah, Nilay and Folk, James C},
  year = {2018},
  volume = {1},
  pages = {39},
  issn = {2398-6352},
  doi = {10.1038/s41746-018-0040-6},
  abstract = {Artificial Intelligence (AI) has long promised to increase healthcare affordability, quality and accessibility but FDA, until recently, had never authorized an autonomous AI diagnostic system. This pivotal trial of an AI system to detect diabetic retinopathy (DR) in people with diabetes enrolled 900 subjects, with no history of DR at primary care clinics, by comparing to Wisconsin Fundus Photograph Reading Center (FPRC) widefield stereoscopic photography and macular Optical Coherence Tomography (OCT), by FPRC certified photographers, and FPRC grading of Early Treatment Diabetic Retinopathy Study Severity Scale (ETDRS) and Diabetic Macular Edema (DME). More than mild DR (mtmDR) was defined as ETDRS level 35 or higher, and/or DME, in at least one eye. AI system operators underwent a standardized training protocol before study start. Median age was 59 years (range, 22\textendash 84 years); among participants, 47.5\% of participants were male; 16.1\% were Hispanic, 83.3\% not Hispanic; 28.6\% African American and 63.4\% were not; 198 (23.8\%) had mtmDR. The AI system exceeded all pre-specified superiority endpoints at sensitivity of 87.2\% (95\% CI, 81.8\textendash 91.2\%) ({$>$}85\%), specificity of 90.7\% (95\% CI, 88.3\textendash 92.7\%) ({$>$}82.5\%), and imageability rate of 96.1\% (95\% CI, 94.6\textendash 97.3\%), demonstrating AI's ability to bring specialty-level diagnostics to primary care settings. Based on these results, FDA authorized the system for use by health care providers to detect more than mild DR and diabetic macular edema, making it, the first FDA authorized autonomous AI diagnostic system in any field of medicine, with the potential to help prevent vision loss in thousands of people with diabetes annually. ClinicalTrials.gov NCT02963441},
  file = {/Users/twalter/Zotero/storage/SQSJSTAL/Abràmoff et al. - 2018 - Pivotal trial of an autonomous AI-based diagnostic.pdf},
  journal = {npj Digital Medicine},
  number = {1}
}

