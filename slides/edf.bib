
@article{sikora_low_1995,
	title = {Low complexity shape-adaptive {DCT} for coding of arbitrarily shaped image segments},
	volume = {7},
	journal = {Signal Processing : Image Communication},
	author = {Sikora, T.},
	year = {1995},
	pages = {381--395}
}

@book{bartlett_face_2001,
	title = {Face image analysis by unsupervised learning},
	publisher = {Kluwer academic publishers},
	author = {Bartlett, Marian Stewart},
	year = {2001}
}

@inproceedings{v._morard_region_2011,
	address = {Etats-Unis},
	title = {Region growing structuring elements and new operators based on their shape},
	booktitle = {Signal and {Image} {Processing} ({SIP} 2011)},
	publisher = {ACTA Press},
	author = {{V. Morard} and {E. Decencière} and {P. Dokladal}},
	year = {2011}
}

@article{pedregosa_scikit-learn:_2011,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	volume = {12},
	shorttitle = {Scikit-learn},
	url = {http://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language.  Emphasis is put on ease of use, performance, documentation, and API consistency.  It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings.  Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
	urldate = {2015-10-22},
	journal = {Journal of Machine Learning Research},
	author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
	month = oct,
	year = {2011},
	pages = {2825−2830},
	file = {Scikit-learn\: Machine Learning in Python:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/NNHRQR3D/Pedregosa et al. - 2011 - Scikit-learn Machine Learning in Python.pdf:application/pdf}
}

@inproceedings{ohtake_ridge-valley_2004,
	address = {New York, NY, USA},
	series = {{SIGGRAPH} '04},
	title = {Ridge-valley {Lines} on {Meshes} via {Implicit} {Surface} {Fitting}},
	url = {http://doi.acm.org/10.1145/1186562.1015768},
	doi = {10.1145/1186562.1015768},
	abstract = {We propose a simple and effective method for detecting view-and scale-independent ridge-valley lines defined via first- and second-order curvature derivatives on shapes approximated by dense triangle meshes. A high-quality estimation of high-order surface derivatives is achieved by combining multi-level implicit surface fitting and finite difference approximations. We demonstrate that the ridges and valleys are geometrically and perceptually salient surface features, and, therefore, can be potentially used for shape recognition, coding, and quality evaluation purposes.},
	urldate = {2014-12-04},
	booktitle = {{ACM} {SIGGRAPH} 2004 {Papers}},
	publisher = {ACM},
	author = {Ohtake, Yutaka and Belyaev, Alexander and Seidel, Hans-Peter},
	year = {2004},
	keywords = {curvature extrema, implicit surface fitting, ridges},
	pages = {609--612}
}

@article{mainsah_effects_1994,
	title = {The effects of quantization on 3D topography characterization},
	number = {5},
	journal = {Meas. Sci. Technol.},
	author = {Mainsah, E. and Stout, K. J and Sullivan, P. J},
	year = {1994},
	pages = {172--181}
}

@inproceedings{stawiaski_region_2007,
	address = {Saint Etienne, France},
	title = {Region merging via graph-cuts},
	booktitle = {The 12th {International} {Congress} for {Stereology} ({ICS} {XII})},
	author = {Stawiaski, Jean and Decencière, Etienne},
	year = {2007}
}

@phdthesis{aubert_proprietes_1999,
	title = {Propriétés optiques des surfaces rugueuses aléatoires},
	school = {Ecole Nationale Supérieure des Mines de Paris},
	author = {Aubert, A.},
	year = {1999}
}

@techreport{muralikrishnan_valley_2000,
	type = {Status report},
	title = {Valley suppression algorithms},
	url = {http://www.coe.uncc.edu/ bmuralik/academic/docs/valley-dec-2000.pdf},
	number = {N-05/95/MM},
	institution = {Center for Precision Metrology, UNC Charlote},
	author = {Muralikrishnan, B. and Raja, J.},
	year = {2000}
}

@incollection{matheron_splines_1981,
	title = {Splines and kriging : their formal equivalence},
	booktitle = {Down-to-earht statistics : solutions looking for geological problems},
	publisher = {Syracuse university. Geology contributions},
	author = {Matheron, G.},
	editor = {Merrian, D. F},
	year = {1981},
	pages = {77--95}
}

@article{boulanger_motifs_1992,
	title = {The motifs method: an interesting complement to {ISO} parameters for some functional problems},
	volume = {32},
	number = {1/2},
	journal = {International Journal of Machine Tools and Manufacture},
	author = {Boulanger, J.},
	year = {1992},
	pages = {203--209}
}

@techreport{matheron_schema_1968,
	title = {Schéma booléen séquentiel de partition aléatoire},
	number = {N-83},
	institution = {Centre de Morphologie Mathématique, Ecole des Mines de Paris},
	author = {Matheron, G.},
	year = {1968}
}

@article{matheron_intrinsic_1973,
	title = {The intrinsic random functions, and their applications},
	volume = {5},
	journal = {Advances in Applied Probability},
	author = {Matheron, Georges},
	year = {1973},
	pages = {439--468}
}

@article{yokoi_topological_1973,
	title = {Topological properties in digital binary pictures},
	volume = {4},
	journal = {Systems Comput. Controls},
	author = {Yokoi, S. and Toriwaki, J. and Fukumura, T.},
	year = {1973},
	pages = {32--40}
}

@article{schunck_image_1986,
	title = {The image flow constraint equation},
	volume = {35},
	number = {1},
	journal = {Computer Vision, Graphics, and Image Processing},
	author = {Schunck, B. G},
	year = {1986},
	pages = {20--46}
}

@inproceedings{yoshizawa_fast_2005,
	address = {New York, NY, USA},
	series = {{SPM} '05},
	title = {Fast and {Robust} {Detection} of {Crest} {Lines} on {Meshes}},
	isbn = {1-59593-015-9},
	url = {http://doi.acm.org/10.1145/1060244.1060270},
	doi = {10.1145/1060244.1060270},
	abstract = {We propose a fast and robust method for detecting crest lines on surfaces approximated by dense triangle meshes. The crest lines, salient surface features defined via first- and second-order curvature derivatives, are widely used for shape matching and interrogation purposes. Their practical extraction is difficult because it requires good estimation of high-order surface derivatives. Our approach to the crest line detection is based on estimating the curvature tensor and curvature derivatives via local polynomial fitting.Since the crest lines are not defined in the surface regions where the surface focal set (caustic) degenerates, we introduce a new thresholding scheme which exploits interesting relationships between curvature extrema, the so-called MVS functional of Moreton and Sequin, and Dupin cyclides,An application of the crest lines to adaptive mesh simplification is also considered.},
	urldate = {2014-12-04},
	booktitle = {Proceedings of the 2005 {ACM} {Symposium} on {Solid} and {Physical} {Modeling}},
	publisher = {ACM},
	author = {Yoshizawa, Shin and Belyaev, Alexander and Seidel, Hans-Peter},
	year = {2005},
	pages = {227--232}
}

@article{stout_characterization_1982,
	title = {The characterization of internal combustion engine bores},
	volume = {83},
	journal = {Wear},
	author = {Stout, K. J},
	year = {1982},
	pages = {311--326}
}

@article{levoy_efficient_1990,
	title = {Efficient {Ray} {Tracing} of {Volume} {Data}},
	volume = {9},
	number = {3},
	journal = {ACM Transactions on Graphics},
	author = {Levoy, Marc},
	month = jul,
	year = {1990},
	pages = {245--261}
}

@article{dong_reference_1995,
	title = {Reference planes for the assessment of surface roughness in three dimensions},
	volume = {35},
	number = {2},
	journal = {International Journal of Machine Tools and Manufacture},
	author = {Dong, W. P and Mainsah, E. and Stout, K. J},
	year = {1995},
	pages = {263--271}
}

@misc{matheron_surpotentes_1982,
	title = {Surpotentes et sous-potentes},
	publisher = {Ecole des Mines de Paris},
	author = {Matheron, Georges},
	year = {1982}
}

@article{stawiaski_region_2008,
	title = {Region merging via graph cuts},
	volume = {27},
	number = {1},
	journal = {Image Analysis and Stereology},
	author = {Stawiaski, J. and Decencière, E.},
	year = {2008},
	pages = {39--46}
}

@article{breiman_random_2001,
	title = {Random {Forests}},
	volume = {45},
	issn = {0885-6125, 1573-0565},
	url = {http://link.springer.com/article/10.1023/A%3A1010933404324},
	doi = {10.1023/A:1010933404324},
	abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
	language = {en},
	number = {1},
	urldate = {2015-10-22},
	journal = {Machine Learning},
	author = {Breiman, Leo},
	month = oct,
	year = {2001},
	keywords = {Artificial Intelligence (incl. Robotics), Automation and Robotics, Computing Methodologies, Language Translation and Linguistics, Simulation and Modeling, classification, ensemble, regression},
	pages = {5--32},
	file = {Snapshot:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/JNW4PZBJ/A1010933404324.html:text/html}
}

@phdthesis{pardas_segmentacion_1994,
	title = {Segmentación morfológica de secuencias de imágenes: aplicación a la codificación},
	school = {Universitat Politècnica de Catalunya},
	author = {Pardàs, M.},
	month = dec,
	year = {1994}
}

@article{caciu_numerical_2005,
	title = {Numerical analysis of a 3D hydrodynamic contact},
	volume = {51},
	number = {12},
	journal = {International Journal for numerical methods in fluids},
	author = {Caciu, Costin A and Decencière, Etienne},
	year = {2005},
	pages = {1355--1377}
}

@inproceedings{louppe_understanding_2013,
	title = {Understanding variable importances in forests of randomized trees},
	url = {http://papers.nips.cc/paper/4928-understanding-variable-importances-in-forests-of-randomized-trees},
	abstract = {Eletronic Proceedings of Neural Information Processing Systems},
	urldate = {2013-12-17},
	author = {Louppe, Gilles and Wehenkel, Louis and Sutera, Antonio and Geurts, Pierre},
	year = {2013},
	pages = {431--439},
	file = {Snapshot:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/VHV3C66X/4928-understanding-variable-importances-in-forests-of-randomized-trees.html:text/html}
}

@inproceedings{schulze_properties_1991,
	address = {San Jose, CA, USA},
	title = {Some properties of the two-dimensional pseudomedian filter},
	url = {http://link.aip.org/link/?PSI/1451/48/1&Agg=doi},
	doi = {10.1117/12.44315},
	urldate = {2011-04-11},
	booktitle = {Proceedings of {SPIE}},
	author = {Schulze, Mark A. and Pearce, John A.},
	year = {1991},
	pages = {48--57}
}

@article{schmitt_strong_1994,
	title = {Strong and weak convex hulls in non-{Euclidean} metric: theory and application},
	volume = {15},
	issn = {0167-8655},
	shorttitle = {Strong and weak convex hulls in non-{Euclidean} metric},
	url = {http://www.sciencedirect.com/science/article/pii/0167865594901570},
	doi = {10.1016/0167-8655(94)90157-0},
	abstract = {The notion of convexity is usually defined in the plane supplied with the Euclidean metric. This paper examines what remains if we equip the plane with a distance induced by a norm which is not necessarily the Euclidean one. The basic properties of the geodesic arcs according to these non-Euclidean metrics are stated. In some cases there exists more than one geodesic arc between two points. The two associated notions of convexity, both strong and weak, are the presented. The relationships between the notion of weak convex hull and the limit of closings of increasing size are stated. Finally an application in binary image pattern recognition is described.},
	number = {9},
	urldate = {2014-11-21},
	journal = {Pattern Recognition Letters},
	author = {Schmitt, Michel and Mattioli, Juliette},
	month = sep,
	year = {1994},
	keywords = {Convexity, Geodesic arcs, Morphological closing, Weakly convex hull, mathematical morphology},
	pages = {943--947},
	file = {ScienceDirect Snapshot:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/PF5HJHAS/0167865594901570.html:text/html}
}

@inproceedings{kunt_second-generation_1985,
	title = {Second-generation image coding techniques},
	volume = {73},
	booktitle = {Proceedings of the {IEEE}},
	author = {Kunt, M. and Ikonomopoulos, A. and Kocher, M.},
	year = {1985},
	pages = {549--574}
}

@misc{maisonneuve_sur_1982,
	title = {Sur le partage des eaux},
	author = {Maisonneuve, Francis},
	year = {1982},
	note = {Int. Rep CGMM}
}

@book{matheron_elements_1967,
	title = {Éléments pour une théorie des milieux poreux},
	publisher = {Masson, Paris},
	author = {Matheron, G.},
	year = {1967}
}

@article{hoover_experimental_1996,
	title = {An experimental comparison of range image segmentation algorithms},
	volume = {18},
	issn = {0162-8828},
	doi = {10.1109/34.506791},
	abstract = {A methodology for evaluating range image segmentation algorithms is proposed. This methodology involves (1) a common set of 40 laser range finder images and 40 structured light scanner images that have manually specified ground truth and (2) a set of defined performance metrics for instances of correctly segmented, missed, and noise regions, over- and under-segmentation, and accuracy of the recovered geometry. A tool is used to objectively compare a machine generated segmentation against the specified ground truth. Four research groups have contributed to evaluate their own algorithm for segmenting a range image into planar patches.},
	number = {7},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Hoover, A. and Jean-Baptiste, G. and Jiang, X. and Flynn, P.J. and Bunke, H. and Goldgof, D.B. and Bowyer, K. and Eggert, D.W. and Fitzgibbon, A. and Fisher, R.B.},
	month = jul,
	year = {1996},
	keywords = {Artificial Intelligence, Geometrical optics, Geometry, Image segmentation, Laser noise, Measurement standards, Pixel, Shape, Testing, computer vision, image classification, laser range finder images, laser ranging, over-segmentation, performance metrics, planar patches, range image segmentation algorithms, recovered geometry, structured light scanner images, under-segmentation},
	pages = {673--689},
	file = {IEEE Xplore Abstract Record:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/8PT8NRZA/abs_all.html:text/html}
}

@article{setos_fox_1996,
	title = {The {Fox} {Movietone} news preservation project: an introduction},
	volume = {105},
	number = {9},
	journal = {SMPTE Journal},
	author = {Setos, A. G},
	year = {1996},
	pages = {532--536}
}

@article{tholath_three-dimensional_1999,
	title = {Three-dimensional filtering of engineering surfaces using envelope system},
	volume = {23},
	journal = {Precision engineering},
	author = {Tholath, J. and Radhakrishnan, V.},
	year = {1999},
	pages = {221--228}
}

@book{matheron_random_1975,
	title = {Random sets and integral geometry},
	publisher = {Wiley, New York},
	author = {Matheron, G.},
	year = {1975}
}

@book{bowden_friction_1950,
	title = {The friction and lubrication of solids, part {I}},
	publisher = {Clarendon, Oxford},
	author = {Bowden, F. P and Tabor, D.},
	year = {1950}
}

@article{stout_surface_1984,
	title = {Surface topography of cylinder bores - the relationship between manufacture, characterization and function},
	volume = {95},
	journal = {Wear},
	author = {Stout, K. J},
	year = {1984},
	pages = {111--125}
}

@book{bowden_friction_1964,
	title = {The friction and lubrication of solids, part {II}},
	publisher = {Clarendon, Oxford},
	author = {Bowden, F. P and Tabor, D.},
	year = {1964}
}

@article{decenciere_feedback_2014,
	title = {{FEEDBACK} {ON} {A} {PUBLICLY} {DISTRIBUTED} {IMAGE} {DATABASE}: {THE} {MESSIDOR} {DATABASE}},
	volume = {33},
	copyright = {Copyright (c) 2014 Image Analysis \& Stereology},
	issn = {1854-5165},
	shorttitle = {{FEEDBACK} {ON} {A} {PUBLICLY} {DISTRIBUTED} {IMAGE} {DATABASE}},
	url = {http://www.ias-iss.org/ojs/IAS/article/view/1155},
	doi = {10.5566/ias.1155},
	abstract = {The Messidor database, which contains hundreds of eye fundus images, has been publicly distributed since 2008. It was created by the Messidor project in order to evaluate automatic lesion segmentation and diabetic retinopathy grading methods. Designing, producing and maintaining such a database entails significant costs. By publicly sharing it, one hopes to bring a valuable resource to the public research community. However, the real interest and benefit of the research community is not easy to quantify. We analyse here the feedback on the Messidor database, after more than 6 years of diffusion. This analysis should apply to other similar research databases.},
	language = {en},
	number = {3},
	urldate = {2014-11-20},
	journal = {Image Analysis \& Stereology},
	author = {Decencière, Etienne and Zhang, Xiwei and Cazuguel, Guy and Lay, Bruno and Cochener, Béatrice and Trone, Caroline and Gain, Philippe and Ordonez, Richard and Massin, Pascale and Erginay, Ali and Charton, Béatrice and Klein, Jean-Claude},
	month = aug,
	year = {2014},
	keywords = {Diabetic Retinopathy, Image Processing, Messidor, image database},
	pages = {231--234},
	file = {Snapshot:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/CI7Q85XF/1155.html:text/html}
}

@article{lantuejoul_geodesic_1984,
	title = {Geodesic methods in quantitative image analysis},
	volume = {17},
	number = {2},
	journal = {Pattern Recognition},
	author = {Lantuéjoul, Christian and Maisonneuve, F.},
	year = {1984},
	pages = {177--187}
}

@article{edmonds_theoretical_1972,
	title = {Theoretical improvements in algorithmic efficiency for network flow problems},
	volume = {19},
	number = {2},
	journal = {J. ACM},
	author = {Edmonds, J. and Karp, R. M},
	year = {1972},
	pages = {248--264}
}

@article{sacerdotti_mathematical_2000,
	title = {Mathematical {Modelling} of three-dimensional surface topography in autobody manufacture - {The} {State} of the {Art}},
	volume = {214},
	journal = {Proceedings of the Institution of Mechanical Engineers, PartB},
	author = {Sacerdotti, F. and Griffiths, B. J and Benati, F. and Butler, C.},
	year = {2000},
	pages = {811--819}
}

@techreport{decenciere_topological_2004,
	type = {Rapport {Pocket} {Multimedia}},
	title = {Topological sampling of binary images},
	number = {N 01/05/MM},
	institution = {Ecole des Mines de Paris, Centre de Morphologie Mathématique},
	author = {Decencière, Etienne and Bilodeau, Michel},
	month = dec,
	year = {2004}
}

@article{belongie_shape_2002,
	title = {Shape matching and object recognition using shape contexts},
	volume = {24},
	number = {24},
	journal = {i3epami},
	author = {Belongie, Serge and Malik, Jitendra and Puzicha, Jan},
	month = apr,
	year = {2002},
	pages = {509--522}
}

@article{hoffman_segmentation_1987,
	title = {Segmentation and {Classification} of {Range} {Images}},
	volume = {PAMI-9},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.1987.4767955},
	abstract = {The recognition of objects in three-dimensional space is a desirable capability of a computer vision system. Range images, which directly measure 3-D surface coordinates of a scene, are well suited for this task. In this paper we report a procedure to detect connected planar, convex, and concave surfaces of 3-D objects. This is accomplished in three stages. The first stage segments the range image into “surface patches” by a square error criterion clustering algorithm using surface points and associated surface normals. The second stage classifies these patches as planar, convex, or concave based on a non-parametric statistical test for trend, curvature values, and eigenvalue analysis. In the final stage, boundaries between adjacent surface patches are classified as crease or noncrease edges, and this information is used to merge compatible patches to produce reasonable faces of the object(s). This procedure has been successfully applied to a large number of real and synthetic images, four of which we present in this paper.},
	number = {5},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Hoffman, R. and Jain, Anil K.},
	month = sep,
	year = {1987},
	keywords = {Clustering algorithms, Eigenvalues and eigenfunctions, Face detection, Image segmentation, Layout, Reflectivity, Surface fitting, Testing, clustering, computer vision, curvature, decision tree, eigenvalues, nonparametric statistical tests, object detection, range images, surface normals, surface patches},
	pages = {608--620},
	file = {IEEE Xplore Abstract Record:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/RWTSVKHD/abs_all.html:text/html}
}

@article{caciu_parametric_nodate,
	title = {Parametric optimisation of periodic textured surfaces for friction reduction in combustion engines},
	journal = {STLE Tribology Transactions (accepted Feb. 2008)},
	author = {Caciu, Costin A and Decencière, Etienne and Jeulin, Dominique}
}

@phdthesis{lerallut_modelisation_2006,
	title = {Modélisation et {Interprétation} d'{Images} à l'{Aide} de {Graphes}},
	school = {Ecole des Mines de Paris, Paris},
	author = {Lerallut, Romain},
	year = {2006}
}

@phdthesis{casas_pla_image_1996,
	title = {Image compression based on perceptual coding techniques},
	school = {Universitat Politècnica de Catalunya},
	author = {Casas Pla, J. R},
	month = mar,
	year = {1996}
}

@article{von_weingraber_suitability_1957,
	title = {Suitability of the envelope line as a reference standard for measuring roughness},
	volume = {11},
	journal = {Microtecnic},
	author = {von Weingraber, H.},
	year = {1957},
	pages = {6--17}
}

@book{matheron_traite_1963,
	title = {Traité de géostatistique appliquée, tome {II}},
	publisher = {Editions Techniques, Paris},
	author = {Matheron, Georges},
	year = {1963}
}

@article{caciu_numerical_nodate,
	title = {Numerical analysis of the consequences of rugosity modifications in 3D hydrodynamic contacts},
	journal = {STLE Tribology Transactions (accepted Feb. 2008)},
	author = {Caciu, Costin A and Decencière, Etienne and Jeulin, Dominique}
}

@book{henry_sismique_1997,
	title = {Sismique réflexion : principes et développements},
	publisher = {Technip},
	author = {Henry, G.},
	year = {1997}
}

@article{rosenblatt_perceptron:_1958,
	title = {The perceptron: {A} probabilistic model for information storage and organization in the brain},
	volume = {65},
	copyright = {(c) 2012 APA, all rights reserved},
	issn = {1939-1471(Electronic);0033-295X(Print)},
	shorttitle = {The perceptron},
	doi = {10.1037/h0042519},
	abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems. 18 references.},
	number = {6},
	journal = {Psychological Review},
	author = {Rosenblatt, F.},
	year = {1958},
	keywords = {*Brain, *Cognition, *Memory, Nervous System},
	pages = {386--408}
}

@inproceedings{lecun_procedure_1985,
	title = {Une procedure d'apprentissage pour reseau a seuil asymmetrique ({A} learning scheme for asymmetric threshold networks)},
	url = {https://nyu.pure.elsevier.com/en/publications/une-procedure-dapprentissage-pour-reseau-a-seuil-asymmetrique-a-l},
	language = {English (US)},
	urldate = {2016-06-06},
	booktitle = {proceedings of {Cognitiva} 85},
	author = {LeCun, Yann},
	year = {1985},
	file = {Snapshot:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/3Z77FDMX/une-procedure-dapprentissage-pour-reseau-a-seuil-asymmetrique-a-l.html:text/html}
}

@incollection{krizhevsky_imagenet_2012,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
	urldate = {2016-06-06},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
	pages = {1097--1105},
	file = {NIPS Snapshort:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/945EI2D3/4824-imagenet-classification-w.html:text/html}
}

@inproceedings{nguyen_deep_2015,
	title = {Deep neural networks are easily fooled: {High} confidence predictions for unrecognizable images},
	shorttitle = {Deep neural networks are easily fooled},
	doi = {10.1109/CVPR.2015.7298640},
	abstract = {Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study [30] revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99\% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call “fooling images” (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision.},
	booktitle = {2015 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Nguyen, A. and Yosinski, J. and Clune, J.},
	month = jun,
	year = {2015},
	keywords = {Biomedical imaging, computer vision, image classification, neural nets, convolution, evolutionary computation, object recognition, DNNs, ImageNet datasets, MNIST datasets, convolutional neural networks, deep neural networks, evolutionary algorithms, fooling images, gradient ascent, image labeling, pattern-recognition tasks, recognizable objects, unrecognizable images, visual classification problems, Keyboards, Volcanoes},
	pages = {427--436},
	file = {IEEE Xplore Abstract Record:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/HMXF785X/abs_all.html:text/html}
}

@article{arganda-carreras_crowdsourcing_2015,
	title = {Crowdsourcing the creation of image segmentation algorithms for connectomics},
	volume = {9},
	issn = {1662-5129},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4633678/},
	doi = {10.3389/fnana.2015.00142},
	abstract = {To stimulate progress in automating the reconstruction of neural circuits, we organized the first international challenge on 2D segmentation of electron microscopic (EM) images of the brain. Participants submitted boundary maps predicted for a test set of images, and were scored based on their agreement with a consensus of human expert annotations. The winning team had no prior experience with EM images, and employed a convolutional network. This “deep learning” approach has since become accepted as a standard for segmentation of EM images. The challenge has continued to accept submissions, and the best so far has resulted from cooperation between two teams. The challenge has probably saturated, as algorithms cannot progress beyond limits set by ambiguities inherent in 2D scoring and the size of the test dataset. Retrospective evaluation of the challenge scoring system reveals that it was not sufficiently robust to variations in the widths of neurite borders. We propose a solution to this problem, which should be useful for a future 3D segmentation challenge.},
	urldate = {2016-06-30},
	journal = {Frontiers in Neuroanatomy},
	author = {Arganda-Carreras, Ignacio and Turaga, Srinivas C. and Berger, Daniel R. and Cireşan, Dan and Giusti, Alessandro and Gambardella, Luca M. and Schmidhuber, Jürgen and Laptev, Dmitry and Dwivedi, Sarvesh and Buhmann, Joachim M. and Liu, Ting and Seyedhosseini, Mojtaba and Tasdizen, Tolga and Kamentsky, Lee and Burget, Radim and Uher, Vaclav and Tan, Xiao and Sun, Changming and Pham, Tuan D. and Bas, Erhan and Uzunbas, Mustafa G. and Cardona, Albert and Schindelin, Johannes and Seung, H. Sebastian},
	month = nov,
	year = {2015},
	pmid = {26594156},
	pmcid = {PMC4633678}
}

@inproceedings{mehta_selective_2014,
	title = {Selective quantifiable facial assessment of aging},
	doi = {10.1109/PAHCE.2014.6849637},
	abstract = {Imaging represents a technique of choice in evaluation of the visual effects of aging and associated with that occurrence of wrinkles. In particular, skin wrinkles typically occur due to aging processes, including loss of body mass, sun damage, smoking, squinting and other factors. They represent a clear and easily accessible indicator of changes. As such, one can also acquire useful information about the aging process in skin by analyzing the wrinkles. To this end, we utilize a combination of numerical techniques, including color quantization, image segmentation, and various edge detection algorithms in order to perform automated wrinkle counting and wrinkle density calculations. As a more appropriate alternative to chronological age, such a methodology allows us to come up with quantifiable measures for skin aging, which may be used for performing statistics and extracting general patterns associated with physiological aging of the skin, as well as extending such numerical techniques for other biomedical applications in which distinct topological features contain important information about biological processes. Different subjects were used to test the techniques and extract aging patterns by examining the skin immediately underneath the lower eyelid as our region of interest. Numerically processed photographs, included counting the number of wrinkles meeting predefined threshold conditions, and calculating the corresponding wrinkle density for a given subject and particular conditions. Applicability and practicality of different edge detection methods were also a part of the studies as demonstrated.},
	booktitle = {Health {Care} {Exchanges} ({PAHCE}), 2014 {Pan} {American}},
	author = {Mehta, G. and Druzgalski, C.},
	month = apr,
	year = {2014},
	keywords = {Aging, Edge detection, Feature extraction, Gray-scale, Image color analysis, Image edge detection, Image segmentation, Skin Aging, Statistics, biomedical optical imaging, image colour analysis, medical image processing, skin, numerical analysis, biomedical applications, chronological age, color quantization, edge detection algorithms, edge detection methods, facial assessment, numerical techniques, pattern extraction, photographs, skin wrinkle counting, skin wrinkle density calculations, topological features, visual effect evaluation, Cameras, Physiology, Skin wrinkles},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/UXIASNCQ/abs_all.html:text/html}
}

@inproceedings{long_fully_2015,
	title = {Fully {Convolutional} {Networks} for {Semantic} {Segmentation}},
	url = {http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html},
	urldate = {2016-09-12},
	booktitle = {{IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	year = {2015},
	pages = {3431--3440},
	file = {Snapshot:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/QSXCC3ZF/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html:text/html}
}

@incollection{ronneberger_u-net:_2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	copyright = {©2015 Springer International Publishing Switzerland},
	isbn = {978-3-319-24573-7 978-3-319-24574-4},
	shorttitle = {U-{Net}},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	language = {en},
	number = {9351},
	urldate = {2016-09-12},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2015},
	publisher = {Springer International Publishing},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	editor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
	month = oct,
	year = {2015},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Graphics, Image Processing and Computer Vision, Pattern recognition, Imaging / Radiology, Health Informatics},
	pages = {234--241},
	file = {Snapshot:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/BBUWJFJV/978-3-319-24574-4_28.html:text/html}
}

@article{badrinarayanan_segnet:_2015,
	title = {{SegNet}: {A} {Deep} {Convolutional} {Encoder}-{Decoder} {Architecture} for {Image} {Segmentation}},
	shorttitle = {{SegNet}},
	url = {http://arxiv.org/abs/1511.00561},
	abstract = {We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation termed SegNet. This core trainable segmentation engine consists of an encoder network, a corresponding decoder network followed by a pixel-wise classification layer. The architecture of the encoder network is topologically identical to the 13 convolutional layers in the VGG16 network . The role of the decoder network is to map the low resolution encoder feature maps to full input resolution feature maps for pixel-wise classification. The novelty of SegNet lies is in the manner in which the decoder upsamples its lower resolution input feature map(s). Specifically, the decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. This eliminates the need for learning to upsample. The upsampled maps are sparse and are then convolved with trainable filters to produce dense feature maps. We compare our proposed architecture with the fully convolutional network (FCN) architecture and its variants. This comparison reveals the memory versus accuracy trade-off involved in achieving good segmentation performance. The design of SegNet was primarily motivated by road scene understanding applications. Hence, it is efficient both in terms of memory and computational time during inference. It is also significantly smaller in the number of trainable parameters than competing architectures and can be trained end-to-end using stochastic gradient descent. We also benchmark the performance of SegNet on Pascal VOC12 salient object segmentation and the recent SUN RGB-D indoor scene understanding challenge. We show that SegNet provides competitive performance although it is significantly smaller than other architectures. We also provide a Caffe implementation of SegNet and a webdemo at http://mi.eng.cam.ac.uk/projects/segnet/},
	urldate = {2016-09-12},
	journal = {arXiv:1511.00561 [cs]},
	author = {Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.00561},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv\:1511.00561 PDF:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/C2EXEX9G/Badrinarayanan et al. - 2015 - SegNet A Deep Convolutional Encoder-Decoder Archi.pdf:application/pdf;arXiv.org Snapshot:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/ZC76VUF8/1511.html:text/html}
}

@article{everingham_pascal_2014,
	title = {The {Pascal} {Visual} {Object} {Classes} {Challenge}: {A} {Retrospective}},
	volume = {111},
	issn = {0920-5691, 1573-1405},
	shorttitle = {The {Pascal} {Visual} {Object} {Classes} {Challenge}},
	url = {http://link.springer.com/article/10.1007/s11263-014-0733-5},
	doi = {10.1007/s11263-014-0733-5},
	abstract = {The Pascal Visual Object Classes (VOC) challenge consists of two components: (i) a publicly available dataset of images together with ground truth annotation and standardised evaluation software; and (ii) an annual competition and workshop. There are five challenges: classification, detection, segmentation, action classification, and person layout. In this paper we provide a review of the challenge from 2008–2012. The paper is intended for two audiences: algorithm designers, researchers who want to see what the state of the art is, as measured by performance on the VOC datasets, along with the limitations and weak points of the current generation of algorithms; and, challenge designers, who want to see what we as organisers have learnt from the process and our recommendations for the organisation of future challenges. To analyse the performance of submitted algorithms on the VOC datasets we introduce a number of novel evaluation methods: a bootstrapping method for determining whether differences in the performance of two algorithms are significant or not; a normalised average precision so that performance can be compared across classes with different proportions of positive instances; a clustering method for visualising the performance across multiple algorithms so that the hard and easy images can be identified; and the use of a joint classifier over the submitted algorithms in order to measure their complementarity and combined performance. We also analyse the community’s progress through time using the methods of Hoiem et al. (Proceedings of European Conference on Computer Vision, 2012) to identify the types of occurring errors. We conclude the paper with an appraisal of the aspects of the challenge that worked well, and those that could be improved in future challenges.},
	language = {en},
	number = {1},
	urldate = {2016-09-27},
	journal = {International Journal of Computer Vision},
	author = {Everingham, Mark and Eslami, S. M. Ali and Gool, Luc Van and Williams, Christopher K. I. and Winn, John and Zisserman, Andrew},
	month = jun,
	year = {2014},
	pages = {98--136},
	file = {Snapshot:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/RX7JR9Z4/s11263-014-0733-5.html:text/html}
}

@incollection{ganin_n^4-fields:_2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {N{\textasciicircum}4-{Fields}: {Neural} {Network} {Nearest} {Neighbor} {Fields} for {Image} {Transforms}},
	copyright = {©2015 Springer International Publishing Switzerland},
	isbn = {978-3-319-16807-4 978-3-319-16808-1},
	shorttitle = {N{\textasciicircum}4-{Fields}},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-16808-1_36},
	abstract = {We propose a new architecture for difficult image processing operations, such as natural edge detection or thin object segmentation. The architecture is based on a simple combination of convolutional neural networks with the nearest neighbor search. We focus our attention on the situations when the desired image transformation is too hard for a neural network to learn explicitly. We show that in such situations the use of the nearest neighbor search on top of the network output allows to improve the results considerably and to account for the underfitting effect during the neural network training. The approach is validated on three challenging benchmarks, where the performance of the proposed architecture matches or exceeds the state-of-the-art.},
	language = {en},
	number = {9004},
	urldate = {2016-09-28},
	booktitle = {Computer {Vision} -- {ACCV} 2014},
	publisher = {Springer International Publishing},
	author = {Ganin, Yaroslav and Lempitsky, Victor},
	editor = {Cremers, Daniel and Reid, Ian and Saito, Hideo and Yang, Ming-Hsuan},
	month = nov,
	year = {2014},
	doi = {10.1007/978-3-319-16808-1_36},
	keywords = {Artificial Intelligence (incl. Robotics), Image Processing and Computer Vision, Pattern recognition, Health Informatics, Information Systems Applications (incl. Internet), Information Storage and Retrieval},
	pages = {536--551},
	file = {Snapshot:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/U7PJD35G/978-3-319-16808-1_36.html:text/html}
}

@incollection{zilly_boosting_2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Boosting {Convolutional} {Filters} with {Entropy} {Sampling} for {Optic} {Cup} and {Disc} {Image} {Segmentation} from {Fundus} {Images}},
	copyright = {©2015 Springer International Publishing Switzerland},
	isbn = {978-3-319-24887-5 978-3-319-24888-2},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-24888-2_17},
	abstract = {We propose a novel convolutional neural network (CNN) based method for optic cup and disc segmentation. To reduce computational complexity, an entropy based sampling technique is introduced that gives superior results over uniform sampling. Filters are learned over several layers with the output of previous layers serving as the input to the next layer. A softmax logistic regression classifier is subsequently trained on the output of all learned filters. In several error metrics, the proposed algorithm outperforms existing methods on the public DRISHTI-GS data set.},
	language = {en},
	number = {9352},
	urldate = {2016-09-28},
	booktitle = {Machine {Learning} in {Medical} {Imaging}},
	publisher = {Springer International Publishing},
	author = {Zilly, Julian G. and Buhmann, Joachim M. and Mahapatra, Dwarikanath},
	editor = {Zhou, Luping and Wang, Li and Wang, Qian and Shi, Yinghuan},
	month = oct,
	year = {2015},
	doi = {10.1007/978-3-319-24888-2_17},
	keywords = {Artificial Intelligence (incl. Robotics), Image Processing and Computer Vision, Pattern recognition, Health Informatics, Data Mining and Knowledge Discovery},
	pages = {136--143},
	file = {Snapshot:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/DEHKRC84/978-3-319-24888-2_17.html:text/html}
}

@article{schmidhuber_deep_2015,
	title = {Deep learning in neural networks: {An} overview},
	volume = {61},
	issn = {0893-6080},
	shorttitle = {Deep learning in neural networks},
	url = {http://www.sciencedirect.com/science/article/pii/S0893608014002135},
	doi = {10.1016/j.neunet.2014.09.003},
	abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \&amp; evolutionary computation, and indirect search for short programs encoding deep and large networks.},
	urldate = {2016-11-24},
	journal = {Neural Networks},
	author = {Schmidhuber, Jürgen},
	month = jan,
	year = {2015},
	keywords = {unsupervised learning, deep learning, evolutionary computation, Supervised learning, Reinforcement learning},
	pages = {85--117}
}

@article{fukushima_neural_1979,
	title = {Neural {Network} {Model} for a {Mechanism} of {Pattern} {Recognition} {Unaffected} by {Shift} in {Position}- {Neocognitron}},
	volume = {62},
	number = {10},
	journal = {ELECTRON. \& COMMUN. JAPAN},
	author = {Fukushima, Kunihiko},
	year = {1979},
	pages = {11--18}
}

@article{farabet_learning_2013,
	title = {Learning {Hierarchical} {Features} for {Scene} {Labeling}},
	volume = {35},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2012.231},
	abstract = {Scene labeling consists of labeling each pixel in an image with the category of the object it belongs to. We propose a method that uses a multiscale convolutional network trained from raw pixels to extract dense feature vectors that encode regions of multiple sizes centered on each pixel. The method alleviates the need for engineered features, and produces a powerful representation that captures texture, shape, and contextual information. We report results using multiple postprocessing methods to produce the final labeling. Among those, we propose a technique to automatically retrieve, from a pool of segmentation components, an optimal set of components that best explain the scene; these components are arbitrary, for example, they can be taken from a segmentation tree or from any family of oversegmentations. The system yields record accuracies on the SIFT Flow dataset (33 classes) and the Barcelona dataset (170 classes) and near-record accuracy on Stanford background dataset (eight classes), while being an order of magnitude faster than competing approaches, producing a 320×240 image labeling in less than a second, including feature extraction.},
	number = {8},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Farabet, C. and Couprie, C. and Najman, L. and LeCun, Y.},
	month = aug,
	year = {2013},
	keywords = {Context, Feature extraction, Image edge detection, Image segmentation, Labeling, image classification, image texture, trees (mathematics), deep learning, image labeling, Transforms, shape recognition, Barcelona dataset, SIFT flow dataset, Stanford background dataset, contextual information capturing, dense feature vector extraction, hierarchical feature learning, image pixel labeling, multiple size region encoding, multiscale convolutional network, near-record accuracy, object category, scene labeling, segmentation components, segmentation tree, shape information capturing, texture information capturing, Accuracy, Vectors, Convolutional networks, scene parsing},
	pages = {1915--1929}
}

@article{lin_microsoft_2014,
	title = {Microsoft {COCO}: {Common} {Objects} in {Context}},
	shorttitle = {Microsoft {COCO}},
	url = {http://arxiv.org/abs/1405.0312},
	abstract = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.},
	urldate = {2016-11-29},
	journal = {arXiv:1405.0312 [cs]},
	author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Dollár, Piotr},
	month = may,
	year = {2014},
	note = {arXiv: 1405.0312},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{li_fully_2016,
	title = {Fully {Convolutional} {Instance}-aware {Semantic} {Segmentation}},
	url = {http://arxiv.org/abs/1611.07709},
	abstract = {We present the first fully convolutional end-to-end solution for instance-aware semantic segmentation task. It inherits all the merits of FCNs for semantic segmentation and instance mask proposal. It performs instance mask prediction and classification jointly. The underlying convolutional representation is fully shared between the two sub-tasks, as well as between all regions of interest. The proposed network is highly integrated and achieves state-of-the-art performance in both accuracy and efficiency. It wins the COCO 2016 segmentation competition by a large margin. The code would be released at {\textbackslash}url\{https://github.com/daijifeng001/TA-FCN\}.},
	urldate = {2016-11-29},
	journal = {arXiv:1611.07709 [cs]},
	author = {Li, Yi and Qi, Haozhi and Dai, Jifeng and Ji, Xiangyang and Wei, Yichen},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.07709},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1611.07709 PDF:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/EMPAUK9Z/Li et al. - 2016 - Fully Convolutional Instance-aware Semantic Segmen.pdf:application/pdf;arXiv.org Snapshot:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/IH4NWAJC/1611.html:text/html}
}

@inproceedings{ciresan_committee_2011,
	title = {A committee of neural networks for traffic sign classification},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6033458},
	urldate = {2017-01-03},
	booktitle = {Neural {Networks} ({IJCNN}), {The} 2011 {International} {Joint} {Conference} on},
	publisher = {IEEE},
	author = {Cireşan, Dan and Meier, Ueli and Masci, Jonathan and Schmidhuber, Jürgen},
	year = {2011},
	pages = {1918--1921}
}

@article{fukushima_neocognitron:_1980,
	title = {Neocognitron: {A} self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position},
	volume = {36},
	issn = {0340-1200, 1432-0770},
	shorttitle = {Neocognitron},
	url = {http://link.springer.com/article/10.1007/BF00344251},
	doi = {10.1007/BF00344251},
	abstract = {A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by “learning without a teacher”, and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname “neocognitron”. After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consits of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of “S-cells”, which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of “C-cells” similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any “teacher” during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cell of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern.},
	language = {en},
	number = {4},
	urldate = {2017-01-04},
	journal = {Biological Cybernetics},
	author = {Fukushima, Kunihiko},
	month = apr,
	year = {1980},
	pages = {193--202}
}

@article{lecun_backpropagation_1989,
	title = {Backpropagation {Applied} to {Handwritten} {Zip} {Code} {Recognition}},
	volume = {1},
	issn = {0899-7667},
	url = {http://www.mitpressjournals.org/doi/10.1162/neco.1989.1.4.541},
	doi = {10.1162/neco.1989.1.4.541},
	abstract = {The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.},
	number = {4},
	urldate = {2017-01-04},
	journal = {Neural Computation},
	author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
	month = dec,
	year = {1989},
	pages = {541--551}
}

@inproceedings{ciresan_mitosis_2013,
	title = {Mitosis {Detection} in {Breast} {Cancer} {Histology} {Images} with {Deep} {Neural} {Networks}},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-40763-5_51},
	abstract = {We use deep max-pooling convolutional neural networks to detect mitosis in breast histology images. The networks are trained to classify each pixel in the images, using as context a patch centered on the pixel. Simple postprocessing is then applied to the network output. Our approach won the ICPR 2012 mitosis detection competition, outperforming other contestants by a significant margin.},
	language = {en},
	urldate = {2017-01-06},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2013},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Cireşan, Dan C. and Giusti, Alessandro and Gambardella, Luca M. and Schmidhuber, Jürgen},
	month = sep,
	year = {2013},
	doi = {10.1007/978-3-642-40763-5_51},
	pages = {411--418}
}

@article{simonyan_very_2014,
	title = {Very deep convolutional networks for large-scale image recognition},
	url = {http://arxiv.org/abs/1409.1556},
	urldate = {2017-01-09},
	journal = {arXiv preprint arXiv:1409.1556},
	author = {Simonyan, Karen and Zisserman, Andrew},
	year = {2014},
	file = {[PDF] arxiv.org:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/DIXNC3WH/Simonyan et Zisserman - 2014 - Very deep convolutional networks for large-scale i.pdf:application/pdf;Snapshot:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/9GFJC2W9/1409.html:text/html}
}

@inproceedings{pang_cell_2010,
	title = {Cell {Nucleus} {Segmentation} in {Color} {Histopathological} {Imagery} {Using} {Convolutional} {Networks}},
	doi = {10.1109/CCPR.2010.5659313},
	abstract = {Recent studies have shown that convolutional networks can achieve a great deal of success in high-level vision problems such as objection recognition. In this paper, convolutional networks are used to solve a typical low-level image processing task, image segmentation. Here, the convolutional networks are trained using gradient descent techniques to solve the problem of segmenting the cell nuclei from the background in the histopathology images. Using a dataset with 58 H\&E stained breast cancer biopsy images, we find that the convolutional networks, with 3 hidden layers and 8 feature maps per hidden layer, provide superior performance to other pixel classification methods including FLDA and SVM. We also show two important properties of the convolutional networks as a segmentation method. First, as a machine learning approach, the convolution networks encode enough high-level domain-specific knowledge into the final segmentation strategy by learning the training data. Second, the convolutional networks can use appropriate amount of context information in segmenting by optimizing the weights of the filters in the networks through the learning process. In the end of this paper, several possible directions for future research are also proposed.},
	booktitle = {2010 {Chinese} {Conference} on {Pattern} {Recognition} ({CCPR})},
	author = {Pang, B. and Zhang, Y. and Chen, Q. and Gao, Z. and Peng, Q. and You, X.},
	month = oct,
	year = {2010},
	keywords = {Image color analysis, Image segmentation, Labeling, Pixel, image classification, image colour analysis, medical image processing, learning (artificial intelligence), object recognition, Convolutional networks, Computer architecture, support vector machines, FLDA, SVM, breast cancer biopsy images, cell nucleus segmentation, color histopathological imagery, feature maps per hidden layer, gradient descent techniques, high level domain specific knowledge, high level vision problem, histopathology images, machine learning approach, objection recognition, pixel classification methods, typical low level image processing task, Machine learning, Microprocessors},
	pages = {1--5},
	file = {IEEE Xplore Abstract Record:/home/decencie/.mozilla/firefox/dv1q8ktg.default/zotero/storage/UF9B5NWP/5659313.html:text/html}
}

@article{he_mask_2017,
	title = {Mask {R}-{CNN}},
	url = {http://arxiv.org/abs/1703.06870},
	abstract = {We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without tricks, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code will be made available.},
	urldate = {2017-03-23},
	journal = {arXiv:1703.06870 [cs]},
	author = {He, Kaiming and Gkioxari, Georgia and Dollár, Piotr and Girshick, Ross},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.06870},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@inproceedings{girshick_rich_2014,
	title = {Rich {Feature} {Hierarchies} for {Accurate} {Object} {Detection} and {Semantic} {Segmentation}},
	url = {http://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.html},
	urldate = {2017-03-23},
	author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
	year = {2014},
	pages = {580--587}
}

@article{fukushima_neocognitron_2003,
	title = {Neocognitron for handwritten digit recognition},
	volume = {51},
	issn = {0925-2312, 1872-8286},
	language = {английский},
	journal = {Neurocomputing},
	author = {Fukushima, K.},
	year = {2003},
	keywords = {Handwritten Digit, Multi-Layered Network, Neocognitron, Neural Network Model, Visual Pattern Recognition},
	pages = {161--180}
}

@article{hu_learning_2017,
	title = {Learning to {Segment} {Every} {Thing}},
	url = {http://arxiv.org/abs/1711.10370},
	abstract = {Existing methods for object instance segmentation require all training instances to be labeled with segmentation masks. This requirement makes it expensive to annotate new categories and has restricted instance segmentation models to {\textasciitilde}100 well-annotated classes. The goal of this paper is to propose a new partially supervised training paradigm, together with a novel weight transfer function, that enables training instance segmentation models over a large set of categories for which all have box annotations, but only a small fraction have mask annotations. These contributions allow us to train Mask R-CNN to detect and segment 3000 visual concepts using box annotations from the Visual Genome dataset and mask annotations from the 80 classes in the COCO dataset. We carefully evaluate our proposed approach in a controlled study on the COCO dataset. This work is a first step towards instance segmentation models that have broad comprehension of the visual world.},
	urldate = {2017-12-05},
	journal = {arXiv:1711.10370 [cs]},
	author = {Hu, Ronghang and Dollár, Piotr and He, Kaiming and Darrell, Trevor and Girshick, Ross},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.10370},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{redmon_yolo9000:_2016,
	title = {{YOLO}9000: {Better}, {Faster}, {Stronger}},
	shorttitle = {{YOLO}9000},
	url = {http://arxiv.org/abs/1612.08242},
	abstract = {We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on object detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that don't have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. But YOLO can detect more than just 200 classes; it predicts detections for more than 9000 different object categories. And it still runs in real-time.},
	urldate = {2018-01-08},
	journal = {arXiv:1612.08242 [cs]},
	author = {Redmon, Joseph and Farhadi, Ali},
	month = dec,
	year = {2016},
	note = {arXiv: 1612.08242},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{liu_ssd:_2016,
	title = {{SSD}: {Single} {Shot} {MultiBox} {Detector}},
	volume = {9905},
	shorttitle = {{SSD}},
	url = {http://arxiv.org/abs/1512.02325},
	doi = {10.1007/978-3-319-46448-0_2},
	abstract = {We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. Our SSD model is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stage and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, MS COCO, and ILSVRC datasets confirm that SSD has comparable accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. Compared to other single stage methods, SSD has much better accuracy, even with a smaller input image size. For \$300{\textbackslash}times 300\$ input, SSD achieves 72.1\% mAP on VOC2007 test at 58 FPS on a Nvidia Titan X and for \$500{\textbackslash}times 500\$ input, SSD achieves 75.1\% mAP, outperforming a comparable state of the art Faster R-CNN model. Code is available at https://github.com/weiliu89/caffe/tree/ssd .},
	urldate = {2018-01-08},
	journal = {arXiv:1512.02325 [cs]},
	author = {Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C.},
	year = {2016},
	note = {arXiv: 1512.02325},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {21--37}
}

@article{schlegl_unsupervised_2017,
	title = {Unsupervised {Anomaly} {Detection} with {Generative} {Adversarial} {Networks} to {Guide} {Marker} {Discovery}},
	url = {http://arxiv.org/abs/1703.05921},
	abstract = {Obtaining models that capture imaging markers relevant for disease progression and treatment monitoring is challenging. Models are typically based on large amounts of data with annotated examples of known markers aiming at automating detection. High annotation effort and the limitation to a vocabulary of known markers limit the power of such approaches. Here, we perform unsupervised learning to identify anomalies in imaging data as candidates for markers. We propose AnoGAN, a deep convolutional generative adversarial network to learn a manifold of normal anatomical variability, accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space. Applied to new data, the model labels anomalies, and scores image patches indicating their fit into the learned distribution. Results on optical coherence tomography images of the retina demonstrate that the approach correctly identifies anomalous images, such as images containing retinal fluid or hyperreflective foci.},
	urldate = {2018-01-09},
	journal = {arXiv:1703.05921 [cs]},
	author = {Schlegl, Thomas and Seeböck, Philipp and Waldstein, Sebastian M. and Schmidt-Erfurth, Ursula and Langs, Georg},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.05921},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning}
}

@inproceedings{hradis_convolutional_2015,
	title = {Convolutional neural networks for direct text deblurring},
	volume = {10},
	booktitle = {Proceedings of {BMVC}},
	author = {Hradiš, Michal and Kotera, Jan and Zemcík, Pavel and Šroubek, Filip},
	year = {2015}
}

@article{morard_parsimonious_2014,
	title = {Parsimonious {Path} {Openings} and {Closings}},
	volume = {23},
	issn = {1057-7149},
	doi = {10.1109/TIP.2014.2303647},
	abstract = {Path openings and closings are morphological tools used to preserve long, thin, and tortuous structures in gray level images. They explore all paths from a defined class, and filter them with a length criterion. However, most paths are redundant, making the process generally slow. Parsimonious path openings and closings are introduced in this paper to solve this problem. These operators only consider a subset of the paths considered by classical path openings, thus achieving a substantial speed-up, while obtaining similar results. In addition, a recently introduced 1D opening algorithm is applied along each selected path. Its complexity is linear with respect to the number of pixels, independent of the size of the opening. Furthermore, it is fast for any input data accuracy (integer or floating point) and works in stream. Parsimonious path openings are also extended to incomplete paths, i.e., paths containing gaps. Noise-corrupted paths can thus be processed with the same approach and complexity. These parsimonious operators achieve a several orders of magnitude speed-up. Examples are shown for incomplete path openings, where computing times are brought from minutes to tens of milliseconds, while obtaining similar results.},
	number = {4},
	journal = {IEEE Transactions on Image Processing},
	author = {Morard, V. and Dokládal, P. and Decencière, E.},
	month = apr,
	year = {2014},
	keywords = {Complexity theory, Morphology, Noise, Robustness, filtering theory, mathematical morphology, Electronic mail, 1D opening algorithm, classical path openings, computing times, gray level images, incomplete path openings, incomplete paths, length criterion, long-structure preservation, magnitude speed-up, morphological tools, noise-corrupted paths, parsimonious operators, parsimonious path closings, parsimonious path openings, path filtering, substantial speed-up, thin-structure preservation, tortuous structure preservation, Heuristic algorithms, Timing, Path operators, complete and incomplete paths, curvilinear structures, image processing},
	pages = {1543--1555}
}

@article{bejnordi_diagnostic_2017,
	title = {Diagnostic {Assessment} of {Deep} {Learning} {Algorithms} for {Detection} of {Lymph} {Node} {Metastases} in {Women} {With} {Breast} {Cancer}},
	volume = {318},
	issn = {0098-7484},
	url = {https://jamanetwork.com/journals/jama/fullarticle/2665774},
	doi = {10.1001/jama.2017.14585},
	abstract = {{\textless}h3{\textgreater}Importance{\textless}/h3{\textgreater}{\textless}p{\textgreater}Application of deep learning algorithms to whole-slide pathology images can potentially improve diagnostic accuracy and efficiency.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Objective{\textless}/h3{\textgreater}{\textless}p{\textgreater}Assess the performance of automated deep learning algorithms at detecting metastases in hematoxylin and eosin–stained tissue sections of lymph nodes of women with breast cancer and compare it with pathologists’ diagnoses in a diagnostic setting.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Design, Setting, and Participants{\textless}/h3{\textgreater}{\textless}p{\textgreater}Researcher challenge competition (CAMELYON16) to develop automated solutions for detecting lymph node metastases (November 2015-November 2016). A training data set of whole-slide images from 2 centers in the Netherlands with (n = 110) and without (n = 160) nodal metastases verified by immunohistochemical staining were provided to challenge participants to build algorithms. Algorithm performance was evaluated in an independent test set of 129 whole-slide images (49 with and 80 without metastases). The same test set of corresponding glass slides was also evaluated by a panel of 11 pathologists with time constraint (WTC) from the Netherlands to ascertain likelihood of nodal metastases for each slide in a flexible 2-hour session, simulating routine pathology workflow, and by 1 pathologist without time constraint (WOTC).{\textless}/p{\textgreater}{\textless}h3{\textgreater}Exposures{\textless}/h3{\textgreater}{\textless}p{\textgreater}Deep learning algorithms submitted as part of a challenge competition or pathologist interpretation.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Main Outcomes and Measures{\textless}/h3{\textgreater}{\textless}p{\textgreater}The presence of specific metastatic foci and the absence vs presence of lymph node metastasis in a slide or image using receiver operating characteristic curve analysis. The 11 pathologists participating in the simulation exercise rated their diagnostic confidence as definitely normal, probably normal, equivocal, probably tumor, or definitely tumor.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}The area under the receiver operating characteristic curve (AUC) for the algorithms ranged from 0.556 to 0.994. The top-performing algorithm achieved a lesion-level, true-positive fraction comparable with that of the pathologist WOTC (72.4\% [95\% CI, 64.3\%-80.4\%]) at a mean of 0.0125 false-positives per normal whole-slide image. For the whole-slide image classification task, the best algorithm (AUC, 0.994 [95\% CI, 0.983-0.999]) performed significantly better than the pathologists WTC in a diagnostic simulation (mean AUC, 0.810 [range, 0.738-0.884];\textit{P} \&lt; .001). The top 5 algorithms had a mean AUC that was comparable with the pathologist interpreting the slides in the absence of time constraints (mean AUC, 0.960 [range, 0.923-0.994] for the top 5 algorithms vs 0.966 [95\% CI, 0.927-0.998] for the pathologist WOTC).{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions and Relevance{\textless}/h3{\textgreater}{\textless}p{\textgreater}In the setting of a challenge competition, some deep learning algorithms achieved better diagnostic performance than a panel of 11 pathologists participating in a simulation exercise designed to mimic routine pathology workflow; algorithm performance was comparable with an expert pathologist interpreting whole-slide images without time constraints. Whether this approach has clinical utility will require evaluation in a clinical setting.{\textless}/p{\textgreater}},
	language = {en},
	number = {22},
	urldate = {2018-08-06},
	journal = {JAMA},
	author = {Bejnordi, Babak Ehteshami and Veta, Mitko and Diest, Paul Johannes van and Ginneken, Bram van and Karssemeijer, Nico and Litjens, Geert and Laak, Jeroen A. W. M. van der and Hermsen, Meyke and Manson, Quirine F. and Balkenhol, Maschenka and Geessink, Oscar and Stathonikos, Nikolaos and Dijk, Marcory CRF van and Bult, Peter and Beca, Francisco and Beck, Andrew H. and Wang, Dayong and Khosla, Aditya and Gargeya, Rishab and Irshad, Humayun and Zhong, Aoxiao and Dou, Qi and Li, Quanzheng and Chen, Hao and Lin, Huang-Jing and Heng, Pheng-Ann and Haß, Christian and Bruni, Elia and Wong, Quincy and Halici, Ugur and Öner, Mustafa Ümit and Cetin-Atalay, Rengul and Berseth, Matt and Khvatkov, Vitali and Vylegzhanin, Alexei and Kraus, Oren and Shaban, Muhammad and Rajpoot, Nasir and Awan, Ruqayya and Sirinukunwattana, Korsuk and Qaiser, Talha and Tsang, Yee-Wah and Tellez, David and Annuscheit, Jonas and Hufnagl, Peter and Valkonen, Mira and Kartasalo, Kimmo and Latonen, Leena and Ruusuvuori, Pekka and Liimatainen, Kaisa and Albarqouni, Shadi and Mungal, Bharti and George, Ami and Demirci, Stefanie and Navab, Nassir and Watanabe, Seiryo and Seno, Shigeto and Takenaka, Yoichi and Matsuda, Hideo and Phoulady, Hady Ahmady and Kovalev, Vassili and Kalinovsky, Alexander and Liauchuk, Vitali and Bueno, Gloria and Fernandez-Carrobles, M. Milagro and Serrano, Ismael and Deniz, Oscar and Racoceanu, Daniel and Venâncio, Rui},
	month = dec,
	year = {2017},
	pages = {2199--2210}
}

@article{mcculloch_logical_1943,
	title = {A logical calculus of the ideas immanent in nervous activity},
	volume = {5},
	issn = {1522-9602},
	url = {https://doi.org/10.1007/BF02478259},
	doi = {10.1007/BF02478259},
	abstract = {Because of the “all-or-none” character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.},
	language = {en},
	number = {4},
	urldate = {2018-10-05},
	journal = {The bulletin of mathematical biophysics},
	author = {McCulloch, Warren S. and Pitts, Walter},
	month = dec,
	year = {1943},
	keywords = {Excitatory Synapse, Inhibitory Synapse, Nervous Activity, Spatial Summation, Temporal Summation},
	pages = {115--133}
}

@article{hornik_approximation_1991,
	title = {Approximation capabilities of multilayer feedforward networks},
	volume = {4},
	issn = {0893-6080},
	url = {http://www.sciencedirect.com/science/article/pii/089360809190009T},
	doi = {10.1016/0893-6080(91)90009-T},
	abstract = {We show that standard multilayer feedforward networks with as few as a single hidden layer and arbitrary bounded and nonconstant activation function are universal approximators with respect to Lp(μ) performance criteria, for arbitrary finite input environment measures μ, provided only that sufficiently many hidden units are available. If the activation function is continuous, bounded and nonconstant, then continuous mappings can be learned uniformly over compact input sets. We also give very general conditions ensuring that networks with sufficiently smooth activation functions are capable of arbitrarily accurate approximation to a function and its derivatives.},
	number = {2},
	urldate = {2018-10-08},
	journal = {Neural Networks},
	author = {Hornik, Kurt},
	month = jan,
	year = {1991},
	keywords = {() approximation, Activation function, Input environment measure, Multilayer feedforward networks, Smooth approximation, Sobolev spaces, Uniform approximation, Universal approximation capabilities},
	pages = {251--257}
}

@article{cybenko_approximations_1989,
	title = {Approximations by superpositions of a sigmoidal function},
	volume = {2},
	url = {https://ci.nii.ac.jp/naid/10008983330/},
	urldate = {2018-10-08},
	journal = {Mathematics of Control, Signals and Systems},
	author = {Cybenko, G.},
	year = {1989},
	pages = {183--192}
}

@inproceedings{werbos_applications_1982,
	series = {Lecture {Notes} in {Control} and {Information} {Sciences}},
	title = {Applications of advances in nonlinear sensitivity analysis},
	isbn = {978-3-540-39459-4},
	abstract = {The following paper summarizes the major properties and applications of a collection of algorithms involving differentiation and optimization at minimum cost. The areas of application include the sensitivity analysis of models, new work in statistical or econometric estimation, optimization, artificial intelligence and neuron modelling. The details, references and derivations can be obtained by requesting „Sensitivity Analysis Methods for Nonlinear Systems“ from Forecast Analysis and Evaluation Team, Quality Assurance, OSS/EIA, Room 7413, Department of Energy, Washington, DC 20461.},
	language = {en},
	booktitle = {System {Modeling} and {Optimization}},
	publisher = {Springer Berlin Heidelberg},
	author = {Werbos, Paul J.},
	editor = {Drenick, R. F. and Kozin, F.},
	year = {1982},
	keywords = {Deterministic Optimization, Energy Information Administration, Evaluation Team, Sensitivity Analysis Method, Stochastic Optimization},
	pages = {762--770}
}

@inproceedings{pal_capsdemm:_2018,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{CapsDeMM}: {Capsule} {Network} for {Detection} of {Munro}’s {Microabscess} in {Skin} {Biopsy} {Images}},
	isbn = {978-3-030-00934-2},
	shorttitle = {{CapsDeMM}},
	abstract = {This paper presents an approach for automatic detection of Munro’s Microabscess in stratum corneum (SC) of human skin biopsy in order to realize a machine assisted diagnosis of Psoriasis. The challenge of detecting neutrophils in presence of nucleated cells is solved using the recent advances of deep learning algorithms. Separation of SC layer, extraction of patches from the layer followed by classification of patches with respect to presence or absence of neutrophils form the basis of the overall approach which is effected through an integration of a U-Net based segmentation network and a capsule network for classification. The novel design of the present capsule net leads to a drastic reduction in the number of parameters without any noticeable compromise in the overall performance. The research further addresses the challenge of dealing with Mega-pixel images (in 10X) vis-à-vis Giga-pixel ones (in 40X). The promising result coming out of an experiment on a dataset consisting of 273 real-life images shows that a practical system is possible based on the present research. The implementation of our system is available at https://github.com/Anabik/CapsDeMM.},
	language = {en},
	booktitle = {Medical {Image} {Computing} and {Computer} {Assisted} {Intervention} – {MICCAI} 2018},
	publisher = {Springer International Publishing},
	author = {Pal, Anabik and Chaturvedi, Akshay and Garain, Utpal and Chandra, Aditi and Chatterjee, Raghunath and Senapati, Swapan},
	editor = {Frangi, Alejandro F. and Schnabel, Julia A. and Davatzikos, Christos and Alberola-López, Carlos and Fichtinger, Gabor},
	year = {2018},
	keywords = {Evaluation, Convolutional neural network, Biopsy image, Capsule network, Dataset, Munro’s microabscess, Neutrophil, Psoriasis histopathology, Segmentation, Stratum corneum, Super-pixel},
	pages = {389--397}
}

@inproceedings{masci_learning_2013,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Learning} {Framework} for {Morphological} {Operators} {Using} {Counter}–{Harmonic} {Mean}},
	isbn = {978-3-642-38294-9},
	abstract = {We present a novel framework for learning morphological operators using counter-harmonic mean. It combines concepts from morphology and convolutional neural networks. A thorough experimental validation analyzes basic morphological operators dilation and erosion, opening and closing, as well as the much more complex top-hat transform, for which we report a real-world application from the steel industry. Using online learning and stochastic gradient descent, our system learns both the structuring element and the composition of operators. It scales well to large datasets and online settings.},
	language = {en},
	booktitle = {Mathematical {Morphology} and {Its} {Applications} to {Signal} and {Image} {Processing}},
	publisher = {Springer Berlin Heidelberg},
	author = {Masci, Jonathan and Angulo, Jesús and Schmidhuber, Jürgen},
	editor = {Hendriks, Cris L. Luengo and Borgefors, Gunilla and Strand, Robin},
	year = {2013},
	keywords = {mathematical morphology, convolutional networks, machine learning, online learning},
	pages = {329--340}
}

@incollection{lecun_efficient_1998,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Efficient {BackProp}},
	abstract = {The convergence of back-propagation learning is analyzed so as to explain common phenomenon observed by practitioners. Many undesirable behaviors of backprop can be avoided with tricks that are rarely exposed in serious technical publications. This paper gives some of those tricks, and offers explanations of why they work.Many authors have suggested that second-order optimization methods are advantageous for neural net training. It is shown that most “classical” second-order methods are impractical for large neural networks. A few methods are proposed that do not have these limitations.},
	language = {en},
	booktitle = {Neural {Networks}: {Tricks} of the {Trade}},
	publisher = {Springer},
	author = {LeCun, Yann A. and Bottou, Léon and Orr, Genevieve B. and Müller, Klaus-Robert},
	editor = {Orr, Geneviève B. and Müller, Klaus-Robert},
	year = {1998},
	keywords = {Handwritten Digit, Conjugate Gradient, Gradient Descent, Neural Information Processing System, Newton Algorithm},
	pages = {9--50}
}

@article{he_delving_2015,
	title = {Delving {Deep} into {Rectifiers}: {Surpassing} {Human}-{Level} {Performance} on {ImageNet} {Classification}},
	shorttitle = {Delving {Deep} into {Rectifiers}},
	url = {http://arxiv.org/abs/1502.01852},
	abstract = {Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on our PReLU networks (PReLU-nets), we achieve 4.94\% top-5 test error on the ImageNet 2012 classification dataset. This is a 26\% relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66\%). To our knowledge, our result is the first to surpass human-level performance (5.1\%, Russakovsky et al.) on this visual recognition challenge.},
	urldate = {2018-10-17},
	journal = {arXiv:1502.01852 [cs]},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = feb,
	year = {2015},
	note = {arXiv: 1502.01852},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, Computer Science - Machine Learning}
}

@inproceedings{glorot_understanding_2010,
	title = {Understanding the difficulty of training deep feedforward neural networks},
	url = {http://proceedings.mlr.press/v9/glorot10a.html},
	abstract = {Whereas before 2006 it appears that deep multi-layer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental resul...},
	language = {en},
	urldate = {2018-10-17},
	booktitle = {Proceedings of the {Thirteenth} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	author = {Glorot, Xavier and Bengio, Yoshua},
	month = mar,
	year = {2010},
	pages = {249--256}
}

@incollection{ciresan_deep_2012,
	title = {Deep {Neural} {Networks} {Segment} {Neuronal} {Membranes} in {Electron} {Microscopy} {Images}},
	url = {http://papers.nips.cc/paper/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images.pdf},
	urldate = {2018-10-17},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	publisher = {Curran Associates, Inc.},
	author = {Ciresan, Dan and Giusti, Alessandro and Gambardella, Luca M. and Schmidhuber, Jürgen},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
	pages = {2843--2851}
}

@inproceedings{chellapilla_high_2006,
	title = {High {Performance} {Convolutional} {Neural} {Networks} for {Document} {Processing}},
	url = {https://hal.inria.fr/inria-00112631/document},
	abstract = {Convolutional neural networks (CNNs) are well known for producing state-of-the-art recognizers for document processing [1]. However, they can be difficult to implement and are usually slower than traditional multi-layer perceptrons (MLPs). We present three novel approaches to speeding up CNNs: a) unrolling convolution, b) using BLAS (basic linear algebra subroutines), and c) using GPUs (graphic processing units). Unrolled convolution converts the processing in each convolutional layer (both forward-propagation and back-propagation) into a matrix-matrix product. The matrix-matrix product representation of CNNs makes their implementation as easy as MLPs. BLAS is used to efficiently compute matrix products on the CPU. We also present a pixel shader based GPU implementation of CNNs. Results on character recognition problems indicate that unrolled convolution with BLAS produces a dramatic 2.4X−3.0X speedup. The GPU implementation is even faster and produces a 3.1X−4.1X speedup.},
	language = {en},
	urldate = {2018-10-28},
	booktitle = {Tenth {International} {Workshop} on {Frontiers} in {Handwriting} {Recognition}},
	publisher = {Suvisoft},
	author = {Chellapilla, Kumar and Puri, Sidd and Simard, Patrice},
	month = oct,
	year = {2006}
}

@article{ciresan_deep_2010,
	title = {Deep, {Big}, {Simple} {Neural} {Nets} for {Handwritten} {Digit} {Recognition}},
	volume = {22},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/NECO_a_00052},
	doi = {10.1162/NECO_a_00052},
	abstract = {Good old online backpropagation for plain multilayer perceptrons yields a very low 0.35\% error rate on the MNIST handwritten digits benchmark. All we need to achieve this best result so far are many hidden layers, many neurons per layer, numerous deformed training images to avoid overfitting, and graphics cards to greatly speed up learning.},
	number = {12},
	urldate = {2018-10-28},
	journal = {Neural Computation},
	author = {Cireşan, Dan Claudiu and Meier, Ueli and Gambardella, Luca Maria and Schmidhuber, Jürgen},
	month = sep,
	year = {2010},
	pages = {3207--3220}
}

@article{szegedy_going_2014,
	title = {Going {Deeper} with {Convolutions}},
	url = {http://arxiv.org/abs/1409.4842},
	abstract = {We propose a deep convolutional neural network architecture codenamed "Inception", which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
	urldate = {2018-10-28},
	journal = {arXiv:1409.4842 [cs]},
	author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	month = sep,
	year = {2014},
	note = {arXiv: 1409.4842},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{he_deep_2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://arxiv.org/abs/1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	urldate = {2018-10-28},
	journal = {arXiv:1512.03385 [cs]},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.03385},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{everingham_pascal_2010,
	title = {The {Pascal} {Visual} {Object} {Classes} ({VOC}) {Challenge}},
	volume = {88},
	issn = {1573-1405},
	url = {https://doi.org/10.1007/s11263-009-0275-4},
	doi = {10.1007/s11263-009-0275-4},
	abstract = {The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection.This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classification and detection, analyse whether the methods are statistically different, what they are learning from the images (e.g. the object or its context), and what the methods find easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension.},
	language = {en},
	number = {2},
	urldate = {2018-10-29},
	journal = {International Journal of Computer Vision},
	author = {Everingham, Mark and Van Gool, Luc and Williams, Christopher K. I. and Winn, John and Zisserman, Andrew},
	month = jun,
	year = {2010},
	keywords = {Benchmark, Database, Object detection, Object recognition},
	pages = {303--338}
}

@article{lecun_gradient-based_1998,
	title = {Gradient-based learning applied to document recognition},
	volume = {86},
	issn = {0018-9219},
	doi = {10.1109/5.726791},
	abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
	number = {11},
	journal = {Proceedings of the IEEE},
	author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	month = nov,
	year = {1998},
	keywords = {Feature extraction, Pattern recognition, convolution, Machine learning, Neural networks, 2D shape variability, back-propagation, backpropagation, Character recognition, cheque reading, complex decision surface synthesis, convolutional neural network character recognizers, document recognition, document recognition systems, field extraction, gradient based learning technique, gradient-based learning, graph transformer networks, GTN, handwritten character recognition, handwritten digit recognition task, Hidden Markov models, high-dimensional patterns, language modeling, Multi-layer neural network, multilayer neural networks, multilayer perceptrons, multimodule systems, optical character recognition, Optical character recognition software, Optical computing, performance measure minimization, Principal component analysis, segmentation recognition},
	pages = {2278--2324}
}

@inproceedings{simard_efficient_1993,
	title = {Efficient pattern recognition using a new transformation distance},
	booktitle = {Advances in neural information processing systems},
	author = {Simard, Patrice and LeCun, Yann and Denker, John S},
	year = {1993},
	pages = {50--58}
}

@article{deniz_segmentation_2018,
	title = {Segmentation of the {Proximal} {Femur} from {MR} {Images} using {Deep} {Convolutional} {Neural} {Networks}},
	volume = {8},
	copyright = {2018 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-018-34817-6},
	doi = {10.1038/s41598-018-34817-6},
	abstract = {Magnetic resonance imaging (MRI) has been proposed as a complimentary method to measure bone quality and assess fracture risk. However, manual segmentation of MR images of bone is time-consuming, limiting the use of MRI measurements in the clinical practice. The purpose of this paper is to present an automatic proximal femur segmentation method that is based on deep convolutional neural networks (CNNs). This study had institutional review board approval and written informed consent was obtained from all subjects. A dataset of volumetric structural MR images of the proximal femur from 86 subjects were manually-segmented by an expert. We performed experiments by training two different CNN architectures with multiple number of initial feature maps, layers and dilation rates, and tested their segmentation performance against the gold standard of manual segmentations using four-fold cross-validation. Automatic segmentation of the proximal femur using CNNs achieved a high dice similarity score of 0.95 ± 0.02 with precision = 0.95 ± 0.02, and recall = 0.95 ± 0.03. The high segmentation accuracy provided by CNNs has the potential to help bring the use of structural MRI measurements of bone quality into clinical practice for management of osteoporosis.},
	language = {En},
	number = {1},
	urldate = {2018-11-08},
	journal = {Scientific Reports},
	author = {Deniz, Cem M. and Xiang, Siyuan and Hallyburton, R. Spencer and Welbeck, Arakua and Babb, James S. and Honig, Stephen and Cho, Kyunghyun and Chang, Gregory},
	month = nov,
	year = {2018},
	pages = {16485}
}

@article{szegedy_rethinking_2015,
	title = {Rethinking the {Inception} {Architecture} for {Computer} {Vision}},
	url = {http://arxiv.org/abs/1512.00567},
	abstract = {Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2\% top-1 and 5.6\% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5\% top-5 error on the validation set (3.6\% error on the test set) and 17.3\% top-1 error on the validation set.},
	urldate = {2018-11-08},
	journal = {arXiv:1512.00567 [cs]},
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.00567},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}